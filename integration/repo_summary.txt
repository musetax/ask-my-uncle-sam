
File: CODE_OF_CONDUCT.md

File: .DS_Store

File: CHANGELOG.md

File: README.md
README Summary:
Generative AI Application Builder on AWS
> **_NOTE:_** If you want to use the solution without any custom changes, navigate to Solution Landing Page and click the "Launch in the AWS Console" in the Deployment options for a 1-click deployment into your AWS Console.
The Generative AI Application Builder on AWS solution (GAAB) provides a web-based management dashboard to deploy customizable Generative AI (Gen AI) use cases. This Deployment dashboard allows customers to deploy, experiment with, and compare different combinations of Large Language Model (LLM) use cases. Once customers have successfully configured and optimized their use case, they can take their deployment into production and integrate it within their applications.
The Generative AI Application Builder is published under an Apache 2.0 license and is targeted for novice to experienced users who want to experiment and productionize different Gen AI use cases. The solution uses LangChain open-source software (OSS) to configure connections to your choice of Large Language Models (LLMs) for different use cases. The first release of GAAB allows users to deploy chat use cases which allow the ability to query over users' enterprise data in a chatbot-style User Interface (UI), along with an API to support custom end-user implementations.
Some of the features of GAAB are:
-   Rapid experimentation with ability to productionize at scale
-   Extendable and modularized architecture using nested Amazon CloudFormation stacks
-   Enterprise ready for company-specific data to tackle real-world business problems
-   Integration with Amazon Bedrock, Amazon SageMaker and select third-party LLM providers
-   Multi-LLM comparison and experimentation with metric tracking using Amazon CloudWatch dashboards
-   Growing list of model providers and Gen AI use cases
For a detailed solution implementation guide, refer to The Generative AI Application Builder on AWS
On this page
-   Architecture Overview
-   Deployment
-   Source code
-   SageMaker Model Input Documentation
-   Creating a custom build
Architecture Overview
There are 3 unique user personas that are referred to in the solution walkthrough below:
-   The **DevOps user** is responsible for deploying the solution within the AWS account and for managing the infrastructure, updating the solution, monitoring performance, and maintaining the overall health and lifecycle of the solution.
-   The **admin users** are responsible for managing the content contained within the deployment. These users gets access to the Deployment dashboard UI and is primarily responsible for curating the business user experience. This is our primary target customer.
-   The **business users** represents the individuals who the use case has been deployed for. They are the consumers of the knowledge base and the customer responsible for evaluating and experimenting with the LLMs.
> **_NOTE:_**
-   You have the option of deploying the solution as a VPC enabled configuration. With a VPC enabled configuration, you can choose
-   if the solution should build the VPC for this deployment.
-   if you would like to deploy the solution in a VPC existing in your AWS account.
-   To see the VPC related architecture diagrams, please visit the implementation guide.
Deployment Dashboard
When the DevOps user deploys the Deployment Dashboard, the following components are deployed in the AWS account:
!Diagram
1. The admin users can log in to the deployed Deployment Dashboard UI.
2. Amazon CloudFront delivers the web UI which is hosted in an Amazon S3 bucket.
3. AWS WAF protects the APIs from attacks. This solution configures a set of rules called a web access control list (web ACL) that allows, blocks, or counts web requests based on configurable, user-defined web security rules and conditions.
4. The web app leverages a set of REST APIs that are exposed using Amazon API Gateway.
5. Amazon Cognito authenticates users and backs both the Cloudfront web UI and API Gateway.
6. AWS Lambda is used to provide the business logic for the REST endpoints. This Backing Lambda will manage and create the necessary resources to perform use case deployments using AWS Cloudformation.
7. Amazon DynamoDB is used as a configuration store for the deployment details.
8. When a new use case is created by the admin user, the Backing Lambda will initiate a CloudFormation stack creation event for the requested use case.
9. If the configured deployment uses a third-party LLM, then a secret will be created in AWS Secrets Manager to store the API key.
10. All of the LLM configuration options provided by the admin user in the deployment wizard will be saved in an AWS System Manager Parameter Store. This Parameter store is used by the deployment to configure the LLM at runtime.
11. Using Amazon Cloudwatch, operational metrics are collected by various services to generate custom dashboards used for monitoring the solution's health.
Use Cases
Once the Deployment Dashboard is deployed, the admin user can then deploy multiple use case stacks. When a use case stack is deployed by the admin user, the following components are deployed in the AWS account:
!Diagram
1. Business users can log in to the use case UI.
2. Amazon CloudFront delivers the web UI which is hosted in an Amazon S3 bucket.
3. The web UI leverages a WebSocket integration built using Amazon API Gateway. The API Gateway is backed by a custom Lambda Authorizer function, which returns the appropriate IAM policy based on the Amazon Cognito group the authenticating user is part of.
4. Amazon Cognito authenticates users and backs both the Cloudfront web UI and API Gateway.
5. The LangChain Orchestrator is a collection of Lambda functions and layers that provide the business logic for fulfilling requests coming from the business user.
6. The LangChain Orchestrator leverages Parameter store and DynamoDB to get the configured LLM options and necessary session information (such as the chat history).
7. If the deployment has enabled a knowledge base, then the LangChain Orchestrator will leverage Amazon Kendra to run a search query to retrieve document excerpts.
8. Using the chat history, query, and context from Amazon Kendra, the LangChain Orchestrator creates the final prompt and sends the request to the LLM hosted on Amazon Bedrock or Amazon SageMaker.
9. If using a third-party LLM outside of Amazon Bedrock or Amazon SageMaker, the API key is stored in AWS Secrets Manager and must be obtained before making the API call to the third-party LLM provider.
10. As the response comes back from the LLM, the LangChain Orchestrator Lambda streams the response back through the API Gateway WebSocket to be consumed by the client application.
11. Using Amazon Cloudwatch, operational metrics are collected by various services to generate custom dashboards used for monitoring the deployment's health.
Deployment
> **_NOTE:_**
-   To use Amazon Bedrock, you must request access to models before they are available for use. Refer to Model access in the Amazon Bedrock User Guide for more details.
-   You can also test the UI project locally by deploying the API endpoints and the rest of the infrastructure. To do so, follow either of the below two options and then refer Deployment Dashboard and Chat UI project for details.
There are two options for deployment into your AWS account:
1. Using `cdk deploy`
Following are pre-requisites to build and deploy locally:
-   Docker
-   Nodejs 20.x
-   CDK v2.118.0
-   Python >= 3.11, <=3.12.1
-   _Note: normal python installations should include support for `ensurepip` and `pip`; however, if running in an environment without these packages you will need to manually install them (e.g. a minimal docker image). See pip's installation guide for details._
-   AWS CLI
-   jq
**Note: Configure the AWS CLI with your AWS credentials or have them exported in the CLI terminal environment. In case the credentials are invalid or expired, running `cdk deploy` produces an error.**
**Also, if you have not run `cdk bootstrap` in this account and region, please follow the instructions here to execute cdk bootstrap as a one time process before proceeding with the below steps.**
After cloning the repo from GitHub, complete the following steps:
**Note: Because `cdk deploy` is executed with a stack name, it does not synthesize the other CloudFormation stacks in the infrastructure folder. To ensure all stacks are synthesized based on the infrastructure code changes, please ensure to `cdk synth`. For a complete list of cdk commands that can be run, see Toolkit commands**
For the deployment dashboard to deploy LLM chat use cases, you would additionally need to stage synthesized CDK assets (such as lambdas, synthesized CloudFormation templates, etc.) from the `source/infrastructure/cdk.out` directory to a configured S3 bucket in your account from where these resources will be pulled from at the time of deployment. To make it easy to stage these assets, you can use the `source/stage-assets.sh` script. This script should be run from the `source` directory.
When run, the script looks like this:
You must provide the full region name as the first input to the script as shown in the above example.
**Note: Assets must be staged every time there is a change in the codebase to have the most up-to-date staged assets. It is also recommend to run `cdk synth` before staging.**
2. Using a custom build
Refer section Creating a custom build
Source code
Project structure
SageMaker Model Input Documentation
The project provides a docs folder which gives you access to sample SageMaker inputs. As SageMaker models can take in and output a variety of input and output schemas, respectively, the solution requests these values from the users to allow correct model invocation. This allows the solution to support a wide set of SageMaker models.
The input schemas are essentially your model's payload, with placeholders for the actual values. The placeholders enable replacing the actual model values at run-time and are represented by a keyword enclosed in angle brackets like: `<<prompt>>`. Note that `<<prompt>>` and `<<temperature>>` are reserved placeholders for the model prompt and temperatures respectively.
The model's output JSONPath provides the solution a path to retrieve the LLM's textual response from the model response.
Please always refer to model documentation and SageMaker JumpStart jupyter notebook samples to see the most up-to-date model payloads and supported parameters.
Creating a custom build
1. Clone the repository
Run the following command:
`git clone https://github.com/aws-solutions/<repository_name>`
2. Build the solution for deployment
1. Install the dependencies:
2. (Optional) Run the unit tests:
**Note: To run the unit tests, docker must be installed and running, and valid AWS credentials must be configured.**
3. Configure the bucket name of your target Amazon S3 distribution bucket:
4. Build the distributable:
Parameter details:
When you create and use buckets, we recommended that you:
-   Use randomized names or uuid as part of your bucket naming strategy.
-   Ensure that buckets aren't public.
-   Verify bucket ownership prior to uploading templates or code artifacts.
5. Deploy the distributable to an Amazon S3 bucket in your account.
**Note: You must have the AWS CLI installed.**
Anonymized data collection
This solution collects anonymized operational metrics to help AWS improve the quality and features of the solution. For more information, including how to disable this capability, please see the implementation guide.
---
Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

File: NOTICE.txt

File: .gitignore

File: CONTRIBUTING.md

File: LICENSE.txt

File: integration/summarize_code.py
Summary of summarize_code.py:
- Function: summarize_script
- Function: summarize_readme
- Function: process_repository


File: integration/code_summary.txt

File: integration/repo_summary.txt

File: source/run-all-tests.sh

File: source/.DS_Store

File: source/.prettierignore

File: source/.prettierrc.yml

File: source/stage-assets.sh

File: source/.eslintignore

File: source/pre-build-lambda-layers.sh

File: source/model-info/ragchat-huggingface-google-flan-t5-xl.json

File: source/model-info/chat-bedrock-llama2-13b-chat-v1.json

File: source/model-info/ragchat-bedrock-anthropic-claude-instant.json

File: source/model-info/ragchat-bedrock-cohere-command-light-text-v14.json

File: source/model-info/chat-bedrock-ai21-j2-mid.json

File: source/model-info/ragchat-bedrock-ai21-j2-ultra.json

File: source/model-info/chat-bedrock-llama2-70b-chat-v1.json

File: source/model-info/chat-huggingface-default.json

File: source/model-info/chat-bedrock-cohere-command-light-text-v14.json

File: source/model-info/ragchat-huggingface-ie-tiiuae-falcon7b.json

File: source/model-info/chat-sagemaker-default.json

File: source/model-info/ragchat-bedrock-llama2-70b-chat-v1.json

File: source/model-info/ragchat-huggingface-ie-google-flan-t5-xl.json

File: source/model-info/chat-bedrock-cohere-command-text-v14.json

File: source/model-info/ragchat-bedrock-llama2-13b-chat-v1.json

File: source/model-info/chat-huggingface-ie-tiiuae-falcon40b.json

File: source/model-info/ragchat-huggingface-ie-tiiuae-falcon40b-instruct.json

File: source/model-info/chat-huggingface-google-flan-t5-xxl.json

File: source/model-info/ragchat-bedrock-amazon-titan-text-lite-v1.json

File: source/model-info/chat-bedrock-mistralai-mistral-large-2402-v1.0.json

File: source/model-info/ragchat-huggingface-google-flan-t5-large.json

File: source/model-info/ragchat-bedrock-anthropic-claude-v2.1.json

File: source/model-info/ragchat-huggingface-ie-google-flan-t5-xxl.json

File: source/model-info/chat-bedrock-mistralai-mistral-7b-instruct-v0.2.json

File: source/model-info/ragchat-huggingface-google-flan-t5-base.json

File: source/model-info/ragchat-huggingface-google-flan-t5-small.json

File: source/model-info/ragchat-bedrock-mistralai-mistral-7b-instruct-v0.2.json

File: source/model-info/ragchat-anthropic-claude-v2.json

File: source/model-info/ragchat-bedrock-anthropic-claude-v3.1-sonnet.json

File: source/model-info/ragchat-bedrock-ai21-j2-mid.json

File: source/model-info/chat-huggingface-google-flan-t5-small.json

File: source/model-info/ragchat-huggingface-default.json

File: source/model-info/chat-huggingface-google-flan-t5-base.json

File: source/model-info/ragchat-bedrock-anthropic-claude-v3.1-haiku.json

File: source/model-info/ragchat-huggingface-google-flan-t5-xxl.json

File: source/model-info/chat-bedrock-anthropic-claude-v3.1-sonnet.json

File: source/model-info/chat-anthropic-claude-instant.json

File: source/model-info/chat-bedrock-anthropic-claude-v3.1-haiku.json

File: source/model-info/chat-huggingface-google-flan-t5-xl.json

File: source/model-info/chat-bedrock-anthropic-claude-v2.json

File: source/model-info/chat-huggingface-google-flan-t5-large.json

File: source/model-info/ragchat-anthropic-claude-instant.json

File: source/model-info/chat-huggingface-ie-google-flan-t5-base.json

File: source/model-info/ragchat-bedrock-mistralai-mistral-large-2402-v1.0.json

File: source/model-info/ragchat-bedrock-cohere-command-text-v14.json

File: source/model-info/ragchat-bedrock-anthropic-claude-v2.json

File: source/model-info/chat-bedrock-anthropic-claude-v2.1.json

File: source/model-info/chat-huggingface-ie-google-flan-t5-small.json

File: source/model-info/chat-bedrock-mistralai-mixtral-8x7b-instruct-v0.1.json

File: source/model-info/chat-huggingface-ie-tiiuae-falcon7b-instruct.json

File: source/model-info/ragchat-huggingface-ie-tiiuae-falcon40b.json

File: source/model-info/ragchat-huggingface-ie-google-flan-t5-large.json

File: source/model-info/ragchat-sagemaker-default.json

File: source/model-info/chat-bedrock-amazon-titan-text-lite-v1.json

File: source/model-info/chat-bedrock-ai21-j2-ultra.json

File: source/model-info/chat-huggingface-ie-google-flan-t5-xl.json

File: source/model-info/ragchat-bedrock-mistralai-mixtral-8x7b-instruct-v0.1.json

File: source/model-info/chat-bedrock-amazon-titan-text-express-v1.json

File: source/model-info/chat-anthropic-claude-v2.json

File: source/model-info/chat-huggingface-ie-google-flan-t5-large.json

File: source/model-info/ragchat-huggingface-ie-tiiuae-falcon7b-instruct.json

File: source/model-info/chat-huggingface-ie-tiiuae-falcon40b-instruct.json

File: source/model-info/ragchat-huggingface-ie-google-flan-t5-small.json

File: source/model-info/ragchat-huggingface-ie-google-flan-t5-base.json

File: source/model-info/chat-huggingface-ie-tiiuae-falcon7b.json

File: source/model-info/chat-huggingface-ie-google-flan-t5-xxl.json

File: source/model-info/ragchat-bedrock-amazon-titan-text-express-v1.json

File: source/model-info/chat-bedrock-anthropic-claude-instant.json

File: source/ui-chat/tailwind.config.js

File: source/ui-chat/README.md
README Summary:
Generative AI Application Builder on AWS - WebApp
This project is the web interface (UI Application) that provides the front-end experience. The application is
based on Reactjs framework and uses components from the AWS Cloudscape Design System
Local Configuration Setup
To build and run the application locally, the setup requires
-   Nodejs 18.x or higher installed
Follow the below steps before building the web app for local execution
-   The backend infrastructure stacks from `source/infrastructure` are deployed in your AWS account
-   Create a file `source/ui-chat/public/runtimeConfig.json` (if one does not exist) by executing
-   From the AWS CloudFormation console, navigate to the `Outputs` tab of the main/ parent stack deployed and copy the `Value` of the `Key` named `WebConfigKey`.
-   Navigate to AWS Systems Manager Parameter Store in the AWS web console, search for the `Key` in the previous step and copy the contents into the file created in the previous (step #2) steps (`source/ui-chat/public/runtimeConfig.json`)
For reference, the string in the Parameter Store should look something like the below:
After completing the above steps, you can run the web application locally.
Build and Run the App Locally
1. From the project root directory, change directory to `source/ui-chat`
2. Install the library modules if building the project for the first time
3. Building the project with the below command will generate a `build` folder which contains
the compiled components and minified javascript files.
4. Executing the following command will run a local server on port 3000 (http://localhost:3000)
You should now be able to log in with the User Id and Password for which you should have received an email during deployment. You can also
create additional users in the Amazon Cognito User Pool from the AWS web console.

File: source/ui-chat/.gitignore

File: source/ui-chat/package-lock.json

File: source/ui-chat/package.json

File: source/ui-chat/tsconfig.json

File: source/ui-chat/public/index.html

File: source/ui-chat/public/favicon.png

File: source/ui-chat/public/manifest.json

File: source/ui-chat/public/robots.txt

File: source/ui-chat/src/App.css

File: source/ui-chat/src/index.js

File: source/ui-chat/src/index.css

File: source/ui-chat/src/setupTests.js

File: source/ui-chat/src/App.js

File: source/ui-chat/src/home/home.context.tsx

File: source/ui-chat/src/home/home.state.tsx

File: source/ui-chat/src/types/prompt.ts

File: source/ui-chat/src/types/chat.ts

File: source/ui-chat/src/types/misc.ts

File: source/ui-chat/src/utils/constants.ts

File: source/ui-chat/src/utils/conversation.ts

File: source/ui-chat/src/styles/globals.css

File: source/ui-chat/src/components/MemoizedReactMarkdown.tsx

File: source/ui-chat/src/components/external-link-warning-modal.jsx

File: source/ui-chat/src/components/PromptTemplate.tsx

File: source/ui-chat/src/components/SourceDocumentsModal.tsx

File: source/ui-chat/src/components/Chat.css

File: source/ui-chat/src/components/ChatInput.css

File: source/ui-chat/src/components/Chat.tsx

File: source/ui-chat/src/components/MemoizedChatMessage.tsx

File: source/ui-chat/src/components/ChatMessage.tsx

File: source/ui-chat/src/components/ChatInput.tsx

File: source/ui-chat/src/components/CodeBlock.tsx

File: source/ui-chat/src/components/__tests__/PromptTemplate.tsx

File: source/ui-chat/src/components/__tests__/Chat.tsx

File: source/ui-chat/src/components/__tests__/ChatMessage.tsx

File: source/ui-chat/src/components/__tests__/CodeBlock.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/PromptTemplate.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/Chat.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/ChatMessage.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/ChatInput.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/CodeBlock.tsx

File: source/ui-chat/src/components/__tests__/snapshot_tests/__snapshots__/ChatMessage.tsx.snap

File: source/ui-chat/src/components/__tests__/snapshot_tests/__snapshots__/CodeBlock.tsx.snap

File: source/ui-chat/src/components/__tests__/snapshot_tests/__snapshots__/PromptTemplate.tsx.snap

File: source/ui-chat/src/components/__tests__/snapshot_tests/__snapshots__/Chat.tsx.snap

File: source/ui-chat/src/components/__tests__/snapshot_tests/__snapshots__/ChatInput.tsx.snap

File: source/ui-chat/src/hooks/useCreateReducer.ts

File: source/ui-deployment/README.md
README Summary:
Generative AI Application Builder on AWS - Deployment Dashboard
This project is the web interface (UI Application) that provides the front-end experience. The application is
based on Reactjs framework and uses components from the AWS Cloudscape Design System
Local Configuration Setup
To build and run the application locally, the setup requires
-   Nodejs 18.x or higher installed
Follow the below steps before building the web app for local execution
-   The backend infrastructure stacks from `source/infrastructure` are deployed in your AWS account
-   Create a file `source/ui-deployment/public/runtimeConfig.json` (if one does not exist) by executing
-   From the AWS CloudFormation console, navigate to the `Outputs` tab of the main/ parent stack deployed and copy the `Value` of the `Key` named `WebConfigKey`.
-   Navigate to AWS Systems Manager Parameter Store in the AWS web console, search for the `Key` in the previous step and copy the contents into the file created in the previous (step #2) steps (`source/ui-deployment/public/runtimeConfig.json`)
For reference, the string in the Parameter Store should look something like the below:
After completing the above steps, you can run the web application locally.
Build and Run the App Locally
1. From the project root directory, change directory to `source/ui-deployment`
2. Install the library modules if building the project for the first time
3. Building the project with the below command will generate a `build` folder which contains
the compiled components and minified javascript files.
4. Executing the following command will run a local server on port 3000 (http://localhost:3000)
You should now be able to log in with the User Id and Password for which you should have received an email during deployment. You can also
create additional users in the Amazon Cognito User Pool from the AWS web console.

File: source/ui-deployment/.gitignore

File: source/ui-deployment/package-lock.json

File: source/ui-deployment/package.json

File: source/ui-deployment/tsconfig.json

File: source/ui-deployment/public/index.html

File: source/ui-deployment/public/favicon.png

File: source/ui-deployment/public/manifest.json

File: source/ui-deployment/public/robots.txt

File: source/ui-deployment/src/App.css

File: source/ui-deployment/src/index.js

File: source/ui-deployment/src/index.css

File: source/ui-deployment/src/setupTests.js

File: source/ui-deployment/src/App.js

File: source/ui-deployment/src/contexts/home.context.tsx

File: source/ui-deployment/src/contexts/home.state.tsx

File: source/ui-deployment/src/contexts/index.ts

File: source/ui-deployment/src/utils/test-utils.tsx

File: source/ui-deployment/src/utils/constants.ts

File: source/ui-deployment/src/utils/index.ts

File: source/ui-deployment/src/utils/utils.tsx

File: source/ui-deployment/src/utils/mock-context.json

File: source/ui-deployment/src/components/commons/external-link-group.tsx

File: source/ui-deployment/src/components/commons/use-column-widths.js

File: source/ui-deployment/src/components/commons/external-link-warning-modal.jsx

File: source/ui-deployment/src/components/commons/deploy-confirmation-modal.jsx

File: source/ui-deployment/src/components/commons/table-config.jsx

File: source/ui-deployment/src/components/commons/use-local-storage.ts

File: source/ui-deployment/src/components/commons/localStorage.ts

File: source/ui-deployment/src/components/commons/delete-notifications.tsx

File: source/ui-deployment/src/components/commons/common-components.jsx

File: source/ui-deployment/src/components/commons/delete-modal.jsx

File: source/ui-deployment/src/components/commons/notifications.tsx

File: source/ui-deployment/src/components/commons/external-link.tsx

File: source/ui-deployment/src/components/commons/breadcrumbs.js

File: source/ui-deployment/src/components/commons/full-page-header.tsx

File: source/ui-deployment/src/components/commons/columnDefinitionsHelper.js

File: source/ui-deployment/src/components/commons/index.ts

File: source/ui-deployment/src/components/commons/navigation.tsx

File: source/ui-deployment/src/components/commons/use-component-id.ts

File: source/ui-deployment/src/components/commons/info-link.tsx

File: source/ui-deployment/src/components/commons/separated-list.tsx

File: source/ui-deployment/src/components/commons/copy-text/index.tsx

File: source/ui-deployment/src/components/commons/copy-text/styles.css

File: source/ui-deployment/src/components/wizard/tools-content.jsx

File: source/ui-deployment/src/components/wizard/wizard-components.jsx

File: source/ui-deployment/src/components/wizard/steps-config.jsx

File: source/ui-deployment/src/components/wizard/utils.js

File: source/ui-deployment/src/components/wizard/WizardView.jsx

File: source/ui-deployment/src/components/wizard/VpcConfig/SecurityGroupAttrEditor.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/DeployVpc.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/SubnetIdAttrEditor.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/VpcId.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/index.ts

File: source/ui-deployment/src/components/wizard/VpcConfig/Vpc.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/UseExistingVpc.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/helpers.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/SecurityGroupAttrEditor.test.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/Vpc.test.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/UseExistingVpc.test.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/VpcId.test.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/SubnetIdAttrEditor.test.tsx

File: source/ui-deployment/src/components/wizard/VpcConfig/__tests__/DeployVpc.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/KnowledgeBaseSelection.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/KnowledgeBaseType.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/KnowledgeBase.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/AdvancedKnowledgeBaseConfig.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/index.ts

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/index.ts

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/Kendra.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraQueryCapacity.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/ExistingKendraIndexOption.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/index.ts

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraIndexName.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraResourceRetentionWarning.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraIndexId.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraEdition.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/KendraStorageCapacity.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/AdditionalKendraOptions.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraEdition.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/Kendra.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraStorageCapacity.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/AdditionalKendraOptions.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraQueryCapacity.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/ExistingKendraIndex.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraResourceRetention.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraIndexId.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/providers/Kendra/__tests__/KendraIndexName.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/common/ReturnSourceDocuments.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/common/RetrieveDocumentCount.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/common/__tests__/ReturnSourceDocuments.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/common/__tests__/RetrieveDocumentCount.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/__tests__/KnowledgeBaseSelection.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/__tests__/KnowledgeBase.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/__tests__/AdvancedKnowledgeBaseConfig.test.tsx

File: source/ui-deployment/src/components/wizard/KnowledgeBase/__tests__/KnowledgeBaseType.test.tsx

File: source/ui-deployment/src/components/wizard/Review/UseCaseReview.tsx

File: source/ui-deployment/src/components/wizard/Review/VpcConfigReview.tsx

File: source/ui-deployment/src/components/wizard/Review/KnowledgeBaseReview.tsx

File: source/ui-deployment/src/components/wizard/Review/Review.tsx

File: source/ui-deployment/src/components/wizard/Review/InvalidPromptWarning.tsx

File: source/ui-deployment/src/components/wizard/Review/ModelReview.tsx

File: source/ui-deployment/src/components/wizard/Review/ReviewPrompt.tsx

File: source/ui-deployment/src/components/wizard/Review/index.ts

File: source/ui-deployment/src/components/wizard/Review/__tests__/UseCaseReview.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/VpcConfig.Review.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/ReviewPrompt.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/Review.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/KnowledgeBaseReview.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/InvalidPromptWarning.test.tsx

File: source/ui-deployment/src/components/wizard/Review/__tests__/ModelReview.test.tsx

File: source/ui-deployment/src/components/wizard/Model/helpers.ts

File: source/ui-deployment/src/components/wizard/Model/Model.tsx

File: source/ui-deployment/src/components/wizard/Model/ModelAdditionalSettings.tsx

File: source/ui-deployment/src/components/wizard/Model/index.ts

File: source/ui-deployment/src/components/wizard/Model/ModelSelection.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/Sagemaker.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/Bedrock.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/HuggingFace.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/HuggingFaceInferenceEndpoint.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/index.ts

File: source/ui-deployment/src/components/wizard/Model/providers/Anthropic.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/__tests__/HuggingFaceInferenceEndpoint.test.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/__tests__/Anthropic.test.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/__tests__/Bedrock.test.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/__tests__/Sagemaker.test.tsx

File: source/ui-deployment/src/components/wizard/Model/providers/__tests__/HuggingFace.test.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/helpers.ts

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/InputSchema.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/SagemakerPayloadSchema.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/RenderedMarkdown.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/RenderedInputPayload.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/index.ts

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/OutputSchema.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/__tests__/OutputSchema.test.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/__tests__/InputSchema.test.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/__tests__/helpers.test.ts

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/__tests__/RenderedInputPayload.test.tsx

File: source/ui-deployment/src/components/wizard/Model/SagemakerPayloadSchema/__tests__/SagemakerPayloadSchema.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/helpers.ts

File: source/ui-deployment/src/components/wizard/Model/common/InferenceEndpointUrlInput.tsx

File: source/ui-deployment/src/components/wizard/Model/common/ThirdPartyLegalDisclaimer.tsx

File: source/ui-deployment/src/components/wizard/Model/common/ModelProvider.tsx

File: source/ui-deployment/src/components/wizard/Model/common/ModelNameDropdown.tsx

File: source/ui-deployment/src/components/wizard/Model/common/PromptTemplate.tsx

File: source/ui-deployment/src/components/wizard/Model/common/StreamingToggle.tsx

File: source/ui-deployment/src/components/wizard/Model/common/InferenceEndpointName.tsx

File: source/ui-deployment/src/components/wizard/Model/common/VerboseToggle.tsx

File: source/ui-deployment/src/components/wizard/Model/common/ApiKeyInput.tsx

File: source/ui-deployment/src/components/wizard/Model/common/ModelTemperature.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/InferenceEndpointUrlInput.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/ThirdPartyLegalDisclaimer.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/ModelNameDropdown.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/ModelTemperature.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/PromptTemplate.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/InferenceEndpointName.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/VerboseToggle.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/ModelProviderDropdown.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/StreamingToggle.test.tsx

File: source/ui-deployment/src/components/wizard/Model/common/__tests__/ApiKeyInput.test.tsx

File: source/ui-deployment/src/components/wizard/Model/__tests__/ModelAdditionalSettings.test.tsx

File: source/ui-deployment/src/components/wizard/Model/__tests__/ModelSelection.test.tsx

File: source/ui-deployment/src/components/wizard/Model/__tests__/helpers.test.ts

File: source/ui-deployment/src/components/wizard/Model/__tests__/Model.test.tsx

File: source/ui-deployment/src/components/wizard/Model/AdvancedModelSettings/SelectionControl.tsx

File: source/ui-deployment/src/components/wizard/Model/AdvancedModelSettings/InputControl.tsx

File: source/ui-deployment/src/components/wizard/Model/AdvancedModelSettings/index.ts

File: source/ui-deployment/src/components/wizard/Model/AdvancedModelSettings/AdvancedModelSettings.tsx

File: source/ui-deployment/src/components/wizard/Model/AdvancedModelSettings/__tests__/AdvancedModelSettings.test.tsx

File: source/ui-deployment/src/components/wizard/UseCase/UseCaseName.tsx

File: source/ui-deployment/src/components/wizard/UseCase/UseCase.tsx

File: source/ui-deployment/src/components/wizard/UseCase/UseCaseDescription.tsx

File: source/ui-deployment/src/components/wizard/UseCase/index.ts

File: source/ui-deployment/src/components/wizard/UseCase/UseCaseTypeSelection.tsx

File: source/ui-deployment/src/components/wizard/UseCase/UserEmail.tsx

File: source/ui-deployment/src/components/wizard/UseCase/__tests__/UseCaseDescription.test.tsx

File: source/ui-deployment/src/components/wizard/UseCase/__tests__/UseCaseTypeSelection.test.tsx

File: source/ui-deployment/src/components/wizard/UseCase/__tests__/UseCaseName.test.tsx

File: source/ui-deployment/src/components/wizard/UseCase/__tests__/UseCase.test.tsx

File: source/ui-deployment/src/components/wizard/UseCase/__tests__/UserEmail.test.tsx

File: source/ui-deployment/src/components/wizard/interfaces/Steps.tsx

File: source/ui-deployment/src/components/wizard/interfaces/RuntimeConfig.tsx

File: source/ui-deployment/src/components/wizard/interfaces/index.ts

File: source/ui-deployment/src/components/wizard/interfaces/BaseFormComponent.tsx

File: source/ui-deployment/src/components/dashboard/DashboardView.jsx

File: source/ui-deployment/src/components/dashboard/hooks.js

File: source/ui-deployment/src/components/dashboard/common-components.jsx

File: source/ui-deployment/src/components/dashboard/deployments.js

File: source/ui-deployment/src/components/__tests__/__mocks__/deployment-steps-form-data.js

File: source/ui-deployment/src/components/__tests__/__mocks__/mock-context.json

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/WizardView.tsx

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/utils.test.js

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/stepComponents/KnowledgeBase.jsx

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/stepComponents/Review.jsx

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/stepComponents/__snapshots__/Review.jsx.snap

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/stepComponents/__snapshots__/KnowledgeBase.jsx.snap

File: source/ui-deployment/src/components/__tests__/snapshot_tests/wizard/__snapshots__/WizardView.tsx.snap

File: source/ui-deployment/src/components/__tests__/snapshot_tests/dashboard/Dashboard.tsx

File: source/ui-deployment/src/components/__tests__/snapshot_tests/dashboard/__snapshots__/Dashboard.tsx.snap

File: source/ui-deployment/src/components/__tests__/snapshot_tests/useCaseDetails/UseCaseView.tsx

File: source/ui-deployment/src/components/__tests__/snapshot_tests/useCaseDetails/__snapshots__/UseCaseView.tsx.snap

File: source/ui-deployment/src/components/__tests__/wizard/WizardView.tsx

File: source/ui-deployment/src/components/__tests__/dashboard/DashboardView.tsx

File: source/ui-deployment/src/components/__tests__/useCaseDetails/UseCaseView.tsx

File: source/ui-deployment/src/components/useCaseDetails/tools-content.jsx

File: source/ui-deployment/src/components/useCaseDetails/common-components.jsx

File: source/ui-deployment/src/components/useCaseDetails/UseCaseView.jsx

File: source/ui-deployment/src/hooks/useCreateReducer.ts

File: source/ui-deployment/src/hooks/useQueries.ts

File: source/ui-deployment/src/hooks/useTools.tsx

File: source/ui-deployment/src/hooks/__tests__/useQueries.test.tsx

File: source/ui-deployment/src/i18n-strings/text-filter.ts

File: source/ui-deployment/src/i18n-strings/pagination.ts

File: source/ui-deployment/src/i18n-strings/table.ts

File: source/ui-deployment/src/i18n-strings/app-layout.ts

File: source/ui-deployment/src/i18n-strings/flashbar.ts

File: source/ui-deployment/src/i18n-strings/collection-preferences.ts

File: source/ui-deployment/src/i18n-strings/index.ts

File: source/ui-deployment/src/i18n-strings/header.ts

File: source/ui-deployment/src/services/index.ts

File: source/ui-deployment/src/services/fetchModelData.ts

File: source/ui-deployment/src/services/__tests__/fetchModelData.test.ts

File: source/lambda/model-info/jest.config.js

File: source/lambda/model-info/power-tools-init.ts

File: source/lambda/model-info/package-lock.json

File: source/lambda/model-info/package.json

File: source/lambda/model-info/tsconfig.json

File: source/lambda/model-info/index.ts

File: source/lambda/model-info/test/index.test.ts

File: source/lambda/model-info/test/event-test-data.ts

File: source/lambda/model-info/test/utils/model-info-retriever.test.ts

File: source/lambda/model-info/utils/http-response-formatters.ts

File: source/lambda/model-info/utils/model-info-retriever.ts

File: source/lambda/model-info/utils/check-env.ts

File: source/lambda/model-info/utils/constants.ts

File: source/lambda/websocket-connectors/connect-handler.ts

File: source/lambda/websocket-connectors/jest.config.js

File: source/lambda/websocket-connectors/package-lock.json

File: source/lambda/websocket-connectors/package.json

File: source/lambda/websocket-connectors/tsconfig.json

File: source/lambda/websocket-connectors/disconnect-handler.ts

File: source/lambda/websocket-connectors/test/disconnect-handler.test.ts

File: source/lambda/websocket-connectors/test/connect-handler.test.ts

File: source/lambda/layers/huggingface_hub/pyproject.toml

File: source/lambda/layers/huggingface_hub/.gitignore

File: source/lambda/layers/huggingface_hub/poetry.lock

File: source/lambda/layers/langchain/pyproject.toml

File: source/lambda/layers/langchain/.gitignore

File: source/lambda/layers/langchain/poetry.lock

File: source/lambda/layers/aws-sdk-lib/package-lock.json

File: source/lambda/layers/aws-sdk-lib/package.json

File: source/lambda/layers/aws_boto3/pyproject.toml

File: source/lambda/layers/aws_boto3/.gitignore

File: source/lambda/layers/aws_boto3/poetry.lock

File: source/lambda/layers/anthropic/pyproject.toml

File: source/lambda/layers/anthropic/.gitignore

File: source/lambda/layers/anthropic/poetry.lock

File: source/lambda/layers/aws-node-user-agent-config/.gitignore

File: source/lambda/layers/aws-node-user-agent-config/package-lock.json

File: source/lambda/layers/aws-node-user-agent-config/package.json

File: source/lambda/layers/aws-node-user-agent-config/tsconfig.json

File: source/lambda/layers/aws-node-user-agent-config/index.ts

File: source/lambda/layers/aws-node-user-agent-config/test/index.test.ts

File: source/lambda/layers/custom_boto3_init/pyproject.toml

File: source/lambda/layers/custom_boto3_init/__init__.py
Summary of __init__.py:


File: source/lambda/layers/custom_boto3_init/.coveragerc

File: source/lambda/layers/custom_boto3_init/.gitignore

File: source/lambda/layers/custom_boto3_init/helper.py
Summary of helper.py:
- Function: get_session
- Function: get_service_client
- Function: get_service_resource


File: source/lambda/layers/custom_boto3_init/poetry.lock

File: source/lambda/layers/custom_boto3_init/custom_config.py
Summary of custom_config.py:
- Function: custom_usr_agent_config
- Function: check_env_setup


File: source/lambda/layers/custom_boto3_init/test/conftest.py
Summary of conftest.py:
- Function: aws_credentials


File: source/lambda/layers/custom_boto3_init/test/test_layer_env_config.py
Summary of test_layer_env_config.py:
- Function: test_when_usr_agent_not_set
- Function: test_custom_usr_agent_config
- Function: test_with_wrong_usr_agent_key_value


File: source/lambda/layers/custom_boto3_init/test/__init__.py
Summary of __init__.py:


File: source/lambda/layers/custom_boto3_init/test/test_service_instance_creation.py
Summary of test_service_instance_creation.py:
- Function: user_agent
- Function: test_get_session
- Function: test_get_service_resource
- Function: test_get_service_client
- Function: test_get_service_resource


File: source/lambda/chat/sagemaker_handler.py
Summary of sagemaker_handler.py:
- Function: lambda_handler


File: source/lambda/chat/huggingface_handler.py
Summary of huggingface_handler.py:
- Function: lambda_handler


File: source/lambda/chat/pyproject.toml

File: source/lambda/chat/__init__.py
Summary of __init__.py:


File: source/lambda/chat/.coveragerc

File: source/lambda/chat/anthropic_handler.py
Summary of anthropic_handler.py:
- Function: lambda_handler


File: source/lambda/chat/.gitignore

File: source/lambda/chat/bedrock_handler.py
Summary of bedrock_handler.py:
- Function: lambda_handler


File: source/lambda/chat/poetry.lock

File: source/lambda/chat/clients/bedrock_client.py
Summary of bedrock_client.py:
- Class: BedrockClient
- Function: __init__
- Function: get_model
- Function: construct_chat_model


File: source/lambda/chat/clients/sagemaker_client.py
Summary of sagemaker_client.py:
- Class: SageMakerClient
- Function: __init__
- Function: get_model
- Function: construct_chat_model


File: source/lambda/chat/clients/__init__.py
Summary of __init__.py:


File: source/lambda/chat/clients/llm_chat_client.py
Summary of llm_chat_client.py:
- Class: LLMChatClient
- Function: __init__
- Function: builder
- Function: builder
- Function: llm_config
- Function: llm_config
- Function: rag_enabled
- Function: rag_enabled
- Function: connection_id
- Function: connection_id
- Function: check_env
- Function: __validate_user_id
- Function: __validate_event_body
- Function: __validate_user_query
- Function: __validate_event_prompt
- Function: check_event
- Function: get_llm_config
- Function: construct_chat_model
- Function: get_event_conversation_id
- Function: get_model


File: source/lambda/chat/clients/anthropic_client.py
Summary of anthropic_client.py:
- Class: AnthropicClient
- Function: __init__
- Function: check_env
- Function: get_model


File: source/lambda/chat/clients/huggingface_client.py
Summary of huggingface_client.py:
- Class: HuggingFaceClient
- Function: __init__
- Function: check_env
- Function: get_model


File: source/lambda/chat/clients/builders/bedrock_builder.py
Summary of bedrock_builder.py:
- Class: BedrockBuilder
- Function: __init__
- Function: set_llm_model


File: source/lambda/chat/clients/builders/llm_builder.py
Summary of llm_builder.py:
- Class: LLMBuilder
- Function: __init__
- Function: llm_config
- Function: llm_config
- Function: is_streaming
- Function: is_streaming
- Function: conversation_memory
- Function: conversation_memory
- Function: knowledge_base
- Function: knowledge_base
- Function: callbacks
- Function: callbacks
- Function: llm_model
- Function: llm_model
- Function: api_key
- Function: api_key
- Function: errors
- Function: errors
- Function: model_params
- Function: model_params
- Function: rag_enabled
- Function: rag_enabled
- Function: connection_id
- Function: connection_id
- Function: conversation_id
- Function: conversation_id
- Function: model_defaults
- Function: memory_key
- Function: input_key
- Function: output_key
- Function: context_key
- Function: human_prefix
- Function: ai_prefix
- Function: set_model_defaults
- Function: validate_event_input_sizes
- Function: set_knowledge_base
- Function: set_conversation_memory
- Function: set_api_key
- Function: set_streaming_callbacks
- Function: set_llm_model


File: source/lambda/chat/clients/builders/anthropic_builder.py
Summary of anthropic_builder.py:
- Class: AnthropicBuilder
- Function: __init__
- Function: set_llm_model


File: source/lambda/chat/clients/builders/__init__.py
Summary of __init__.py:


File: source/lambda/chat/clients/builders/sagemaker_builder.py
Summary of sagemaker_builder.py:
- Class: SageMakerBuilder
- Function: __init__
- Function: set_llm_model


File: source/lambda/chat/clients/builders/huggingface_builder.py
Summary of huggingface_builder.py:
- Class: HuggingFaceBuilder
- Function: __init__
- Function: set_llm_model


File: source/lambda/chat/clients/factories/knowledge_base_factory.py
Summary of knowledge_base_factory.py:
- Class: KnowledgeBaseFactory
- Function: get_knowledge_base


File: source/lambda/chat/clients/factories/__init__.py
Summary of __init__.py:


File: source/lambda/chat/clients/factories/conversation_memory_factory.py
Summary of conversation_memory_factory.py:
- Class: ConversationMemoryFactory
- Function: get_conversation_memory


File: source/lambda/chat/test/conftest.py
Summary of conftest.py:
- Function: context
- Function: ssm
- Function: kendra_stubber
- Function: dynamodb_resource
- Function: secretsmanager
- Function: apigateway_stubber
- Function: ssm_stubber
- Function: bedrock_stubber
- Function: sagemaker_stubber
- Function: setup_environment
- Function: setup_bedrock_environment
- Function: setup_secret
- Function: chat_event
- Function: llm_config
- Function: bedrock_llm_config
- Function: sagemaker_llm_config
- Function: dynamodb_defaults_table
- Function: huggingface_dynamodb_defaults_table
- Function: huggingface_endpoint_dynamodb_defaults_table
- Function: anthropic_dynamodb_defaults_table
- Function: bedrock_dynamodb_defaults_table
- Function: sagemaker_dynamodb_defaults_table


File: source/lambda/chat/test/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/clients/test_anthropic_client.py
Summary of test_anthropic_client.py:
- Function: llm_client
- Function: test_get_model
- Function: test_construct_chat_model1


File: source/lambda/chat/test/clients/test_huggingface_client.py
Summary of test_huggingface_client.py:
- Function: llm_client
- Function: test_parent_get_llm_config
- Function: test_construct_chat_model1


File: source/lambda/chat/test/clients/test_llm_chat_client.py
Summary of test_llm_chat_client.py:
- Function: simple_llm_client
- Function: llm_client
- Function: test_no_body
- Function: test_empty_body
- Function: test_missing_user_id
- Function: test_body_missing_required_fields
- Function: test_prompt_valid_length
- Function: test_empty_prompt
- Function: test_empty_question
- Function: test_multiple_length_issues
- Function: test_get_event_conversation_id
- Function: test_env_not_set
- Function: test_env_set
- Function: test_parent_get_llm_config
- Function: test_parent_get_llm_config_missing_env
- Function: test_parent_get_llm_config_parameter_not_found
- Function: test_parent_get_llm_config_client_exceptions
- Function: test_construct_chat_model_failure
- Function: test_construct_chat_model_missing_params
- Function: test_construct_chat_model_new_prompt


File: source/lambda/chat/test/clients/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/clients/test_sagemaker_client.py
Summary of test_sagemaker_client.py:
- Function: llm_client
- Function: test_get_model
- Function: test_construct_chat_model1


File: source/lambda/chat/test/clients/test_bedrock_client.py
Summary of test_bedrock_client.py:
- Function: llm_client
- Function: test_get_model
- Function: test_construct_chat_model1


File: source/lambda/chat/test/clients/builders/test_sagemaker_builder.py
Summary of test_sagemaker_builder.py:
- Function: test_set_llm_model
- Function: test_set_llm_model_throws_error_missing_memory
- Function: test_set_llm_model_with_errors
- Function: test_set_llm_model_with_missing_config_fields
- Function: test_returned_sagemaker_model


File: source/lambda/chat/test/clients/builders/test_llm_builder.py
Summary of test_llm_builder.py:
- Function: test_knowledge_base_builder
- Function: test_conversation_memory_builder
- Function: test_api_key_builder


File: source/lambda/chat/test/clients/builders/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/clients/builders/test_huggingface_builder.py
Summary of test_huggingface_builder.py:
- Function: test_set_llm_model
- Function: test_set_llm_model_with_errors
- Function: test_set_llm_model_with_missing_config_fields
- Function: test_set_llm_model_with_missing_config_fields
- Function: test_returned_huggingface_model


File: source/lambda/chat/test/clients/builders/test_anthropic_builder.py
Summary of test_anthropic_builder.py:
- Function: test_set_llm_model
- Function: test_set_llm_model_throws_error_missing_memory
- Function: test_set_llm_model_with_errors
- Function: test_set_llm_model_with_missing_config_fields
- Function: test_returned_anthropic_model


File: source/lambda/chat/test/clients/builders/test_bedrock_builder.py
Summary of test_bedrock_builder.py:
- Function: test_set_llm_model
- Function: test_set_llm_model_throws_error_missing_memory
- Function: test_set_llm_model_with_errors
- Function: test_set_llm_model_with_missing_config_fields
- Function: test_returned_bedrock_model


File: source/lambda/chat/test/clients/factories/test_conversation_memory_factory.py
Summary of test_conversation_memory_factory.py:
- Function: test_get_ddb_memory_success
- Function: test_get_ddb_memory_error
- Function: test_get_ddb_memory_missing_table_name
- Function: test_get_ddb_memory_missing_memory_type


File: source/lambda/chat/test/clients/factories/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/clients/factories/test_knowledge_base_factory.py
Summary of test_knowledge_base_factory.py:
- Function: test_get_kb_memory_success
- Function: test_unsupported_kb
- Function: test_get_kb_missing_kendra_index
- Function: test_get_kb_missing_config
- Function: test_get_kb_missing_type


File: source/lambda/chat/test/utils/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/utils/test_helpers.py
Summary of test_helpers.py:
- Function: test_validate_prompt_template_valid
- Function: test_validate_prompt_template_invalid
- Function: test_validate_prompt_template_valid
- Function: test_valid_type_casting
- Function: test_invalid_casting
- Function: test_count_keys
- Function: test_dict_pop_null_values


File: source/lambda/chat/test/shared/memory/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/shared/memory/test_ddb_chat_memory.py
Summary of test_ddb_chat_memory.py:
- Function: test_init
- Function: test_load_memory_variables_with_none
- Function: test_load_memory_variables


File: source/lambda/chat/test/shared/memory/test_ddb_enhanced_chat_message_history.py
Summary of test_ddb_enhanced_chat_message_history.py:
- Function: setup_test_table
- Function: test_add_message
- Function: test_add_message_with_ttl_env_var
- Function: test_adding_multiple_messages
- Function: test_getting_different_messages_for_different_conversations
- Function: test_instances_with_same_user_conversation_are_equal
- Function: test_works_with_existing_ddb
- Function: test_no_messages
- Function: test_clear
- Function: test_get_message_generic_error
- Function: test_get_message_no_resource_error
- Function: test_add_message_error
- Function: test_clear_error


File: source/lambda/chat/test/shared/defaults/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/shared/defaults/test_model_defaults.py
Summary of test_model_defaults.py:
- Function: test_model_defaults_success
- Function: test_model_defaults_failure
- Function: test_model_defaults_missing_values


File: source/lambda/chat/test/shared/knowledge/mock_kendra_response.json

File: source/lambda/chat/test/shared/knowledge/test_kendra_knowledge_base.py
Summary of test_kendra_knowledge_base.py:
- Function: test_knowledge_base_construction_fails
- Function: test_knowledge_base_construction


File: source/lambda/chat/test/shared/knowledge/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/shared/knowledge/test_kendra_retriever.py
Summary of test_kendra_retriever.py:
- Function: kendra_retriever
- Function: get_kendra_result_stubbed
- Function: load_kendra_response
- Function: kendra_query_expected_response
- Function: test_kendra_retriever
- Function: test_kendra_query
- Function: test_get_relevant_documents
- Function: test_kendra_throws_client_error


File: source/lambda/chat/test/llms/test_anthropic.py
Summary of test_anthropic.py:
- Function: streamless_chat
- Function: streaming_chat
- Function: temp_anthropic_dynamodb_defaults_table
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_model_get_clean_model_params
- Function: test_model_default_stop_sequences
- Function: test_exception_for_failed_model_incorrect_key


File: source/lambda/chat/test/llms/test_sagemaker.py
Summary of test_sagemaker.py:
- Function: streamless_chat
- Function: streaming_chat
- Function: test_missing_values
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_exception_for_failed_model_response
- Function: test_model_get_clean_model_params
- Function: test_clean_model_endpoint_args


File: source/lambda/chat/test/llms/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/test_bedrock.py
Summary of test_bedrock.py:
- Function: streamless_chat
- Function: streaming_chat
- Function: temp_bedrock_dynamodb_defaults_table
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_exception_for_failed_model_response
- Function: test_model_get_clean_model_params
- Function: test_model_default_stop_sequences
- Function: test_guardrails
- Function: test_bedrock_get_llm_class
- Function: test_bedrock_get_llm_class_no_env


File: source/lambda/chat/test/llms/test_huggingface.py
Summary of test_huggingface.py:
- Function: chat
- Function: inference_chat
- Function: temp_huggingface_dynamodb_defaults_table
- Function: test_implement_error_not_raised
- Function: test_inference_error_not_raised
- Function: test_exception_for_failed_model_incorrect_repo
- Function: test_huggingface_model_api_error
- Function: test_huggingface_inference_api_error
- Function: test_generate_huggingface
- Function: test_exception_in_generate
- Function: test_model_get_clean_model_params
- Function: test_endpoint_get_clean_model_params
- Function: test_model_default_stop_sequences
- Function: test_endpoint_default_stop_sequences
- Class: MockConversationChainClass
- Function: predict


File: source/lambda/chat/test/llms/test_base_langchain.py
Summary of test_base_langchain.py:
- Function: chat
- Function: rag_chat
- Function: test_placeholder_replacements
- Function: test_get_validated_prompt
- Function: test_get_clean_model_params_success


File: source/lambda/chat/test/llms/models/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/models/bedrock_params/test_anthropic.py
Summary of test_anthropic.py:
- Function: test_anthropic_params_dataclass_success
- Function: test_anthropic_v3_params_dataclass_success
- Function: test_anthropic_get_params_as_dict
- Function: test_anthropic_incorrect_params


File: source/lambda/chat/test/llms/models/bedrock_params/test_cohere.py
Summary of test_cohere.py:
- Function: test_cohere_params_dataclass_success
- Function: test_cohere_get_params_as_dict
- Function: test_cohere_incorrect_params


File: source/lambda/chat/test/llms/models/bedrock_params/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/models/bedrock_params/test_amazon.py
Summary of test_amazon.py:
- Function: test_amazon_params_dataclass_success
- Function: test_amazon_get_params_as_dict
- Function: test_amazon_incorrect_params


File: source/lambda/chat/test/llms/models/bedrock_params/test_meta.py
Summary of test_meta.py:
- Function: test_meta_params_dataclass_success
- Function: test_meta_get_params_as_dict
- Function: test_meta_incorrect_params


File: source/lambda/chat/test/llms/models/bedrock_params/test_ai21.py
Summary of test_ai21.py:
- Function: test_ai21_params_dataclass_success
- Function: test_ai21_get_params_as_dict
- Function: test_ai21_incorrect_params


File: source/lambda/chat/test/llms/models/sagemaker/test_content_handler.py
Summary of test_content_handler.py:
- Function: test_replace_placeholders
- Function: test_transform_input
- Function: test_transform_output
- Function: test_transform_output_raises


File: source/lambda/chat/test/llms/models/sagemaker/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/rag/test_bedrock_retrieval.py
Summary of test_bedrock_retrieval.py:
- Function: llm_params
- Function: titan_model
- Function: temp_bedrock_dynamodb_defaults_table
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_exception_for_failed_model_incorrect_key
- Function: test_bedrock_model_variation
- Function: test_guardrails


File: source/lambda/chat/test/llms/rag/test_huggingface_retrieval.py
Summary of test_huggingface_retrieval.py:
- Function: knowledge_base
- Function: llm_params
- Function: streamless_huggingface_model
- Function: streamless_huggingface_endpoint
- Function: test_implement_error_not_raised
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_exception_for_failed_model_incorrect_api_key
- Function: test_exception_for_failed_endpoint_incorrect_api_key
- Class: MockConversationChainClass
- Function: invoke


File: source/lambda/chat/test/llms/rag/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/rag/test_anthropic_retrieval.py
Summary of test_anthropic_retrieval.py:
- Function: llm_params
- Function: anthropic_model
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_exception_for_failed_model_incorrect_key


File: source/lambda/chat/test/llms/rag/test_sagemaker_retrieval.py
Summary of test_sagemaker_retrieval.py:
- Function: llm_params
- Function: sagemaker_model
- Function: temp_sagemaker_dynamodb_defaults_table
- Function: test_implement_error_not_raised
- Function: test_generate
- Function: test_generate_error


File: source/lambda/chat/test/llms/factories/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/llms/factories/test_bedrock_params_factory.py
Summary of test_bedrock_params_factory.py:
- Function: test_sanitizer_passes
- Function: test_sanitizer_fails


File: source/lambda/chat/test/handlers/test_huggingface_handler.py
Summary of test_huggingface_handler.py:
- Function: test_huggingface_chat_handler
- Function: test_huggingface_chat_handler_empty_conversation
- Function: test_missing_llm_config_key


File: source/lambda/chat/test/handlers/test_anthropic_handler.py
Summary of test_anthropic_handler.py:
- Function: test_anthropic_chat_handler
- Function: test_anthropic_chat_handler_empty_conversation
- Function: test_missing_llm_config_key


File: source/lambda/chat/test/handlers/test_bedrock_handler.py
Summary of test_bedrock_handler.py:
- Function: test_bedrock_chat_handler
- Function: test_bedrock_chat_handler_empty_conversation
- Function: test_missing_llm_config_key


File: source/lambda/chat/test/handlers/__init__.py
Summary of __init__.py:


File: source/lambda/chat/test/handlers/test_sagemaker_handler.py
Summary of test_sagemaker_handler.py:
- Function: test_sagemaker_chat_handler
- Function: test_sagemaker_chat_handler_empty_conversation
- Function: test_missing_llm_config_key


File: source/lambda/chat/utils/constants.py
Summary of constants.py:


File: source/lambda/chat/utils/__init__.py
Summary of __init__.py:


File: source/lambda/chat/utils/custom_exceptions.py
Summary of custom_exceptions.py:
- Class: LLMBuildError
- Class: LLMInvocationError


File: source/lambda/chat/utils/enum_types.py
Summary of enum_types.py:
- Class: KnowledgeBaseTypes
- Class: ConversationMemoryTypes
- Class: LLMProviderTypes
- Class: BedrockModelProviders
- Class: CloudWatchNamespaces
- Class: CloudWatchMetrics


File: source/lambda/chat/utils/helpers.py
Summary of helpers.py:
- Function: get_metrics_client
- Function: type_cast
- Function: validate_prompt_placeholders
- Function: format_lambda_response
- Function: enforce_stop_tokens
- Function: count_keys
- Function: pop_null_values


File: source/lambda/chat/utils/handler_response_formatter.py
Summary of handler_response_formatter.py:
- Function: format_response


File: source/lambda/chat/shared/__init__.py
Summary of __init__.py:


File: source/lambda/chat/shared/memory/ddb_enhanced_message_history.py
Summary of ddb_enhanced_message_history.py:
- Class: DynamoDBChatMessageHistory
- Function: __init__
- Function: messages
- Function: add_message
- Function: clear


File: source/lambda/chat/shared/memory/ddb_chat_memory.py
Summary of ddb_chat_memory.py:
- Class: DynamoDBChatMemory
- Function: __init__
- Function: buffer
- Function: load_memory_variables
- Function: memory_variables
- Function: _get_input_output


File: source/lambda/chat/shared/memory/__init__.py
Summary of __init__.py:


File: source/lambda/chat/shared/callbacks/websocket_handler.py
Summary of websocket_handler.py:
- Class: WebsocketHandler
- Function: __init__
- Function: connection_id
- Function: conversation_id
- Function: client
- Function: connection_url
- Function: source_documents_formatter
- Function: send_references
- Function: post_token_to_connection
- Function: post_response_to_connection
- Function: format_response


File: source/lambda/chat/shared/callbacks/__init__.py
Summary of __init__.py:


File: source/lambda/chat/shared/callbacks/websocket_error_handler.py
Summary of websocket_error_handler.py:
- Class: WebsocketErrorHandler
- Function: __init__
- Function: connection_url
- Function: trace_id
- Function: trace_id
- Function: client
- Function: connection_id
- Function: post_token_to_connection
- Function: format_response


File: source/lambda/chat/shared/callbacks/websocket_streaming_handler.py
Summary of websocket_streaming_handler.py:
- Class: WebsocketStreamingCallbackHandler
- Function: __init__
- Function: is_streaming
- Function: connection_id
- Function: connection_url
- Function: conversation_id
- Function: client
- Function: source_documents_formatter
- Function: on_chat_model_start
- Function: post_token_to_connection
- Function: on_llm_new_token
- Function: send_references
- Function: on_chain_end
- Function: on_llm_error
- Function: format_response


File: source/lambda/chat/shared/defaults/model_defaults.py
Summary of model_defaults.py:
- Class: ModelDefaults
- Function: __init__
- Function: set_model_defaults


File: source/lambda/chat/shared/defaults/__init__.py
Summary of __init__.py:


File: source/lambda/chat/shared/knowledge/knowledge_base.py
Summary of knowledge_base.py:
- Class: KnowledgeBase
- Function: retriever
- Function: retriever
- Function: source_docs_formatter


File: source/lambda/chat/shared/knowledge/__init__.py
Summary of __init__.py:


File: source/lambda/chat/shared/knowledge/kendra_retriever.py
Summary of kendra_retriever.py:
- Class: CustomKendraRetriever
- Function: __init__
- Function: _get_relevant_documents
- Function: _kendra_query
- Function: _get_clean_docs


File: source/lambda/chat/shared/knowledge/kendra_knowledge_base.py
Summary of kendra_knowledge_base.py:
- Class: KendraKnowledgeBase
- Function: __init__
- Function: _check_env_variables
- Function: source_docs_formatter


File: source/lambda/chat/llms/base_langchain.py
Summary of base_langchain.py:
- Class: BaseLangChainModel
- Function: __init__
- Function: api_token
- Function: api_token
- Function: streaming
- Function: streaming
- Function: verbose
- Function: verbose
- Function: conversation_chain
- Function: conversation_chain
- Function: prompt
- Function: memory_buffer
- Function: conversation_memory
- Function: conversation_memory
- Function: knowledge_base
- Function: knowledge_base
- Function: model_params
- Function: model_params
- Function: temperature
- Function: temperature
- Function: model
- Function: model
- Function: llm
- Function: llm
- Function: stop_sequences
- Function: stop_sequences
- Function: prompt_template
- Function: prompt_template
- Function: prompt_template_placeholders
- Function: callbacks
- Function: callbacks
- Function: rag_enabled
- Function: rag_enabled
- Function: prompt
- Function: memory_buffer
- Function: get_conversation_chain
- Function: generate
- Function: get_validated_prompt
- Function: get_clean_model_params
- Function: get_llm


File: source/lambda/chat/llms/__init__.py
Summary of __init__.py:


File: source/lambda/chat/llms/sagemaker.py
Summary of sagemaker.py:
- Class: SageMakerLLM
- Function: __init__
- Function: sagemaker_endpoint_name
- Function: sagemaker_endpoint_name
- Function: input_schema
- Function: response_jsonpath
- Function: endpoint_params
- Function: get_llm
- Function: generate
- Function: get_clean_params


File: source/lambda/chat/llms/huggingface.py
Summary of huggingface.py:
- Class: HuggingFaceLLM
- Function: __init__
- Function: inference_endpoint
- Function: inference_endpoint
- Function: get_llm
- Function: generate
- Function: get_clean_model_params


File: source/lambda/chat/llms/anthropic.py
Summary of anthropic.py:
- Class: AnthropicLLM
- Function: __init__
- Function: get_llm
- Function: generate
- Function: get_clean_model_params


File: source/lambda/chat/llms/bedrock.py
Summary of bedrock.py:
- Class: BedrockLLM
- Function: __init__
- Function: model_family
- Function: model_family
- Function: get_llm
- Function: generate
- Function: get_clean_model_params


File: source/lambda/chat/llms/models/__init__.py
Summary of __init__.py:


File: source/lambda/chat/llms/models/llm.py
Summary of llm.py:
- Class: LLM
- Function: __post_init__


File: source/lambda/chat/llms/models/custom_chat_anthropic.py
Summary of custom_chat_anthropic.py:
- Class: CustomChatAnthropic
- Function: _default_params


File: source/lambda/chat/llms/models/llm_params.py
Summary of llm_params.py:
- Class: LLMParams
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/bedrock_params/mistral.py
Summary of mistral.py:
- Class: BedrockMistralLLMParams
- Function: __post_init__
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/bedrock_params/__init__.py
Summary of __init__.py:


File: source/lambda/chat/llms/models/bedrock_params/llm.py
Summary of llm.py:
- Class: BedrockLLMParams
- Function: cleanup


File: source/lambda/chat/llms/models/bedrock_params/anthropic.py
Summary of anthropic.py:
- Class: BedrockAnthropicLLMParams
- Class: BedrockAnthropicV1LLMParams
- Class: BedrockAnthropicV3LLMParams
- Function: __post_init__
- Function: get_params_as_dict
- Function: __post_init__
- Function: __post_init__


File: source/lambda/chat/llms/models/bedrock_params/ai21.py
Summary of ai21.py:
- Class: BedrockAI21LLMParams
- Function: __post_init__
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/bedrock_params/cohere.py
Summary of cohere.py:
- Class: BedrockCohereLLMParams
- Function: __post_init__
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/bedrock_params/amazon.py
Summary of amazon.py:
- Class: BedrockAmazonLLMParams
- Function: __post_init__
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/bedrock_params/meta.py
Summary of meta.py:
- Class: BedrockMetaLLMParams
- Function: __post_init__
- Function: get_params_as_dict


File: source/lambda/chat/llms/models/sagemaker/__init__.py
Summary of __init__.py:


File: source/lambda/chat/llms/models/sagemaker/content_handler.py
Summary of content_handler.py:
- Class: SageMakerContentHandler
- Function: __init__
- Function: transform_input
- Function: transform_output
- Function: replace_placeholders


File: source/lambda/chat/llms/rag/__init__.py
Summary of __init__.py:


File: source/lambda/chat/llms/rag/bedrock_retrieval.py
Summary of bedrock_retrieval.py:
- Class: BedrockRetrievalLLM
- Function: __init__
- Function: condensing_prompt_template
- Function: return_source_docs
- Function: get_conversation_chain
- Function: generate


File: source/lambda/chat/llms/rag/sagemaker_retrieval.py
Summary of sagemaker_retrieval.py:
- Class: SageMakerRetrievalLLM
- Function: __init__
- Function: condensing_prompt_template
- Function: return_source_docs
- Function: get_conversation_chain
- Function: generate


File: source/lambda/chat/llms/rag/huggingface_retrieval.py
Summary of huggingface_retrieval.py:
- Class: HuggingFaceRetrievalLLM
- Function: __init__
- Function: condensing_prompt_template
- Function: return_source_docs
- Function: get_conversation_chain
- Function: generate


File: source/lambda/chat/llms/rag/anthropic_retrieval.py
Summary of anthropic_retrieval.py:
- Class: AnthropicRetrievalLLM
- Function: __init__
- Function: condensing_prompt_template
- Function: return_source_docs
- Function: get_conversation_chain
- Function: generate


File: source/lambda/chat/llms/factories/bedrock_adapter_factory.py
Summary of bedrock_adapter_factory.py:
- Class: BedrockAdapterFactory
- Function: __init__
- Function: model_map
- Function: get_bedrock_adapter


File: source/lambda/chat/llms/factories/__init__.py
Summary of __init__.py:


File: source/lambda/custom-authorizer/jest.config.js

File: source/lambda/custom-authorizer/rest-authorizer.ts

File: source/lambda/custom-authorizer/.gitignore

File: source/lambda/custom-authorizer/package-lock.json

File: source/lambda/custom-authorizer/package.json

File: source/lambda/custom-authorizer/tsconfig.json

File: source/lambda/custom-authorizer/websocket-authorizer.ts

File: source/lambda/custom-authorizer/test/jest-environment-variables.ts

File: source/lambda/custom-authorizer/test/get-policy.test.ts

File: source/lambda/custom-authorizer/test/authorizer.test.ts

File: source/lambda/custom-authorizer/test/event-test-data.ts

File: source/lambda/custom-authorizer/utils/get-policy.ts

File: source/lambda/custom-resource/cfn_response.py
Summary of cfn_response.py:
- Function: send_response


File: source/lambda/custom-resource/lambda_ops_metrics.py
Summary of lambda_ops_metrics.py:
- Function: handler


File: source/lambda/custom-resource/pyproject.toml

File: source/lambda/custom-resource/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/.coveragerc

File: source/lambda/custom-resource/lambda_func.py
Summary of lambda_func.py:
- Class: UnSupportedOperationTypeException
- Function: get_function_for_resource
- Function: handler


File: source/lambda/custom-resource/.gitignore

File: source/lambda/custom-resource/poetry.lock

File: source/lambda/custom-resource/test/conftest.py
Summary of conftest.py:
- Function: aws_credentials
- Function: s3
- Function: ddb
- Function: cw_logs
- Function: ssm
- Function: secretsmanager
- Function: custom_resource_event
- Function: mock_lambda_context
- Function: reset_metric_set
- Class: FakeLambdaContext
- Function: __init__


File: source/lambda/custom-resource/test/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/test/test_lambda_func.py
Summary of test_lambda_func.py:
- Function: patch_powertools
- Function: test_get_function_for_operation
- Function: test_handler_for_success
- Function: test_handler_for_error
- Function: test_get_function_for_operation


File: source/lambda/custom-resource/test/test_lambda_ops_metrics.py
Summary of test_lambda_ops_metrics.py:
- Function: test_lambda_handler_success
- Function: test_lambda_handler_on_exception


File: source/lambda/custom-resource/test/utils/test_metrics.py
Summary of test_metrics.py:
- Function: test_when_env_variables_set
- Function: test_when_solution_version_not_set
- Function: test_when_solution_id_not_set
- Function: test_sending_cw_metrics
- Function: test_sending_cw_metrics_raises


File: source/lambda/custom-resource/test/utils/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/test/utils/test_lambda_context_parser.py
Summary of test_lambda_context_parser.py:
- Function: test_get_invocation_account_id


File: source/lambda/custom-resource/test/utils/test_metrics_payload.py
Summary of test_metrics_payload.py:
- Function: cw_stub
- Function: metric_responses
- Function: setup_metrics_environment
- Function: get_metric_data_stubbed
- Function: test_publish_metrics_success
- Function: test_publish_metrics_success_kendra_missing
- Function: test_publish_metrics_raises


File: source/lambda/custom-resource/test/operations/test_shared.py
Summary of test_shared.py:
- Function: test_get_zip_archive
- Function: test_get_archive_errors_for_wrong_prefix
- Function: test_with_bad_zip_file


File: source/lambda/custom-resource/test/operations/test_copy_web_ui.py
Summary of test_copy_web_ui.py:
- Function: test_verify_env_setup_success
- Function: test_evn_setup_with_resource_props_wrong_value
- Function: test_evn_setup_with_resource_props_empty
- Function: test_evn_with_missing_source_bucket
- Function: test_evn_with_missing_destination_bucket
- Function: test_evn_with_source_bucket_str_empty
- Function: test_env_with_destination_bucket_str_empty
- Function: test_env_with_missing_ssm_param_key
- Function: test_env_with_non_existing_ssm_param_key
- Function: test_get_params_succes
- Function: test_get_params_failure
- Function: test_execute_call_success
- Function: test_execute_call_with_bad_archive
- Function: test_execute_call_with_wrong_source_bucket
- Function: test_execute_call_with_wrong_destination_bucket
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/operations/test_use_case_policy.py
Summary of test_use_case_policy.py:
- Function: test_when_operation_type_is_invalid
- Function: test_when_resource_properties_missing
- Function: test_create_with_no_admin_group
- Function: test_create_with_existing_admin_group
- Function: test_create_where_group_exists
- Function: test_create_fails
- Function: test_delete
- Function: test_delete_with_no_admin_group
- Function: test_delete_with_no_table_fails_but_continues
- Function: test_delete_fails
- Function: test_execute_method
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/operations/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/test/operations/test_admin_policy.py
Summary of test_admin_policy.py:
- Function: test_when_operation_type_is_invalid
- Function: test_when_resource_properties_missing
- Function: test_create_with_no_admin_group
- Function: test_create_with_existing_admin_group
- Function: test_create_fails
- Function: test_delete
- Function: test_delete_fails
- Function: test_execute_method
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/operations/test_copy_model_info_to_ddb.py
Summary of test_copy_model_info_to_ddb.py:
- Function: test_verify_env_setup_success
- Function: test_verify_when_ddb_table_missing
- Function: test_verify_when_source_bucket_missing
- Function: test_verify_when_source_prefix_missing
- Function: test_create_success
- Function: test_create_with_incorrect_table_name
- Function: test_create_with_bad_zip_file
- Function: test_execute_call_success
- Function: test_execute_with_missing_resource_properties
- Function: test_execute_delete_event_succesful_with_missing_properties
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/operations/test_anonymous_metric.py
Summary of test_anonymous_metric.py:
- Function: setup_ssm
- Function: test_when_operation_type_is_invalid
- Function: test_sending_metric
- Function: test_sending_metric_missing_props
- Function: test_sanitize_method
- Function: test_lambda_handler
- Function: test_lambda_handler_for_missing_props


File: source/lambda/custom-resource/test/operations/test_update_s3_policy.py
Summary of test_update_s3_policy.py:
- Function: test_execute_success
- Function: test_execute_with_non_matching_policy
- Function: test_execute_with_matching_policy
- Function: test_execute_with_policy_for_different_prefix
- Function: test_execute_delete
- Function: test_verify_env_setup_success
- Function: test_verify_env_setup_failure
- Function: test_create_success


File: source/lambda/custom-resource/test/operations/test_gen_uuid.py
Summary of test_gen_uuid.py:
- Function: test_regex
- Function: test_gen_uuid_success
- Function: test_gen_uuid_success
- Function: test_when_uuid_fails
- Function: test_when_operation_type_is_invalid
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/operations/test_copy_api_key.py
Summary of test_copy_api_key.py:
- Function: test_verify_env_setup_success
- Function: test_env_setup_with_no_api_key
- Function: test_env_setup_with_no_secret_name
- Function: test_create_failure
- Function: test_create_success
- Function: test_create_success_when_existing
- Function: test_delete_failure
- Function: test_delete_success
- Function: test_execute_create_and_update
- Function: test_execute_delete
- Function: test_execute_failure


File: source/lambda/custom-resource/test/operations/test_webconfig.py
Summary of test_webconfig.py:
- Function: test_verify_env_setup_success
- Function: test_env_setup_with_no_ssm_key
- Function: test_env_setup_with_no_api_endpoint
- Function: test_env_setup_with_no_usr_pool_id
- Function: test_env_setup_with_no_usr_pool_client_id
- Function: test_create_success
- Function: test_create_success_with_additional_config
- Function: test_create_success_with_additional_config_marking_internal_user
- Function: test_create_success_with_additional_config_marking_external_user
- Function: test_create_success_with_additional_config_empty
- Function: test_create_success_with_additional_config_empty_marking_internal_user
- Function: test_create_success_with_additional_config_empty_marking_external_user
- Function: test_delete_failure
- Function: test_delete_success
- Function: test_execute_create_and_update
- Function: test_execute_delete
- Function: test_execute_failure


File: source/lambda/custom-resource/test/operations/test_cw_loggroup_policy.py
Summary of test_cw_loggroup_policy.py:
- Function: test_when_operation_type_is_invalid
- Function: test_when_resource_properties_missing
- Function: test_create_log_policy_for_valid_principal
- Function: test_create_log_policy_for_invalid_principal
- Function: test_update_method
- Function: test_delete_method
- Function: test_delete_method_for_invalid_policy
- Function: test_create_method_for_succesful_creation
- Function: test_execute_method
- Function: test_lambda_handler


File: source/lambda/custom-resource/test/fixtures/cw_loggroup_policy_events.py
Summary of cw_loggroup_policy_events.py:
- Function: lambda_event


File: source/lambda/custom-resource/test/fixtures/copy_web_ui_events.py
Summary of copy_web_ui_events.py:
- Function: lambda_event
- Function: web_ui_copy_setup


File: source/lambda/custom-resource/test/fixtures/copy_model_info_events.py
Summary of copy_model_info_events.py:
- Function: copy_to_ddb_event
- Function: setup_model_info


File: source/lambda/custom-resource/test/fixtures/gen_uuid_events.py
Summary of gen_uuid_events.py:
- Function: lambda_event


File: source/lambda/custom-resource/test/fixtures/copy_api_key_events.py
Summary of copy_api_key_events.py:
- Function: lambda_event
- Function: setup_secretsmanager


File: source/lambda/custom-resource/test/fixtures/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/test/fixtures/use_case_policy_events.py
Summary of use_case_policy_events.py:
- Function: lambda_event
- Function: setup_ddb


File: source/lambda/custom-resource/test/fixtures/anonymous_metrics_events.py
Summary of anonymous_metrics_events.py:
- Function: lambda_events


File: source/lambda/custom-resource/test/fixtures/update_s3_policy_events.py
Summary of update_s3_policy_events.py:
- Function: lambda_event
- Function: s3_stub
- Function: put_public_access_block_as_false
- Function: put_public_access_block_as_true
- Function: s3_stub_success
- Function: s3_stub_existing_non_matching_policy
- Function: s3_stub_existing_policy
- Function: s3_stub_existing_policy_for_different_prefix


File: source/lambda/custom-resource/test/fixtures/admin_policy_events.py
Summary of admin_policy_events.py:
- Function: lambda_event
- Function: setup_ddb


File: source/lambda/custom-resource/test/fixtures/webconfig_events.py
Summary of webconfig_events.py:
- Function: lambda_event
- Function: lambda_event_with_additional_config
- Function: lambda_event_with_additional_config_internal_user
- Function: lambda_event_with_additional_config_external_user
- Function: setup_ssm


File: source/lambda/custom-resource/utils/metrics.py
Summary of metrics.py:
- Function: verify_env_setup
- Function: push_builder_metrics


File: source/lambda/custom-resource/utils/lambda_context_parser.py
Summary of lambda_context_parser.py:
- Function: get_invocation_account_id


File: source/lambda/custom-resource/utils/constants.py
Summary of constants.py:
- Class: CloudWatchNamespaces
- Class: CloudWatchMetrics


File: source/lambda/custom-resource/utils/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/utils/metrics_payload.py
Summary of metrics_payload.py:
- Function: get_cloudwatch_metrics_queries
- Function: get_metrics_payload


File: source/lambda/custom-resource/utils/data.py
Summary of data.py:
- Class: BuilderMetrics
- Function: __init__
- Function: __post_init__


File: source/lambda/custom-resource/operations/webconfig.py
Summary of webconfig.py:
- Function: verify_env_setup
- Function: get_additional_config_ssm_parameter
- Function: create
- Function: delete
- Function: execute


File: source/lambda/custom-resource/operations/operation_types.py
Summary of operation_types.py:


File: source/lambda/custom-resource/operations/cw_loggroup_policy.py
Summary of cw_loggroup_policy.py:
- Class: InvalidPrincipalException
- Function: verify_env_setup
- Function: create_loggroup_policy
- Function: create
- Function: update
- Function: delete
- Function: execute


File: source/lambda/custom-resource/operations/update_s3_policy.py
Summary of update_s3_policy.py:
- Function: create
- Function: verify_env_setup
- Function: execute


File: source/lambda/custom-resource/operations/copy_web_ui.py
Summary of copy_web_ui.py:
- Function: get_params
- Function: verify_env_setup
- Function: delete
- Function: create
- Function: execute


File: source/lambda/custom-resource/operations/__init__.py
Summary of __init__.py:


File: source/lambda/custom-resource/operations/copy_api_key.py
Summary of copy_api_key.py:
- Function: verify_env_setup
- Function: create
- Function: delete
- Function: execute


File: source/lambda/custom-resource/operations/shared.py
Summary of shared.py:
- Function: get_zip_archive


File: source/lambda/custom-resource/operations/admin_policy.py
Summary of admin_policy.py:
- Class: InvalidPrincipalException
- Function: verify_env_setup
- Function: create
- Function: delete
- Function: execute


File: source/lambda/custom-resource/operations/copy_model_info_to_ddb.py
Summary of copy_model_info_to_ddb.py:
- Function: verify_env_setup
- Function: create
- Function: execute


File: source/lambda/custom-resource/operations/anonymous_metrics.py
Summary of anonymous_metrics.py:
- Function: verify_env_setup
- Function: sanitize_data
- Function: get_additional_config_ssm_parameter
- Function: execute


File: source/lambda/custom-resource/operations/gen_uuid.py
Summary of gen_uuid.py:
- Function: verify_env_setup
- Function: execute


File: source/lambda/custom-resource/operations/use_case_policy.py
Summary of use_case_policy.py:
- Class: InvalidPrincipalException
- Function: verify_env_setup
- Function: create
- Function: _create_updated_admin_policy
- Function: delete
- Function: execute


File: source/lambda/reconcile-data/pyproject.toml

File: source/lambda/reconcile-data/.coveragerc

File: source/lambda/reconcile-data/lambda_func.py
Summary of lambda_func.py:
- Function: determine_operation
- Function: handler


File: source/lambda/reconcile-data/poetry.lock

File: source/lambda/reconcile-data/test/conftest.py
Summary of conftest.py:
- Function: aws_credentials
- Function: ssm
- Function: custom_resource_event
- Function: mock_lambda_context
- Class: FakeLambdaContext
- Function: __init__


File: source/lambda/reconcile-data/test/test_lambda_func.py
Summary of test_lambda_func.py:
- Function: init_ssm
- Function: test_handler
- Function: test_handler_with_diff_user_identity
- Function: test_when_operation_not_found


File: source/lambda/reconcile-data/test/operations/test_dynamodb_remove_case.py
Summary of test_dynamodb_remove_case.py:
- Function: test_reconcile
- Function: test_reconcile_failure_with_ssm
- Function: test_reconcile_with_parameter_name_missing_in_record


File: source/lambda/reconcile-data/test/fixtures/remove_case_event.py
Summary of remove_case_event.py:
- Function: ttl_remove_event


File: source/lambda/reconcile-data/exceptions/operation_not_found.py
Summary of operation_not_found.py:
- Class: OperationNotFoundException


File: source/lambda/reconcile-data/operations/operation_types.py
Summary of operation_types.py:


File: source/lambda/reconcile-data/operations/constants.py
Summary of constants.py:


File: source/lambda/reconcile-data/operations/dynamodb_remove_case.py
Summary of dynamodb_remove_case.py:
- Function: delete_ssm_parameter_key
- Function: reconcile


File: source/lambda/use-case-management/jest.config.js

File: source/lambda/use-case-management/power-tools-init.ts

File: source/lambda/use-case-management/package-lock.json

File: source/lambda/use-case-management/package.json

File: source/lambda/use-case-management/tsconfig.json

File: source/lambda/use-case-management/index.ts

File: source/lambda/use-case-management/command.ts

File: source/lambda/use-case-management/ssm/use-case-config-view-builder.ts

File: source/lambda/use-case-management/ssm/use-case-config-operation-builder.ts

File: source/lambda/use-case-management/ssm/config-management.ts

File: source/lambda/use-case-management/ssm/web-config-builder.ts

File: source/lambda/use-case-management/secretsmanager/secret-management.ts

File: source/lambda/use-case-management/secretsmanager/api-key-secret-operation-builder.ts

File: source/lambda/use-case-management/test/index.test.ts

File: source/lambda/use-case-management/test/command.test.ts

File: source/lambda/use-case-management/test/event-test-data.ts

File: source/lambda/use-case-management/test/ssm/config-management.test.ts

File: source/lambda/use-case-management/test/ssm/web-config-builder.test.ts

File: source/lambda/use-case-management/test/ssm/use-case-config-builder.test.ts

File: source/lambda/use-case-management/test/secretsmanager/api-key-secret-operation-builder.test.ts

File: source/lambda/use-case-management/test/secretsmanager/secret-management.test.ts

File: source/lambda/use-case-management/test/ddb/storage-management.test.ts

File: source/lambda/use-case-management/test/ddb/builder.test.ts

File: source/lambda/use-case-management/test/utils/http-response-formatter.test.ts

File: source/lambda/use-case-management/test/cfn/stack-operation-builder.test.ts

File: source/lambda/use-case-management/test/cfn/stack-management.test.ts

File: source/lambda/use-case-management/test/cfn/stack-view-builder.test.ts

File: source/lambda/use-case-management/test/model/use-case-validator.test.ts

File: source/lambda/use-case-management/test/model/list-use-cases.test.ts

File: source/lambda/use-case-management/test/model/use-case.test.ts

File: source/lambda/use-case-management/ddb/storage-view-builder.ts

File: source/lambda/use-case-management/ddb/storage-management.ts

File: source/lambda/use-case-management/ddb/storage-operation-builder.ts

File: source/lambda/use-case-management/utils/http-response-formatters.ts

File: source/lambda/use-case-management/utils/check-env.ts

File: source/lambda/use-case-management/utils/constants.ts

File: source/lambda/use-case-management/cfn/stack-operation-builder.ts

File: source/lambda/use-case-management/cfn/stack-view-builder.ts

File: source/lambda/use-case-management/cfn/stack-management.ts

File: source/lambda/use-case-management/model/use-case-validator.ts

File: source/lambda/use-case-management/model/list-use-cases.ts

File: source/lambda/use-case-management/model/use-case.ts

File: source/lambda/use-case-management/exception/missing-value-error.ts

File: source/infrastructure/jest.config.js

File: source/infrastructure/cdk.json

File: source/infrastructure/.gitignore

File: source/infrastructure/package-lock.json

File: source/infrastructure/package.json

File: source/infrastructure/tsconfig.json

File: source/infrastructure/test/bedrock-chat-stack.test.ts

File: source/infrastructure/test/sagemaker-chat-stack.test.ts

File: source/infrastructure/test/deployment-platform-stack.test.ts

File: source/infrastructure/test/anthropic-chat-stack.test.ts

File: source/infrastructure/test/hugging-face-chat-stack.test.ts

File: source/infrastructure/test/ui/ui-infrstructure.test.ts

File: source/infrastructure/test/layers/runtime-lib.test.ts

File: source/infrastructure/test/layers/python-user-agent.test.ts

File: source/infrastructure/test/layers/shared-lib.test.ts

File: source/infrastructure/test/layers/node-user-agent.test.ts

File: source/infrastructure/test/framework/application-setup.test.ts

File: source/infrastructure/test/framework/base-stack.test.ts

File: source/infrastructure/test/framework/use-case-stack.test.ts

File: source/infrastructure/test/framework/external-use-case-stack.test.ts

File: source/infrastructure/test/auth/deployment-platform-cognito-setup.test.ts

File: source/infrastructure/test/auth/use-case-cognito-setup.test.ts

File: source/infrastructure/test/mock-lambda-func/.gitignore

File: source/infrastructure/test/mock-lambda-func/python-lambda/pyproject.toml

File: source/infrastructure/test/mock-lambda-func/python-lambda/__init__.py
Summary of __init__.py:


File: source/infrastructure/test/mock-lambda-func/python-lambda/poetry.lock

File: source/infrastructure/test/mock-lambda-func/python-lambda/function.py
Summary of function.py:
- Function: handler


File: source/infrastructure/test/mock-lambda-func/typescript-lambda/.gitignore

File: source/infrastructure/test/mock-lambda-func/typescript-lambda/package-lock.json

File: source/infrastructure/test/mock-lambda-func/typescript-lambda/package.json

File: source/infrastructure/test/mock-lambda-func/typescript-lambda/tsconfig.json

File: source/infrastructure/test/mock-lambda-func/typescript-lambda/index.ts

File: source/infrastructure/test/mock-lambda-func/typescript-lambda/test/index.test.ts

File: source/infrastructure/test/mock-lambda-func/node-lambda/package-lock.json

File: source/infrastructure/test/mock-lambda-func/node-lambda/package.json

File: source/infrastructure/test/utils/lambda-runtimes.test.ts

File: source/infrastructure/test/utils/cfn-nag-suppressions.test.ts

File: source/infrastructure/test/utils/asset-bundling.test.ts

File: source/infrastructure/test/utils/solution-helper.test.ts

File: source/infrastructure/test/utils/lambda-aspect.test.ts

File: source/infrastructure/test/utils/custom-infra-setup.test.ts

File: source/infrastructure/test/utils/common-utils.test.ts

File: source/infrastructure/test/utils/app-registry.test.ts

File: source/infrastructure/test/storage/deployment-platform-storage-setup.test.ts

File: source/infrastructure/test/storage/deployment-platform-storage-stack.test.ts

File: source/infrastructure/test/storage/chat-storage-stack.test.ts

File: source/infrastructure/test/storage/chat-storage-setup.test.ts

File: source/infrastructure/test/storage/use-case-model-info-storage.test.ts

File: source/infrastructure/test/storage/deployment-platform-model-info-storage.test.ts

File: source/infrastructure/test/search/knowledge-base-setup.test.ts

File: source/infrastructure/test/search/kendra-knowledge-base.test.ts

File: source/infrastructure/test/mock-ui/.gitignore

File: source/infrastructure/test/mock-ui/package-lock.json

File: source/infrastructure/test/mock-ui/package.json

File: source/infrastructure/test/mock-ui/tsconfig.json

File: source/infrastructure/test/mock-ui/public/index.html

File: source/infrastructure/test/mock-ui/src/index.js

File: source/infrastructure/test/api/rest-request-processor.test.ts

File: source/infrastructure/test/api/deployment-platform-rest-endpoint.test.ts

File: source/infrastructure/test/api/websocket-request-processor.test.ts

File: source/infrastructure/test/api/websocket-endpoint.test.ts

File: source/infrastructure/test/vpc/external-vpc-params.test.ts

File: source/infrastructure/test/vpc/external-use-case-vpc.test.ts

File: source/infrastructure/test/vpc/vpc-setup.test.ts

File: source/infrastructure/test/vpc/custom-vpc.test.ts

File: source/infrastructure/test/vpc/deployment-platform-vpc.test.ts

File: source/infrastructure/test/vpc/use-case-custom-vpc.test.ts

File: source/infrastructure/test/vpc/bedrock-vpc.test.ts

File: source/infrastructure/test/vpc/first-party-use-case-vpc.test.ts

File: source/infrastructure/test/vpc/sagemaker-vpc.test.ts

File: source/infrastructure/test/use-case-management/management-stack.test.ts

File: source/infrastructure/test/s3web/ui-asset.test.ts

File: source/infrastructure/test/s3web/chat-use-case-ui-asset.test.ts

File: source/infrastructure/test/s3web/static-site.test.ts

File: source/infrastructure/bin/gen-ai-app-builder.ts

File: source/infrastructure/lib/bedrock-chat-stack.ts

File: source/infrastructure/lib/sagemaker-chat-stack.ts

File: source/infrastructure/lib/anthropic-chat-stack.ts

File: source/infrastructure/lib/hugging-face-chat-stack.ts

File: source/infrastructure/lib/deployment-platform-stack.ts

File: source/infrastructure/lib/metrics/custom-dashboard.ts

File: source/infrastructure/lib/metrics/use-case-dashboard.ts

File: source/infrastructure/lib/metrics/deployment-platform-dashboard.ts

File: source/infrastructure/lib/ui/ui-infrastructure.ts

File: source/infrastructure/lib/layers/shared-lib.ts

File: source/infrastructure/lib/layers/python-user-agent.ts

File: source/infrastructure/lib/layers/node-user-agent.ts

File: source/infrastructure/lib/layers/ts-user-agent.ts

File: source/infrastructure/lib/layers/runtime-libs.ts

File: source/infrastructure/lib/framework/base-stack.ts

File: source/infrastructure/lib/framework/use-case-stack.ts

File: source/infrastructure/lib/framework/ui-asset.ts

File: source/infrastructure/lib/framework/application-setup.ts

File: source/infrastructure/lib/framework/external-use-case-stack.ts

File: source/infrastructure/lib/auth/deployment-platform-cognito-setup.ts

File: source/infrastructure/lib/auth/cognito-setup.ts

File: source/infrastructure/lib/auth/use-case-cognito-setup.ts

File: source/infrastructure/lib/utils/cfn-nag-suppressions.ts

File: source/infrastructure/lib/utils/nested-stack-parameters.ts

File: source/infrastructure/lib/utils/app-registry-aspects.ts

File: source/infrastructure/lib/utils/custom-infra-setup.ts

File: source/infrastructure/lib/utils/lambda-runtimes.ts

File: source/infrastructure/lib/utils/lambda-aspect.ts

File: source/infrastructure/lib/utils/constants.ts

File: source/infrastructure/lib/utils/asset-bundling.ts

File: source/infrastructure/lib/utils/common-utils.ts

File: source/infrastructure/lib/utils/solution-helper.ts

File: source/infrastructure/lib/storage/chat-storage-stack.ts

File: source/infrastructure/lib/storage/rds-2-s3

File: source/infrastructure/lib/storage/chat-storage-setup.ts

File: source/infrastructure/lib/storage/deployment-platform-storage-setup.ts

File: source/infrastructure/lib/storage/deployment-platform-model-info-storage.ts

File: source/infrastructure/lib/storage/deployment-platform-storage-stack.ts

File: source/infrastructure/lib/storage/model-info-storage.ts

File: source/infrastructure/lib/storage/use-case-model-info-storage.ts

File: source/infrastructure/lib/search/kendra-knowledge-base.ts

File: source/infrastructure/lib/search/knowledge-base-setup.ts

File: source/infrastructure/lib/api/rest-request-processor.ts

File: source/infrastructure/lib/api/deployment-platform-rest-endpoint.ts

File: source/infrastructure/lib/api/websocket-request-processor.ts

File: source/infrastructure/lib/api/websocket-endpoint.ts

File: source/infrastructure/lib/api/model-schema/update-usecase-response.ts

File: source/infrastructure/lib/api/model-schema/deploy-usecase-body.ts

File: source/infrastructure/lib/api/model-schema/deploy-usecase-response.ts

File: source/infrastructure/lib/api/model-schema/update-usecase-body.ts

File: source/infrastructure/lib/vpc/vpc-setup.ts

File: source/infrastructure/lib/vpc/first-party-use-case-vpc.ts

File: source/infrastructure/lib/vpc/exisiting-vpc-params.ts

File: source/infrastructure/lib/vpc/deployment-platform-vpc.ts

File: source/infrastructure/lib/vpc/use-case-custom-vpc.ts

File: source/infrastructure/lib/vpc/custom-vpc.ts

File: source/infrastructure/lib/vpc/bedrock-vpc.ts

File: source/infrastructure/lib/vpc/external-use-case-vpc.ts

File: source/infrastructure/lib/vpc/sagemaker-vpc.ts

File: source/infrastructure/lib/use-case-management/setup.ts

File: source/infrastructure/lib/use-case-management/management-stack.ts

File: source/infrastructure/lib/s3web/deployment-platform-ui-asset.ts

File: source/infrastructure/lib/s3web/static-site.ts

File: source/infrastructure/lib/s3web/chat-use-case-ui-asset.ts

File: source/amazon-bedrock-samples-main/CODE_OF_CONDUCT.md

File: source/amazon-bedrock-samples-main/LICENSE

File: source/amazon-bedrock-samples-main/README.md
README Summary:
Amazon Bedrock Samples
This repository contains pre-built examples to help customers get started with the Amazon Bedrock service.
Contents
- Introduction to Bedrock - Learn the basics of the Bedrock service
- Prompt Engineering  - Tips for crafting effective prompts
- Bedrock Fine-tuning - Fine-tune Bedrock models for your specific use case
- Custom Model Import - Import custom models into Bedrock
- Generative AI Solutions - Example use cases for generative AI
- Knowledge Bases - Build knowledge bases with Bedrock
- Retrival Augmented Generation (RAG) - Implementing RAG with Amazon Bedrock
- Agents - Generative AI agents with Bedrock
- Security and Governance - Secure your Bedrock applications
- Responsible AI - Use Bedrock responsibly and ethically
- Operational Tooling - Helpful samples to help operationalize your useage of Amazon Bedrock
- Multimodal - Working with multimodal data using Amazon Bedrock
Getting Started
To get started with the code examples, ensure you have access to Amazon Bedrock. Then clone this repo and navigate to one of the folders above. Detailed instructions are provided in each folder's README.
Enable AWS IAM permissions for Bedrock
The AWS identity you assume from your environment (which is the *Studio/notebook Execution Role* from SageMaker, or could be a role or IAM User for self-managed notebooks or other use-cases), must have sufficient AWS IAM permissions to call the Amazon Bedrock service.
To grant Bedrock access to your identity, you can:
- Open the AWS IAM Console
- Find your Role (if using SageMaker or otherwise assuming an IAM Role), or else User
- Select *Add Permissions > Create Inline Policy* to attach new inline permissions, open the *JSON* editor and paste in the below example policy:
>  **Note:** With Amazon SageMaker, your notebook execution role will typically be *separate* from the user or role that you log in to the AWS Console with. If you'd like to explore the AWS Console for Amazon Bedrock, you'll need to grant permissions to your Console user/role too.
For more information on the fine-grained action and resource permissions in Bedrock, check out the Bedrock Developer Guide.
Contributing
We welcome community contributions! Please see CONTRIBUTING.md for guidelines.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/.gitignore

File: source/amazon-bedrock-samples-main/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/README.md
README Summary:
Fine Tuning
This folder contains examples related to Fine-tuning Bedrock Models
Contents
Fine-tuning Amazon Titan Image Generator G1 - example code for fine-tuning Amazon Titan Image Generator G1 model
Fine-tuning Meta Llama 2 for text summarization - example code for fine-tuning and evaluating a Meta Llama 2 foundation model for text summarization
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/README.md
README Summary:
Amazon Titan Image Generator Model Fine-tuning
Overview
This repository provides resources and notebooks for fine-tuning the Amazon Titan Image Generator Model with Amazon Bedrock. Amazon Titan lmage Generator is a cutting edge text-to-image model that is able to understand prompts describing multiple objects in various contexts and captures these relevant details in the images it generates. It can perform advanced image editing tasks such as smart cropping, in-painting, and background changes. However, users would like to adapt the model to unique characteristics in custom datasets that the model is not already trained on.
| Ron the dog| Smila the cat|
|---------|---------|
| <img src="data/ron_01.jpg" alt="Image 1" width="300"/> | <img src="data/smila_29.jpg" alt="Image 2" width="300"/> |
Notebooks
**1. Customize the model**
In the notebook **1-TIGFT-customization-job**, you will find step-by-step instructions on how to customize the Amazon Titan Image Generator model. You will learn how to prepare the training dataset and launch a fine-tuning job.
**2. Provision and test the customized model**
The notebook **2-TIGFT-provisioned-throughput-inference** guides you through the process of provisioning the fine-tuned model. You will compare base model results vs the customized model results.

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/1-TIGFT-customization-job.ipynb

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/2-TIGFT-provisioned-throughput-inference.ipynb

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/prompts/captions.json

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_07.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_13.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_12.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_06.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_10.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_04.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_05.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_11.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_15.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_01.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_29.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_28.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_14.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_02.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_16.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_17.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_03.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_14.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_28.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_29.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_15.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_01.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_17.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_03.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_02.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_16.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_12.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_06.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_ft_2.png

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_07.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_13.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_05.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_11.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_ft_1.png

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_10.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_04.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_21.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_09.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_08.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_20.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_22.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_23.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_27.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_ft_2.png

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_26.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_18.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_24.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_30.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_ft_1.png

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_25.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/ron_19.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_26.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_27.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_19.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_25.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_24.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_30.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_18.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_20.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_08.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_09.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_21.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_23.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/amazon-titan-image-generator/data/smila_22.jpg

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/meta-llama/README.md
README Summary:
Fine-Tuning Foundation Models with Amazon Bedrock
You can customize Foundation Models(FMs) on Bedrock through fine-tuning. We provide examples on how to set up the resources, fine-tune and evaluate the customized model, and clean up the resources after running the examples.
Contents
- 00_setup.ipynb - Setup for running customization notebooks both for fine-tuning and continued pre-training using Amazon Bedrock. In this notebook, we will create set of roles and an S3 bucket which will be used for other notebooks in this module.
- 02_fine-tune_and_evaluate_llama2_bedrock_summarization.ipynb - In this notebook, we build an end-to-end workflow for fine-tuning, provisioning and evaluating the Foundation Models (FMs) in Amazon Bedrock. We choose Meta Llama 2 13B as our FM to perform the customization through fine-tuning, we then create provisioned throughput of the fine-tuned model, test the provisioned model invocation, and finally evaluate the fine-tuned model performance using fmeval on the summarization accuracy metrics.
- 03_cleanup.ipynb - Clean up all the resources that you have created in the previous notebooks to avoid unnecessary cost associated with the resources.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/meta-llama/02_fine-tune_and_evaluate_llama2_bedrock_summarization.ipynb

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/meta-llama/00_setup.ipynb

File: source/amazon-bedrock-samples-main/bedrock-fine-tuning/meta-llama/03_cleanup.ipynb

File: source/amazon-bedrock-samples-main/function-calling/legacy-function-calling-with-Claude.ipynb

File: source/amazon-bedrock-samples-main/function-calling/create_athena_catalog.py
Summary of create_athena_catalog.py:


File: source/amazon-bedrock-samples-main/function-calling/advanced_fn_calling_w_claude3.ipynb

File: source/amazon-bedrock-samples-main/function-calling/Migrating_from_OAI_Bedrock_converse.ipynb

File: source/amazon-bedrock-samples-main/function-calling/tool_use_with_pydantic_Bedrock_converse.ipynb

File: source/amazon-bedrock-samples-main/function-calling/README.md
README Summary:
Function Calling
With function calling, we can provide LLMs with descriptions of tools and functions it can use. An LLM is able to intelligently decide based on user query when and how to use those tools to help answer questions and complete tasks.
This repository contains examples and use-cases to get you started with Function Calling on Amazon Bedrock
Contents
- **Amazon Bedrock Converse API function-calling (tool use) examples** - The Converse or ConverseStream API is a unified structured text API action that allows you simplifying the invocations to Bedrock LLMs, using a universal syntax and message structured prompts for any of the supported model providers, and adding support for tool use of function calling with a unified syntax. For more information check the documentation here and the API reference here.
- Function calling tool use with Converse API in Bedrock:
* Notebook
* Streamlit demo
- Extracting structured JSON with Converse API in Bedrock:
* Notebook - Email entity extraction
* Notebook - Adapted version of Anthropic's cookbook - Adapted by AWS from the original Anthropic's notebook available here.
- Tool use with Pydantic with Converse API in Bedrock:
* Notebook
* Script demo
- Function calling text2SQL with Converse API in Bedrock:
* Streamlit demo
- Function calling migrations with Converse API in Bedrock:
* Notebook
* Streamlit demo
- **Legacy function calling with Claude 3**
* Notebook - An introduction to function calling using Claude 3
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/function-calling/fc_pydantic_class_converse_bedrock.py
Summary of fc_pydantic_class_converse_bedrock.py:
- Function: bedrock_tool
- Class: ToolsList
- Function: converse_with_tools
- Function: converse
- Function: decorator
- Function: get_weather


File: source/amazon-bedrock-samples-main/function-calling/function_calling_text2SQL_converse_bedrock_streamlit.py
Summary of function_calling_text2SQL_converse_bedrock_streamlit.py:
- Class: ToolsList
- Function: converse_with_tools
- Function: converse
- Function: query_athena


File: source/amazon-bedrock-samples-main/function-calling/Extracting_structured_json_Bedrock_converse.ipynb

File: source/amazon-bedrock-samples-main/function-calling/fc_migrations_converse_bedrock_streamlit.py
Summary of fc_migrations_converse_bedrock_streamlit.py:
- Function: oai_call_to_bedrock_call
- Function: converse_with_tools


File: source/amazon-bedrock-samples-main/function-calling/Anthropic_cookbook_extracting_structured_json_Bedrock_converse.ipynb

File: source/amazon-bedrock-samples-main/function-calling/function_calling_converse_bedrock_streamlit.py
Summary of function_calling_converse_bedrock_streamlit.py:
- Class: ToolsList
- Class: ToolsList2
- Class: ToolsList3
- Function: converse_with_tools
- Function: converse
- Function: converse_image
- Function: get_weather
- Function: get_weather
- Function: get_weather
- Function: web_search


File: source/amazon-bedrock-samples-main/function-calling/Function_calling_tool_use_with_Converse_API.ipynb

File: source/amazon-bedrock-samples-main/function-calling/images/bedrock.png

File: source/amazon-bedrock-samples-main/function-calling/images/weather.jpg

File: source/amazon-bedrock-samples-main/function-calling/images/AWS_logo_RGB.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/README.md
README Summary:
Agents for Amazon Bedrock
Agents for Amazon Bedrock helps you accelerate the development of GenAI applications by orchestrating multistep tasks. Agents uses the reasoning capability of foundation models (FMs) to break down user-requested tasks into  steps. Agents for Amazon Bedrock can perform the following tasks:
- Breakdown user requests into multiple smaller steps
- Collect additional information from a user through natural conversation
- Decide which APIs to call and provide the necessary parameters for calling the APIs
- Take actions to fulfill a customer's request calling provided APIs
- Augment performance and accuracy by querying integrated Knowledge Bases
An agent consists of the following components:
1. **Foundation model**  You choose a foundation model that the agent invokes to interpret user input and subsequent prompts in its orchestration process, and to generate responses and follow-up steps in its process
2. **Instructions**  You author instructions that describe what the agent is designed to do
1. (Optional) With **Advanced Prompts** you can further customize instructions for the agent at every step of orchestration
1. With customized **Lambda Parser** functions you can parse the output of each orchestration step
3. (Optional) **Action groups**  You define the actions that the agent should carry out by providing the available APIs with
1. **Function Definition** where you specify functions and define parameters as JSON objects that will be associated to the action group invocation or,
1. **API Schema** file that defines the APIs that the agent can invoke to carry out its tasks resources
Additionally, you can define a Lambda function to execute API calls with the selected parameters
4. (Optional) **Knowledge bases**  Associate knowledge bases with an agent to allow it to retrieve context to augment response generation and input into orchestration steps
Contents
This repository contains examples and use-cases to get you started with Agents for Amazon Bedrock and its capabilities. It is organized in the following folders:
- **Use case examples**: examples of Agents in specific use cases, including:
1. Retail Agent with Bedrock Agents - Agent designed to help with retail transactions
1. Insurance Claim Lifecycle Automation Agent - Agent desided to help insurance employees working with claims
1. Text to SQL Agent - Agent designed to generate and execute SQL queries using natural language
1. Text to SQL  Agent CDK Enhanced - Agent designed to generate and execute SQL queries using natural language. This repository enhances the original Text to SQL Bedrock Agent with improvment on: using CDK, works with any dataset, wroks with super large answers.
1. Customer Relationship Management Agent - Agent designed to help sales employees work with their customers
1. [HR Vacation Agent] - Agent to manage employee vacation time
- **Feature examples**: examples of how to use specific features of Agents for Bedrock
1. Create Agent with Function Definition: Example of how to create an HR assistant agent defining the Action Group function and parameters as JSON object that is associated with the Action Group invocation. It connects with an AWS Lambda function to execute the actions
1. Create Agent with API Schema: Example of how to create an Insurance Claim's handler agent using an API schema for the functions and parameters definition. The API schema follows the OpenAPI Specificiation format and connects with an AWS Lambda function for the actions exection.
1. Create Agent with Return of Control: Example of how to create an HR assistant agent defining the Action Group function and parameters as JSON object that is associated with the Action Group invocation. It skips the AWS Lambda function definition to return the control to the user's application.
1. Create Agent with a Single Knowledge: Example of how to create a restaurant assistant agent that connects with a single Knowledge Base for Amazon Bedrock to find informations on the menus for adults and children.
1. Create Agent with Knowledge Base and Action Group: Example of how to create extend the Insurance Claim's handler to connect to a Knowledge Base and get the requirements for missing documents.
1. Using Agent's Prompt and Session Parameters: Example of how to pass prompt and session parameters to an agent invocation in order to extend the agent's knowledge.
1. Changing Agent's Advanced Prompts and creating custom Lambda Parsers: Example of how to change an Agent's advanced prompt and how to create a custom lambda parser for advanced agents use cases
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/main.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/README.md
README Summary:
Custom integration with knowledge base
The agent integrates with the knowledge base **without an explicit association** to it. Essentially, based on the function invoked in the function definitions, it can choose to query the vector DB directly by filtering or the knowledge base through both filtering and semantic similarity. This is useful when you want to leverage on the managed knowledge base for data maintenance (create,delete,update of documents in vector database), and exert more control over invocations of the knowledge base.
Architecture
!product review agent
Dataset
This example uses the amazon reviews 2018 dataset with these fields - review (string), rating (number), timestamp (number), reviewers (string list).
We create the following metadata file for each of the text chunks (review) in the knowledge base.
The timestamp is in epoch format so date filters using  operators can be used since Bedrock KB doesn't support date type currently.
In addition, string list can be filtered using the  operator. This can be used to implement document level access controls in OpenSearch Serverless. Each document can have a role attribute containing the list of roles that can access the document.
Knowledge Base integration
Function definitions are used to define the APIs that are callable by the agent.
The first function  takes in as arguments the number of results to return, the start date and the end date of the documents. This API performs a direct query on the OpenSearch database.
The second function  is similar to the first except it takes in additional reviewer and description arguments. This API uses a Bedrock KB hybrid query type - filters using count, start_date, end_date, reviewers and semantic similarity using vectors.
Run
1. Request model access to Anthropic Claude 3 Haiku and Cohere Embed (English).
2. Step through the cells in main.ipynb
3. Interact using streamlit web app
Sample prompts and responses
1. Trigger direct query on OpenSearch
Prompt
Response
2. Trigger knowledge base retrieval API
Prompt
Response

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/agent.py
Summary of agent.py:
- Class: ProductReviewAgent
- Function: __init__
- Function: invoke_agent


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/app.py
Summary of app.py:
- Function: get_named_parameter
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/main.py
Summary of main.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/product-review-agent/architecture/architecture.jpeg

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/CODE_OF_CONDUCT.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/LICENSE

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/README.md
README Summary:
Insurance Claim Lifecycle Automation Using Agents and Knowledge Bases for Amazon Bedrock
---
Content
- Overview
- Agents and Knowledge Bases Architecture
- Cost
- Deployment Guide
- Testing and Validation
- Clean Up
Overview
You can now use Agents for Amazon Bedrock and Knowledge Bases for Amazon Bedrock to configure specialized agents that seamlessly run actions based on user input and your organization's data. These managed agents play conductor, orchestrating interactions between foundation models (FMs), API integrations, user conversations, and knowledge bases loaded with your data.
This sample solution highlights how you can use Agents and Knowledge Bases for Amazon Bedrock to **build on existing enterprise resources** to automate the tasks associated with the insurance claim lifecycle, efficiently scale and improve customer service, and enhance decision support through improved knowledge management. Your Bedrock-powered insurance agent can assist human agents by creating new claims, sending pending document reminders for open claims, gathering claims evidence, and searching for information across existing claims and customer knowledge repositories.
Demo Recording
<img src="design/demo-thumbnail.png" width="100%">
Agents and Knowledge Bases for Amazon Bedrock
Agents and Knowledge Bases Functionality
Agents and Knowledge Bases for Amazon Bedrock work together to provide the following set of capabilities:
- **Task Orchestration** - Agents expand FMs to understand natural language user inquiries and dissect multi-step tasks into smaller, executable steps.
- **Interactive Data Collection** - Agents engage in natural conversations to gather supplementary information from users.
- **Task Fulfillment** - Agents complete customer requests through series of reasoning steps and corresponding actions based on ReAct prompting.
- **System Integration** - Agents make API calls to integrated company systems to run specific actions.
- **Data Querying** - Knowledge bases enhance accuracy and performance through fully-managed retrieval augmented generation (RAG) using customer specific data sources.
- **Source Attribution** - Agents conduct source attribution, identifying and tracing the origin of information or actions through chain-of-thought reasoning.
Agents and Knowledge Bases Architecture
<p align="center">
<img src="design/agent-overview.png">
<em>Diagram 1: Agents and Knowledge Bases for Amazon Bedrock Architecture Overview</em>
</p>
The workflow consists of the following steps:
1. Users provide natural language inputs to the agent.
**Sample Prompts:**
- _Create a new claim._
- _Send a pending documents reminder to the policy holder of claim ID 2s34w-8x._
- _Gather evidence for claim ID 5t16u-7v._
- _What is the total claim amount for claim ID 3b45c-9d?_
- _What is the total repair estimate for that same claim?_
- _What factors determine my car insurance premium?_
- _How can I lower my car insurance rates?_
- _Which claims have open status?_
- _Send pending document reminders to all policy holders with open claims._
2. During **pre-processing**, the agent validates, contextualizes, and categorizes user input. The user input (or _Task_) is interpreted by the agent using chat history and the instructions and underlying foundation model that were specified during agent creation. The agent's instructions are descriptive guidelines outlining the agent's intended actions. Also, you can optionally configure advanced prompts, which allow you to boost your agent's precision by employing more detailed configurations and offering manually selected examples for few-shot prompting. This method allows you to enhance the model's performance by providing labeled examples associated with a particular task.
3. Action groups are a set of APIs and corresponding business logic, whose OpenAPI schema is defined as JSON files stored in Amazon Simple Storage Service (S3). The schema allows the agent to reason around the function of each API. Each action group can specify one or more API paths, whose business logic is run through the AWS Lambda function associated with the action group.
4. Knowledge bases provide fully-managed RAG to supply the agent with access to your data. You first configure the knowledge base by specifying a description that instructs the agent when to use your knowledge base. Then you point the knowledge base to your Amazon S3 data source. Finally, you specify an embedding model and choose to use your existing vector store or allow Bedrock to create the vector store on your behalf. Once configured, each data source sync creates vector embeddings of your data that the agent can use to return information to the user or augment subsequent FM prompts.
5. During **orchestration**, the agent develops a _rational_ with the logical steps of which action group API invocations and knowledge base queries are needed to generate an _observation_ that can be used to augment the base prompt for the underlying FM. This ReAct style of prompting serves as the input for activating the FM, which then anticipates the most optimal sequence of actions to complete the user's task.
6. During **post-processing**, once all _orchestration_ iterations are complete, the agent curates a final response. Post-processing is disabled by default.
Cost
You are responsible for the cost of the AWS services used while running this sample solution. As of May 2024, the cost for running this solution with the specified settings in the us-east-1 (N. Virginia) AWS Region is approximately **$766.57** per month based on the following assumptions.
Amazon S3 (Pricing):
- **Storage:**
- Volume: 1 TB (1024 GB) of data in the S3 Standard storage class.
- Storage Cost: $0.023 per GB-month.
- Estimated monthly storage cost: $0.023/GB-month * 1024 GB = $23.55
- **Data Transfer:**
- Volume: 1 TB (1024 GB) of data transfer out per month.
- Data Transfer Cost: $0.09 per GB for the first 10 TB.
- Estimated monthly data transfer cost: $0.09/GB * 1024 GB = $92.16
- **Requests:**
- GET Requests: 1,000,000 requests at $0.0004 per 1,000 requests.
- PUT Requests: 1,000,000 requests at $0.005 per 1,000 requests.
- Estimated monthly requests cost:
- GET: $0.0004 * (1,000,000 / 1,000) = $0.40
- PUT: $0.005 * (1,000,000 / 1,000) = $5.00
- Total requests cost: $0.40 + $5.00 = $5.40
- **Total Amazon S3 Cost:**
- Storage: $23.55
- Data Transfer: $92.16
- Requests: $5.40
- **Total: $121.11**
Amazon OpenSearch (Pricing):
- **Storage:**
- Volume: 1 TB (1024 GB) managed storage.
- Storage Cost: $0.24 per GB per month.
- Estimated monthly storage cost: $0.24/GB * 1024 GB = $245.76
- **Compute:**
- OCU - Indexing: 0.5 OpenSearch Compute Units (OCU) at $0.24 per OCU per hour.
- OCU - Search and Query: 0.5 OCU at $0.24 per OCU per hour.
- OpenSearch Serverless dev mode allows for cost optimization with as low as 0.5 OCU.
- Estimated monthly compute cost: $0.24 * 1 OCU * 24 hours * 30 days = $172.80
- **Total Amazon OpenSearch Cost:**
- Storage: $245.76
- Compute: $172.80
- **Total: $418.56**
AWS Lambda (Pricing):
- **Compute:**
- Invocation Count: 100,000 invocations per month.
- Duration: 0.5 seconds on average.
- Total Execution Time: 50,000 seconds per month.
- Memory: 128 MB.
- Total GB-Seconds: 50,000 * 128 MB / 1024 = 6,250 GB-Seconds.
- Cost: $0.0000166667 per GB-second.
- Estimated monthly cost: $0.0000166667 * 6,250 GB-Seconds = $0.10
- **Total AWS Lambda Cost: $0.10**
Agents and Knowledge Bases for Amazon Bedrock (Pricing):
- **Model:**
- Selection: Anthropic Claude 3 Sonnet.
- Usage Volume: 3,000,000 tokens per month.
- Price per 1,000 input tokens: $0.003
- Price per 1,000 output tokens: $0.015
- **Tokens:**
- Input Tokens: 100,000 tokens/day * 30 days = 3,000,000 tokens/month.
- Output Tokens: 100,000 tokens/day * 30 days = 3,000,000 tokens/month.
- Cost for input tokens: $0.003 * (3,000,000 / 1,000) = $9.00
- Cost for output tokens: $0.015 * (3,000,000 / 1,000) = $45.00
- **Total Agents Cost: $54.00**
Total Monthly Solution Cost
Summing up all the individual costs:
- **Amazon S3 Cost: $121.11**
- **Amazon OpenSearch Cost: $591.36**
- **AWS Lambda Cost: $0.10**
- **Agents and Knowledge Bases for Amazon Bedrock Cost: $54.00**
**Total Estimated Monthly Cost: $766.57**
Deployment Guide
see Deployment Guide
Testing and Validation
see Testing and Validation
Clean Up
see Clean Up
---
Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
SPDX-License-Identifier: MIT-0

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/total-claim-amount-asset.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/streamlit-app.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/send-reminder-email.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-console-testing.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-kb-configuration.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-prepared-banner.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/ag-configuration.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/send-reminder.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-ds-s3-configuration.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-testing.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-embeddings.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-overview.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-select-model.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/existing-claims-table.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/demo-thumbnail.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-configuration.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/ag-tracing.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/create-new-claim.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-creation-banner.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-example.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-ds-overview.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/existing-claims-table-2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-console-2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/repair-estimate.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-prepare.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-configuration.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-console-1.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-tracing.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-example-2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-1.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-overview.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/total-claim-amount-prompt.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/ag-openapi.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/agent-console-3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/design/kb-creation-banner.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/documentation/deployment-guide.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/documentation/testing-and-validation.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/documentation/clean-up.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/shell/delete-customer-resources.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/shell/create-customer-resources.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/streamlit/bedrock_streamlit.py
Summary of bedrock_streamlit.py:
- Function: generate_session_id
- Function: fetch_agents
- Function: fetch_knowledge_bases
- Function: fetch_data_sources
- Function: fetch_agent_aliases
- Function: fetch_agent_knowledge_bases
- Function: fetch_knowledge_base_name
- Function: extract_bucket_name
- Function: fetch_data_source_s3_configuration
- Function: reset_session
- Function: show_csv
- Function: extract_text_from_docx
- Function: convert_docx_to_html
- Function: show_doc
- Function: show_docx
- Function: show_excel
- Function: show_html
- Function: show_md
- Function: show_pdf
- Function: show_text
- Function: process_uploaded_file
- Function: bedrock_query_knowledge_base
- Function: update_knowledge_base
- Function: check_ingestion_job_status
- Function: invoke_agent
- Function: main


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/streamlit/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/streamlit/sigv4.py
Summary of sigv4.py:
- Class: SigV4HttpRequester
- Function: __init__
- Function: send_signed_request


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/streamlit/setup-streamlit-env.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/streamlit/bedrock_logo.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_2s34w-8x_Amounts.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/AccidentReport_file_requirements.docx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/AccidentImages_file_requirements.docx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_2s34w-8x_RepairEstimate.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_3b45c-9d_Amounts.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_5t16u-7v_Amounts.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_3b45c-9d_RepairEstimate.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_2s34w-8x_RepairEstimate.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/AccidentImages_file_requirements.docx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Internal-Insurance-FAQs.xlsx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/External-Insurance-FAQs.xlsx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_5t16u-7v_RepairEstimate.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_5t16u-7v_Amounts.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Driverlicense_file_requirements.docx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Driverlicense_file_requirements.docx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/External-Insurance-FAQs.xlsx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_3b45c-9d_RepairEstimate.pdf.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Internal-Insurance-FAQs.xlsx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_5t16u-7v_RepairEstimate.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/VehicleRegistration_file_requirements.docx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/VehicleRegistration_file_requirements.docx.metadata.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_2s34w-8x_Amounts.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/Claim_3b45c-9d_Amounts.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/knowledge-base-assets/AccidentReport_file_requirements.docx

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/data-loader/index.py
Summary of index.py:
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/data-loader/loader_deployment_package.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/data-loader/claims.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/send_reminder.py
Summary of send_reminder.py:
- Function: get_named_parameter
- Function: get_named_property
- Function: open_claims
- Function: generate_reminder_id
- Function: send_reminder
- Function: notify_pending_documents
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/gather_evidence.py
Summary of gather_evidence.py:
- Function: get_named_parameter
- Function: get_named_property
- Function: generate_upload_id
- Function: send_evidence_url
- Function: gather_evidence
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/create_claim.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/send_reminder.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/gather_evidence.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/action-groups/create_claim.py
Summary of create_claim.py:
- Function: claim_generator
- Function: collect_documents
- Function: create_claim
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/lambda-layer/cfnresponse-layer.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/lambda/lambda-layer/bedrock-agents-layer.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/api-schema/send_reminder.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/api-schema/gather_evidence.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/agent/api-schema/create_claim.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/insurance-claim-lifecycle-automation/cfn/bedrock-customer-resources.yml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/cloudformation.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/CODE_OF_CONDUCT.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/LICENSE

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/README.md
README Summary:
Generative AI and Multi-Modal Agents in AWS: The Key to Unlocking New Value in Financial Markets
This file walks you through how to set up the infrastructure and applications, and run the code to create a multi-modal agent using Amazon Bedrock. The blog post provides a detailed discussion of this solution.
Technical Achitecture Diagram
<img src="images/architecture-diagram.png" width="680"/>
Implementation Steps
Prerequisites
This solution uses Lambda functions, which are serverless, event-driven compute services that runs applications. The Python code plus other dependencies for the applications are packaged as zip files, stored in *files* in this repo. We need to add them to an S3 bucket in your account in order to set up the Lambda functions.
Please use the us-west-2 region.
First, make an S3 bucket. Go to S3 page in AWS, click "Create bucket". Then enter a bucket name, which should be universally unique. Take a note of the name, because we will need it in following sections. Leave the rest as default, and click "Create bucket" at the bottom of the page.
<img src="images/create_bucket.png" width="680"/>
\
Once the bucket is created, click the bucket name, and create a folder called *files*. To create a folder, click "Create folder", and then enter the folder name "files", then click "Submit".
<img src="images/create_folder.png" width="680"/>
<img src="images/enter_folder_name.png" width="680"/>
\
Upload the files in folder *files* to the S3 bucket.
<img src="images/upload_files.png" width="680"/>
<img src="images/select_files.png" width="680"/>
<img src="images/files_uploaded.png" width="680"/>
\
This solution use Anthropic Claude 3 model in Amazon Bedrock. Use the following link as a reference to enable access to the model link
Create infrastructure using CloudFormation
AWS CloudFormation allows you to create infrasturecture as code.
First, download the CloudFormation template *cloudformation.yaml*.
Then upload it in CloudFormation to create a stack. This stack sets up the necessary infrastructure, such as IAM roles and Lambda functions. Go to CloudFormation console in AWS, click Stacks -> Create stack -> With new resources (standard).
<img src="images/create_stack.png" width="680"/>
Upload *cloudformation.yaml*, and click "Next".
<img src="images/upload_stack.png" width="680"/>
On the "Specify stack details" page,
Give the Stack a name. Take a note of this name as we will need it when running the app. Change the "SourceCodeBucket" to the name of the S3 bucket you created above.
<img src="images/specify_stack_details.png" width="680"/>
\
Leave the rest as default. Check the acknowledgement box on the last page and submit it.
It takes a few minutes to create. Once it is created, you can check the generated resources by clicking on Stacks -> Stack Name. Then click "Resources". The example below shows that the AudioTranscriptsSourceBucketResource is an S3 bucket with the bucket name "test-cf-stack-audiotranscriptssourcebucketresourc-1kg41ts9dy7hk".
<img src="images/stack_resources.png" width="680"/>
Generate text files from audio and pdf files
AWS CloudShell allows you to explore and manage AWS resources from a terminal in your browser
Open AWS CloudShell
<img src="images/open_cloudshell.png" width="680"/>
Execute the following commands
`aws lambda invoke --function-name FSI-TextractAsyncInvocationFunction response.json`
`aws lambda invoke --function-name FSI-Transcribe response.json`
Wait a few minutes (between 5-10 minutes) and check that the following files are created in the S3 bucket `[your_stack_name]-multimodaloutputbucketresource-[random_id]/audioutputs/files/` and `[your_stack_name]-multimodaloutputbucketresource-[random_id]/pdfoutputs/files/`
<img src="images/converted_audiofiles_s3.png" width="680"/>
<img src="images/converted_pdffiles_s3.png" width="680"/>
Create the Knowledge Base
Go to the Amazon Bedrock page in AWS, then go to "Knowledge base" and then Click "Create Knowledge Base"
<img src="images/kb1.png" width="680"/>
\
In the field "Knowledge base name" enter "Financial-Data-Explorer" and in the field "Knowledge base description" enter "Useful for when you need to look up financial information like 10K reports, revenues, sales, net sales, loss and risks about Amazon Inc. Contains the Amazon's earnings call.". Then click "Next"
<img src="images/kb2.png" width="680"/>
In the field "S3 URI" select the bucket `[your_stack_name]-multimodaloutputbucketresource-[random_id]`. Then click "Next"
<img src="images/kb3.png" width="680"/>
\
Select the model "Titan Embeddings G1 - Text". Then click "Next"
<img src="images/kb4.png" width="680"/>
\
Click "Create knowledge base"
<img src="images/kb5.png" width="680"/>
\
Wait for the following popup to show up and then click "Sync"
<img src="images/kb6.png" width="680"/>
\
Wait for the status of the data source change to "Ready"
<img src="images/kb7.png" width="680"/>
Create the Agent
Click "Create Agent"
<img src="images/ag0.png" width="680"/>
\
In the field "Name" enter "Prototype" and in the field "Description" enter "Prototype". Then click "Create"
<img src="images/ag1.png" width="680"/>
\
Choose "Create and use a new service role"  and the Anthropic Claude 3 Sonnet model. In the field "Instructions for the Agent" enter "You are a financial analyst with a set of tools at your disposal.". Click "Save".
<img src="images/ag2.png" width="680"/>
\
Click "Add" in the "Action groups" section
<img src="images/ag3.png" width="680"/>
\
In the field "Enter Action group name" enter "Phrase-Detection", in the field "Description" enter "Useful for when you need to detect key phrases in financial reports.". Choose "Define with API schemas". Choose "Select an existing Lambda function". Select the Lambda function "FSI-KeyPhrasesDetection" and in the field "Select API Schema" select the "openapi_keyphrases.json" file in the bucket created in the prerequisites. Then click "Create"
<img src="images/ag4.png" width="680"/>
<img src="images/ag5.png" width="680"/>
\
Repeat the previous two steps, three more times using the following information:
Field "Enter Action group name" enter "Portfolio-Optimization" \
Field "Description" enter "Useful when you need to build optimal allocation portfolio. \
Select the Lambda function "FSI-PortfolioTool-BedrockAgent" \
Field "Select API Schema" select the "openapi_portfolio.json" file in the bucket created in the prerequisites.
Field "Enter Action group name" enter "Sentiment-Analysis" \
field "Description" enter "Useful for when you need to analyze the sentiment of an excerpt from a financial report." \
Select the Lambda function "FSI-SentimentDetecttion" \
Field "Select API Schema" select the "openapi_sentiment.json" file in the bucket created in the prerequisites. \
Field "Enter Action group name" enter "Stock-Query" \
Field "Description" enter "Useful for when you need to answer any question about stocks prices." \
Select the Lambda function "FSI-StockQuery-BedrockAgent" \
Field "Select API Schema" select the "openapi_stock_query.json" file in the bucket created in the prerequisites.
At the end you should have the following actions configured:
<img src="images/ag6.png" width="680"/>
\
Click "Add" in the "Knowledge bases" section
<img src="images/ag7.png" width="680"/>
\
In the field "Select Knowledge base" select "Financial-Data-Explorer", in the field "Knowledge base instructions for Agent" enter "Useful for when you need to look up financial information like 10K reports, revenues, sales, net sales, loss and risks about Amazon Inc. Contains the Amazon's earnings call.". Then click "Add"
<img src="images/ag8.png" width="680"/>
\
Click "Save and exit"
<img src="images/ag9.png" width="680"/>
\
In the test chat window (left), click "Prepare"
<img src="images/ag10.png" width="680"/>
\
Enter your question or requirement to test the agent
<img src="images/ag11.png" width="680"/>
Key considerations using action groups
As part of wrapping the business logic using Lambda functions, it's important to highlight two aspects:
1. The OpenAPI Schemas for each action group were built in a local text editor using this documentation as a reference, it can also be built using the in-line OpenAPI schema editor in the Amazon Bedrock console. It's important to highlight the importance of defining an adequate description for each method, and also for each field in the request and the response, because the agent can use this information to determine when to call this API operation and to understand what the operation does.
2. For the code in the Lambda functions, it's important to know what the agent send to the Lambda function and what should be response. For the request you can check the general format in this link, in the *parameters* or *requestBody* fields you can get the data necessary to execute the logic depending of your needs. For the response you can check the general format in this link, it's important to generate in the code a response object that comply with structure defined in the corresponding OpenAPI Schema.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/upload_files.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/open_jupyter_instance.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/converted_pdffiles_s3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/specify_stack_details.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/audio_output.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag8.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag11.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/bedrock-access2.JPG

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag10.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag9.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/stack_resources.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/output_bucket.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/studio-new-launcher.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/architecture-diagram.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/create_stack.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/pdf_output.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/bedrock-access.jpg

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb1.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/create_folder.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/files_uploaded.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb5.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb4.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb6.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/kb7.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag7.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/sg-rules.PNG

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/create_bucket.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag6.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag4.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag5.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/open_cloudshell.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag1.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/converted_audiofiles_s3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/upload_stack.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag0.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/enter_folder_name.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/select_files.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/images/ag3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/Amazon-Quarterly-Earnings-Report-Q1-2023-Full-Call-v1.mp3

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/openapi_stock_query.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-StockQuery-BedrockAgent-4bed2482-a84f-4d9b-b53c-37220fd4b9bb.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-TextractProcessingFunction-b6054c5e-0286-4cfb-a2f3-55d408a9972c.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/openapi_portfolio.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/openapi_sentiment.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/Amazon-10K-2022-EarningsReport.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/stock_prices.csv

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-SentimentDetecttion-BedrockAgent-6aebee60-d2df-464c-b652-b93e2aef7b3a.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-TextractAsyncInvocationFunction-759363ea-7b4b-411c-a96f-b137a595387b.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/agents-layer-porfolio.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-Transcribe-66a4860d-390a-4af5-aa1b-05fb469be7ac.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/openapi_keyphrases.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-KeyPhrasesDetection-BedrockAgent-21b0f3b8-f981-4db6-a0ce-606a13e9c35f.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/Amazon-10Q-Q1-2023-QuaterlyEarningsReport.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/agents-layer-stock-query.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/ai-powered-assistant-for-investment-research/files/FSI-PortfolioTool-BedrockAgent-9a4cdb9f-14b9-4658-9720-537735bf2b1c.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/README.md
README Summary:
<h1 align="center">Text to SQL Bedrock Agent</h1>
Authors:
**Pedram Jahangiri** @jpedram, **Sawyer Hirt** @sawyehir, **Zeek Granston** @zeekg, **Suyin Wang** @suyinwa
Reviewer:
**Maira Ladeira Tanke** @mttanke
Introduction
Harnessing the power of natural language processing, the "Text to SQL Bedrock Agent" facilitates the automatic transformation of natural language questions into executable SQL queries. This tool bridges the gap between complex database structures and intuitive human inquiries, enabling users to effortlessly extract insights from data using simple English prompts. It leverages AWS Bedrock's cutting-edge agent technology and exemplifies the synergy between AWS's robust infrastructure and advanced large language models offered in AWS bedrock, making sophisticated data analysis accessible to a wider audience.
This repository contains the necessary files to set up and test a Text to SQL conversion using the Bedrock Agent with AWS services.
!sequence-flow-agent
Use case
The code here sets up an agent capable of crafting SQL queries from natural language questions. It then retrieves responses from the database, providing accurate answers to user inquiries. The diagram below outlines the high-level architecture of this solution.
The Agent is designed to:
- Retrieve database schemas
- Execute SQL queries
Prerequisites
Before you begin, ensure you have the following:
- An AWS account with the following permissions:
- Create and manage IAM roles and policies.
- Create and invoke AWS Lambda functions.
- Create, read from, and write to Amazon S3 buckets.
- Access and manage Amazon Bedrock agents and models.
- Create and manage Amazon Glue databases and crawlers.
- Execute queries and manage workspaces in Amazon Athena.
- Access to Amazon Bedrock foundation models (Anthropics Claude 3 Sonnet model for this solution)
- For local setup,
- Python and Jupyter Notebooks installed
- AWS CLI installed and configured
- For AWS SageMaker
- Make sure your domain has above permission
- Use Data Science 3.0 kernel in SageMaker Studio
Installation
Clone the repository to your local machine or AWS environment
Usage
1. Start by opening the `create_and_invoke_sql_agent.ipynb` Jupyter Notebook.
2. Run the notebook cells in order. The notebook will:
- Import configurations from `config.py`.
- Set your own 'AWS_PROFILE'
- Build the necessary infrastructure using `build_infrastructure.py`, which includes:
- S3 buckets
- Lambda functions
- Bedrock agents
- Glue databases and crawlers
- Necessary IAM roles and policies
3. After the infrastructure is set up, you can execute sample queries within the notebook to test the agent.
4. To delete all resources created and avoid ongoing charges, run the clean.py script, in the notebook.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/create_and_invoke_sql_agent.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/lambda_function.py
Summary of lambda_function.py:
- Function: get_schema
- Function: execute_athena_query
- Function: extract_result_data
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/images/text-to-sql-architecture-Athena.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/dependencies/config.py
Summary of config.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/dependencies/clean.py
Summary of clean.py:
- Function: delete_crawler
- Function: delete_tables
- Function: delete_database
- Function: delete_policy_by_name


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/dependencies/build_infrastructure.py
Summary of build_infrastructure.py:
- Function: unzip_data
- Function: upload_data


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/dependencies/text_to_sql_openapi_schema.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent/data/TheHistoryofBaseball.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/Dockerfile

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/deploy.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/README.md
README Summary:
Customer relationship management (CRM) Bedrock Agent
Authors:
Sawyer Hirt @sawyehir, Zeek Granston @zeekg, Eashan Kaushik @eashank
Reviewer:
Maira Ladeira Tanke @mttanke
Introduction
The Customer Relationship Management (CRM) Bedrock Agent is a conversational AI solution that utilizes natural language processing to facilitate interactions with customer data and management of customer relationships. This agent bridges the gap between complex customer information systems and user-friendly communication by allowing users to retrieve insights, update tasks, and receive recommendations using natural language prompts.
Built with Agents for Amazon Bedrock and leveraging AWS services like Amazon DynamoDB and AWS Lambda, the CRM Bedrock Agent integrates AI capabilities with an intuitive chat interface. By connecting with AWS services and the Jira API, the agent streamlines customer relationship management processes, enhances customer experiences, and improves efficiency.
Through natural language interaction, the agent provides access to customer information, enabling users to retrieve company overviews, fetch recent interactions, update Jira tasks, and receive personalized recommendations based on customer preferences. This functionality caters to the needs of modern customer-centric businesses, making data-driven decision-making more accessible and user-friendly.
Architecture
!architecture
Customer Use Case
AnyCompany Manufacturing Inc. is a producer of industrial equipment and machinery. With a vast customer base spanning multiple continents, the company constantly struggles to maintain effective customer relationships. Customer data is scattered across various systems, making it challenging to track interactions, preferences, and open tasks. This often results in missed opportunities, delayed responses, and suboptimal customer experiences, ultimately hindering business growth.
A seasoned project manager at AnyCompany, is responsible for overseeing the company's software solutions. Recently, the sales team expressed frustration with the cumbersome process of accessing customer information and updating related tasks during customer interactions. This sales team frequently engages with existing and potential clients, discussing projects, gathering requirements, and providing progress updates. However, the lack of a centralized system made it difficult for them to access relevant customer data and manage follow-up actions efficiently.
To address these challenges, AnyCompany decided to implement the Customer Relationship Management (CRM) Agent, a conversational AI solution that leverages natural language processing and integrates with existing systems. The CRM Agent acts as a bridge between the company's customer data, task management tools (like Jira), and their sales and support teams. By allowing users to interact with customer information and manage tasks through natural language prompts, the agent provides a user-friendly interface that simplifies data access and updates Jira as needed for issue and project tracking.
With the CRM Agent, the team can leverage the in-built functionality combining these disparate resources. The sales team can retrieve customer overviews, recent interactions, and communication preferences from DynamoDB tables using natural language prompts. They can also fetch open Jira tasks for a project and update task timelines by interacting with the agent, which communicates via the Jira API. This streamlined process allows the sales team to efficiently access customer data and manage follow-up actions within their project management system, enhancing productivity and customer interactions.
Jira Integration (Optional)
The agent can integrate with Jira for task management. Provide the necessary Jira configuration parameters during the CloudFormation deployment. To get more information about Jira developer API refer the documentation.
Deployment
> [!NOTE]
> This repository provides base code for Streamlit application's and is not production ready. It is your responsibility as a developer to test and vet the application according to your security guidlines.
Upload the codepipleline.yaml file to AWS CloudFormation. This template sets up a CodePipeline to build and deploy the Streamlit application to an ECS Fargate service. It also creates the necessary infrastructure (VPC, subnets, etc.) and integrates with Jira (optional).
|   Region   | codepipeline.yaml |
| ---------- | ----------------- |
| us-east-1  | ![launch-stack](https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=CRMBot&templateURL=https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/0a9f7588-a2c4-4484-b051-6658ce32605c/CRM/codepipeline.yaml)|
| us-west-2  | ![launch-stack](https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=CRMBot&templateURL=https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/0a9f7588-a2c4-4484-b051-6658ce32605c/CRM/codepipeline.yaml)|
Follow these steps to implement the CRM Agent in your environment:
1. Deploy the `codepipeline.yaml` CloudFormation template. The following CloudFormation parameters are provided:
- GitURL: Initial repository for CRM Agent - leave unchanged.
- EnvironmentName: Unique name to distinguish different CRM applications in the same AWS account- min length 1 and max length 4.
- DeployVPCInfrastructure: Select `true` if this is your first deployment of CRM application in your AWS account, else `false`.
- JiraURL: URL of the Jira without `https://`.
- JiraAPIToken: API Token for Jira API.
- JiraUsername: Username for Jira API.
> [!IMPORTANT]
> `JiraURL`, `JiraAPIToken`, and `JiraUsername` needs to be left unchanged if you are not configuring Jira for this application.
2. AWS CodePipeline will automatically build and deploy the application to an ECS Fargate service. Wait for AWS CodePipeline to deploy `<StackName>deploy<EnvironmentName>` CloudFormation stack.
3. Get the CloudFront URL from the Output of the stack `<StackName>deploy<EnvironmentName>`. Paste it in the browser to view CRM app. Invoke the agent by interacting with the chat interface.
> [!IMPORTANT]
> Use the supported prompts as shown below.
> [!NOTE]
> To get more information about deployment of the streamlit application refer aws-streamlit-deploy-cicd aws-samples.
4. Access to Amazon Bedrock foundation models isn't granted by default. In order to gain access to a foundation model follow documentation.
Amazon Bedrock Agent API Paths and Actions
The agent supports the following API paths and actions:
- `GET /recent-interactions/{customerId}/{count}`: Retrieve the latest interactions for a given customer ID and count.
- `GET /company-overview/{customerId}`: Fetch the company overview details for a given customer ID.
- `GET /preferences/{customerId}`: Retrieve the meeting preferences (type, time, day) for a given customer ID.
- `GET /open-jira-tasks/{projectID}`: Fetch a list of open Jira issues based on project key.
- `PUT /update-jira-task/{issueKey}`: Update the timeline of a Jira issues.
Sample Data
The customer and interactions DynamoDB tables are filled with mock data.
Customer data
!customer
Interactions data
!interactions
Supported Prompts
The agent can be invoked using the following prompts:
- Provide a brief overview of customer [CUSTOMER_ID].
- List the last [COUNT] recent interactions for customer [CUSTOMER_ID].
- What communication method does customer [CUSTOMER_ID] prefer?
- Recommend optimal time and contact channel to reach out to [CUSTOMER_ID] based on their preferences and our last interaction.
The following prompts only work if you have configured Jira CloudForation parameters with valid values.
- What are the open Jira Tasks for project id [PROJECT_KEY]?
- Please update Jira Task [IssueKey] to [DURATION] weeks out.
Replace [CUSTOMER_ID], [COUNT], [PROJECT_KEY], [IssueKey] and [DURATION] with the appropriate values in the prompts.
Clean Up
- Open the CloudFormation console.
- Select the stack `codepipeline.yaml` you created then click **Delete** twice. Wait for the stack to be deleted.
- Delete the nested stack `<StackName>-Infra-<StackId>` created by `codepipeline.yaml`. Please ensure that you refrain from deleting this stack if there are any additional web deployments utilizing this repository within the specified region of your current work environment.
- Delete the role `StreamlitCfnRole-<EnvironmentName>` manually.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/app.py
Summary of app.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/infrastructure.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/codepipeline.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/util/__init__.py
Summary of __init__.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/util/bedrock.py
Summary of bedrock.py:
- Class: BedrockAgent
- Function: __init__
- Function: new_session
- Function: invoke_agent


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/basic/crm-bot-lambda.py
Summary of crm-bot-lambda.py:
- Function: get_customer_interactions
- Function: get_customer
- Function: get_named_parameter
- Function: get_named_property
- Function: listRecentInteractions
- Function: companyOverview
- Function: getPreferences
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/basic/crm-bot-lambda.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/basic/crm_schema.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/jira/crm-bot-lambda.py
Summary of crm-bot-lambda.py:
- Function: get_customer_interactions
- Function: get_customer
- Function: get_named_parameter
- Function: get_named_property
- Function: listRecentInteractions
- Function: companyOverview
- Function: getPreferences
- Function: getOpenJiraIssues
- Function: updateJiraIssue
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/jira/crm-bot-lambda.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/bedrock-agent/jira/crm_schema.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/data/data.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/data/interactions.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/data/prompt.py
Summary of prompt.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/data/upload_data.py
Summary of upload_data.py:
- Function: upload_data


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/customer-relationship-management-agent/src/data/customers.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/csbot_agent.py
Summary of csbot_agent.py:
- Function: load_data
- Function: return_customer_info
- Function: return_shoe_inventory
- Function: place_shoe_order
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/customerservicebot.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/README.md
README Summary:
Build a Foundation Model (FM) powered customer service bot with agents for Amazon Bedrock
Introduction
From enhancing the conversational experience to agent assistance, there are a plenty of ways that generative AI and foundation models (FMs) can help deliver faster, better support. With the increasing availability and diversity of FMs, it is difficult to experiment and keep up-to-date with the latest model versions. Amazon Bedrock is a fully managed service that offers a choice of high-performing FMs from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon. With Amazon Bedrocks comprehensive capabilities, you can easily experiment with a variety of top FMs, customize them privately with your data using techniques such as fine tuning and retrieval-augmented generation (RAG).
Agents for Amazon Bedrock
In July, AWS announced the preview of agents for Amazon Bedrock, a new capability for developers to create fully managed agents in a few clicks. Agents extend FMs to execute complex business tasksfrom booking travel and processing insurance claims to creating ad campaigns and managing inventoryall without writing any code. With fully managed agents, you dont have to worry about provisioning or managing infrastructure.
In this post, we provide a step-by-step guide with building blocks to create a customer service bot. We use a text generation model (Anthropic Claude V2) and agents for Amazon Bedrock for this solution.
We provide an AWS CloudFormation template to provision the resources required for building this solution. Then we walk you through steps on how to create an agent for Amazon Bedrock.
ReAct Prompting
FMs reason and figure out how to solve user-requested tasks with a reasoning technique called ReAct. It is a general paradigm that combines reasoning and acting with FMs. ReAct prompts FMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while incorporating additional information into the reasoning. The structured prompts include a sequence of question-thought-action-observation examples.
* The question is the user-requested task or problem to solve.
* The thought is a reasoning step that helps demonstrate to the FM how to tackle the problem and identify an action to take.
* The action is an API that the model can invoke from an allowed set of APIs.
* The observation is the result of carrying out the action.
Components in agents for Amazon Bedrock
Behind the scenes, agents for Amazon Bedrock automate the prompt engineering and orchestration of user-requested tasks. They can securely augment the prompts with company-specific information to provide responses back to the user in natural language. The agent breaks the user-requested task into multiple steps and orchestrates sub tasks with the help of FMs. Action groups are tasks that the agent can perform autonomously. Action groups are mapped to an AWS Lambda function and related API schema to perform API calls. Below diagram depicts the agent structure.
![](./img/ML-15539-agents-components.png)
Solution overview
We use a shoe retailer use case to build the customer service bot. The bot will help customers purchase shoes by providing options in a human like conversation. Customers converse with the bot in a natural language with multiple steps invoking external APIs to accomplish sub-tasks. Following diagram illustrates the sample process flow.
![](img/ML-15539-sequence-flow-agents.png)
The following diagram depicts a high-level architecture of this solution.
![](./img/ML-15539-agents-arch-diagram.png)
1.	You can create an agent with Bedrock supported FMs like Anthropic Claude V2.
2.	Attach API schema, residing in an Amazon Simple Storage Service (S3) bucket, and a Lambda function containing the business logic to the agent. (Note: This is a one-time setup)
3.	The agent uses customer requests to create a prompt using the ReAct framework. It, then, uses the API schema to invoke corresponding code in the Lambda function.
4.	You can perform a variety of tasks including sending email notifications, writing to databases, triggering application APIs in the Lambda functions.
In this post, we use the Lambda function to retrieve customer details, list shoes matching customer preferred activity and finally, place orders. Our code is backed by an in-memory SQLite database. You can use similar constructs to write to a persistent data store. We walk you through agent setup in the next section.
Prerequisites
To implement the solution provided in this post, you should have an AWS account and access to Amazon Bedrock with agents enabled (currently in preview). Use AWS CloudFormation template to create the resource stack required for the solution.
<img src="./img/ML-15539-cfn-launch-stack.png">
The CloudFormation template creates two IAM roles. Update these roles to apply least-privilege permissions as discussed in Security best practices.
1.	`LambdaBasicExecutionRole` with S3 full access and CloudWatch access for logging.
2.	`AmazonBedrockExecutionRoleForAgents` with S3 full access and Lambda full access.
*Note: Agents for Amazon Bedrock requires the role name to be prefixed by `AmazonBedrockExecutionRoleForAgents_*`*
Bedrock Agents setup
Create an Agent for Amazon Bedrock
To create an agent, open the Amazon Bedrock console and choose **Agents** in the left navigation pane. Then select **Create Agent**.
![](img/ML-15539-agents-menu.png)
This starts the agent creation workflow.
1.	**Provide agent details:** Give the agent a name and description (optional). Select the service role created by the CloudFormation stack and select **Next**.
![](img/ML-15539-agent-details.png)
2.	**Select a foundation model:** In the next screen, you will select a model. Provide clear and precise instructions to the agent on what tasks to perform and how to interact with the users.
![](img/ML-15539-agent-model.png)
3.	**Add action groups:** An action is a task the agent can perform by making API calls. A set of actions comprise an action group. You will provide an API schema that will define all the APIs in the action group. Note that you must provide an API schema in the OpenAPI schema JSON format. The Lambda function contains the business logic required to perform API calls. You must associate a Lambda function to each action group.
Give the action group a name and provide a description for the action. Select the Lambda function and provide an API schema file and select **Next**.
![](img/ML-15539-agent-action-groups.png)
5.	In the final step, review the agent configuration and select **Create Agent**.
Test/Deploy agents for Amazon Bedrock
1.	**Test the agent:** After the agent is created, you will see the agent overview along with a working draft. Bedrock console provides a UI to test your agent.
![](img/ML-15539-agent-test.png)
2.	**Deploy:** After successful testing, you can deploy your agent. To deploy an agent in your application, you must create an alias. Bedrock then automatically creates a version for that alias.
![](img/ML-15539-agent-alias.png)
You will notice the following actions with the above agent setup and the Lambda code provided with this post:
1.	The agent creates a prompt from the developer-provided instructions (such as You are an agent that helps customers purchase shoes.), API schemas needed to complete the tasks, and data source details. The automatic prompt creation saves weeks of experimenting with prompts for different FMs.
2.	The agent orchestrates the user-requested task, such as I am looking for shoes by breaking it into smaller subtasks like getting customer details, matching the customer preferred activity with shoe activity, and placing shoe orders. The agent determines the right sequence of tasks and handles error scenarios along the way.
The below screenshot displays the sample responses from the agent.
![](img/ML-15539-agent-response.png)
By selecting the Show trace for each of the responses, you can see the reasoning technique used by the agent. Sample traces below.
![](img/ML-15539-agent-trace1.png)
![](img/ML-15539-agent-trace2.png)
![](img/ML-15539-agent-trace3.png)
Cleanup
To avoid incurring future charges, delete the resources. You can do this by deleting the CloudFormation stack as shown below.
![](img/ML-15539-cfn-stack-delete.png)
Call to action
Feel free to download and test the code in this GitHub repository. You can also invoke the agents for Amazon Bedrock programmatically using the sample Jupyter Notebook provided.
Conclusion
Agents for Amazon Bedrock can help you increase productivity, improve your customer service experience, or automate DevOps tasks. In this post, we showed you how to setup agents for Amazon Bedrock to create a customer service bot.
We encourage you to learn more by reviewing additional features of Amazon Bedrock. You can use the sample code provided in this post to create your own implementation. Try our workshop to gain hands-on experience with Amazon Bedrock.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.
Authors
Manju Prasad - manjuprs@
Archana Inapudi - ainapudi@
Amit Arora - aroraai@

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/csbot_agent_template.yml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/workshop/test_retailagent_agentsforbedrock.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-sequence-flow-agents.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-trace1.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-AgentsBlog.drawio

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agents-menu.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-model.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-trace2.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-trace3.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-cfn-launch-stack.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-test.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-cfn-stack-delete.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-action-groups.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-alias.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-response.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/img/ML-15539-agent-details.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/open-api-spec/customerservicebot.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/agentsforbedrock-retailagent/data/demo_csbot_db

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/CODE_OF_CONDUCT.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/LICENSE

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/README.md
README Summary:
HR Assistant Using Titan Text Premier with Agents and Knowledge Bases for Amazon Bedrock
---
Authors:
Anupam Dewan @dewanup, Jie Lie @liaji, Han Liu @haliuz
Reviewer:
Maira Ladeira Tanke @mttanke
Content
- Overview
- Agents and Knowledge Bases Architecture
- Deployment Guide
- Test Conversation
- Clean Up
Overview
Amazon Titan Text Premier is the latest addition to the Titan family of Large Language Models. It is a high-performing, cost effective and model engineered to deliver superior performance for enterprise grade applications.
With a maximum context length of 32K tokens, it has been specically optimized for enterprise use cases, such as building Retrieval Augmented Generation (RAG) and agent-based applications with Knowledge Bases and Agents for Amazon Bedrock. With Titan Text Premier, you can unlock new levels of efficiency and productivity by creating custom agents that can automate multistep internal or external tasks. You can also use this model to build interactive AI assistants that leverage your existing APIs and interact with your own data.
This sample solution  uses Titan Text Premier with, Agents, and Knowledge Bases, all tied together with Amazon Bedrock. The solution showcases an HR assistant build on existing enterprise resources, with the an employee asking questions around HR related tasks like time off, leave policies, employee pay-stubs. The solution also aims at automating leave requests and question answering on time off policies and employee payment related details. Your Bedrock-powered HR Assistant can assist employees from asking policy related questions, to submitting a time off and sending communications through email and slack to their team-mates and managers.
Demo Recording
<img src="imgs/00_youtube_thumbnail.png" width="100%">
Agents and Knowledge Bases for Amazon Bedrock
Agents and Knowledge Bases Functionality
Agents and Knowledge Bases for Amazon Bedrock work together to provide the following set of capabilities:
- **Task Orchestration** - Agents expand FMs to understand natural language user inquiries and dissect multi-step tasks into smaller, executable steps.
- **Interactive Data Collection** - Agents engage in natural conversations to gather supplementary information from users.
- **Task Fulfillment** - Agents complete customer requests through series of reasoning steps and corresponding actions based on ReAct prompting.
- **System Integration** - Agents make API calls to integrated company systems to run specific actions.
- **Data Querying** - Knowledge bases enhance accuracy and performance through fully-managed retrieval augmented generation (RAG) using customer specific data sources.
- **Source Attribution** - Agents conduct source attribution, identifying and tracing the origin of information or actions through chain-of-thought reasoning.
Agents and Knowledge Bases Architecture
<p align="center">
<img src="imgs/01_agent-overview.png">
<em>Diagram 1: Agents and Knowledge Bases for Amazon Bedrock Architecture Overview</em>
</p>
The workflow consists of the following steps:
1. **Input Query**: Users provide natural language inputs to the agent.
**Sample Prompts:**
* _(**KB call**) Can you get me some details about Parental Leave Policy?_
* _(**KB+Athena API**) My partner and I are expecting a baby on July 1st. Can I take 2 weeks off?_
- _Employee Name: `Pepper Li`_
- _Employee Alias: `hremployee`_
* _(**KB + Athena API Call**) Yes, Please request two weeks time off using my vacation time, from July 1st, 2024 to July 12, 2024_
* _(**Image Generator**) Generate a cartoon image of new born child with parents_
* _(**Email Action**) Send a email with above image to my team telling them that I will be away for 2 weeks starting July 1_
- _Email Address: Use the email that you used at <SNS_EMAIL>_
* _(**Slack Message**) You can setup slack message API similarly using Slack Webhooks_
2. **Preprocessing Step**: During pre-processing, the agent validates, contextualizes, and categorizes user input. The user input (or _Task_) is interpreted by the agent using chat history and the instructions and underlying foundation model that were specified during agent creation. The agent's instructions are descriptive guidelines outlining the agent's intended actions. Also, you can optionally configure advanced prompts, which allow you to boost your agent's precision by employing more detailed configurations and offering manually selected examples for few-shot prompting. This method allows you to enhance the model's performance by providing labeled examples associated with a particular task.
3. **Action Groups**: Action groups are a set of APIs and corresponding business logic, whose OpenAPI schema is defined as JSON files stored in Amazon Simple Storage Service (S3). The schema allows the agent to reason around the function of each API. Each action group can specify one or more API paths, whose business logic is run through the AWS Lambda function associated with the action group.
> In this sample application the agent has multiple actions associated within an action group, such as looking up and updating the data around the employee's time off in an Athena table, sending slack and outlook messages to team mates, generating images using Titan Image Generator, making a Knowledge Base Query to get the relevent details.
4. **Knowledge bases Look Up as an action**: Knowledge bases provide fully-managed RAG to supply the agent with access to your data. You first configure the knowledge base by specifying a description that instructs the agent when to use your knowledge base. Then you point the knowledge base to your Amazon S3 data source. Finally, you specify an embedding model and choose to use your existing vector store or allow Bedrock to create the vector store on your behalf. Once configured, each data source sync creates vector embeddings of your data that the agent can use to return information to the user or augment subsequent FM prompts.
> In this sample application, we use Titan Embedding Model as an embedding model along with default open search serverless vector database for storing our embedding. The Knowledge Base contains the employers relevant HR documents, such as parental leave policy, vacation policy, payment slips and more.
5. **Orchestration**: During orchestration, the agent develops a _rational_ with the logical steps of which action group API invocations and knowledge base queries are needed to generate an _observation_ that can be used to augment the base prompt for the underlying FM. This ReAct style of prompting serves as the input for activating the FM, which then anticipates the most optimal sequence of actions to complete the user's task.
> In this sample application, The agent processes the employee's query, reasons on the query, breaks it down into a series of sub-tasks, determines the proper sequence of steps, and finally executes the appropriate actions and knowledge searches on the fly.
6. During **post-processing**, once all _orchestration_ iterations are complete, the agent curates a final response. Post-processing is disabled by default.
Deployment Guide
see Deployment Guide
Test Conversation
see Test Conversation
Clean Up
see Clean Up
Refrences:
Data Sources:
(1) The Aglaia_Benifits_Policy.pdf is a Fictitious Company HR policy
(2) Paystubs for January and Feburary is also synthetically created fake paystubs
---
Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
SPDX-License-Identifier: MIT-0

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/documentation/deployment-guide.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/documentation/clean-up.md

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/streamlit/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/streamlit/agent_streamlit.py
Summary of agent_streamlit.py:
- Function: session_generator
- Function: bedrock_agent
- Function: get_file_from_s3
- Function: render_s3_image
- Function: parse_trace
- Function: main


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/15_streamlit.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/00_youtube_thumbnail.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/12_agent_working_draft.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/03_kb_review.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/11_agent_overview.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/04_kb_creation_banner.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/14_testing.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/13_create_alias.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/05_kb_data_sync.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/10_associated_actions_withkb.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/01_cfn_resources.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/06_kb_id.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/01_agent-overview.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/09_associated_actions.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/08_hr_agent.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/07_kb_ds_id.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/imgs/02_kb_data_source.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/shell/delete-hr-resources.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/shell/create-hr-resources.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/knowledge-base-assets/pay-february.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/knowledge-base-assets/Aglaia_Benefit_Policy.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/knowledge-base-assets/pay-january.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/index.py
Summary of index.py:
- Function: call_sql_database
- Function: send_email_endpoint
- Function: generate_image_endpoint
- Function: send_slack_message_endpoint
- Function: schedule_meeting_endpoint
- Function: get_availability_endpoint
- Function: handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/calendar_integration.py
Summary of calendar_integration.py:
- Function: schedule_standard_meeting
- Function: find_meeting_timeslot


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/athena_sql_query.py
Summary of athena_sql_query.py:
- Function: get_data_from_database
- Function: execute_athena_query
- Function: check_query_status
- Function: get_query_results


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/__init__.py
Summary of __init__.py:


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/hr_function.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/generate_image.py
Summary of generate_image.py:
- Function: generate_image


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/email_integration.py
Summary of email_integration.py:
- Function: send_email


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/lambda/slack_integration.py
Summary of slack_integration.py:
- Function: send_slack_message


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/action-groups.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/slack-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/send-email-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/calendar-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/sql-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/calendar-availability-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/agent/api-schema/generate-image-action-group.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/hr-assistant/cfn/hr-resources.yml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/setup.sh

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/cdk.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/claude_3.py
Summary of claude_3.py:
- Function: invoke_claude_3_with_text
- Class: Claude3Wrapper
- Function: __init__
- Function: invoke_claude_3_with_text
- Function: invoke_claude_3_multimodal


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/agent_instruction_generator.py
Summary of agent_instruction_generator.py:
- Function: analyze_csv_files
- Function: generate_instruction


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/Prep_Data.py
Summary of Prep_Data.py:
- Function: prep_data


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/Readme.md
README Summary:
Text to SQL Bedrock Agent CDK Enhanced
Authors:
- **Pedram Jahangiri** @iut62elec
Reviewer:
- **Maira Ladeira Tanke** @mttanke
Introduction
Harnessing the power of natural language processing, the "Text to SQL Bedrock Agent" facilitates the automatic transformation of natural language questions into executable SQL queries. This tool bridges the gap between complex database structures and intuitive human inquiries, enabling users to effortlessly extract insights from data using simple English prompts. It leverages AWS Bedrock's cutting-edge agent technology and exemplifies the synergy between AWS's robust infrastructure and advanced large language models offered in AWS Bedrock, making sophisticated data analysis accessible to a wider audience. This repository contains the necessary files to set up and test a Text to SQL conversion using the Bedrock Agent with AWS services.
Use Case
The code here sets up an agent capable of crafting SQL queries from natural language questions. It then retrieves responses from the database, providing accurate answers to user inquiries. The diagram below outlines the high-level architecture of this solution.
The Agent is designed to:
- Retrieve database schemas
- Execute SQL queries
Differences from text-2-sql-agent
This repository enhances the original Text to SQL Bedrock Agent with the following improvements:
- Uses AWS CDK to build the necessary infrastructure.
- Works with any dataset: simply create a folder with all your data in CSV files, create a zip file of this folder, place it in the "Data" directory, and the code will automatically extract and upload the files, generating the necessary instructions. Provide the zip file name at the time of deployment (cdk deploy --profile XXX --context zip_file_name=EV_WA.zip --context region=us-east-1).
- If the answer is large, it creates a file in S3 and points the user to the S3 location.
Prerequisites
Before you begin, ensure you have the following:
- AWS CLI installed and configured with the necessary permissions
- Node.js and npm
- Python 3.9 or higher and pip
- Access to Amazon Bedrock foundation models (Before you can use a foundation model in Amazon Bedrock, you must request access to it. Use this Link for detail https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)
- An AWS account (AWS_PROFILE) with the following permissions:
- Create and manage IAM roles and policies.
- Create and invoke AWS Lambda functions.
- Create, read from, and write to Amazon S3 buckets.
- Access and manage Amazon Bedrock agents and models.
- Create and manage Amazon Glue databases and crawlers.
- Execute queries and manage workspaces in Amazon Athena.
- Access to Amazon Bedrock foundation models (Anthropics Claude 3 Sonnet model for this solution)
Installation
Clone the repository to your local machine or AWS environment, set up a virtual environment and activate it and install the AWS CDK and required Python packages using below code:
Deployment
Deploy the stack using the AWS CDK.
If you want to run this with sample data, use the data provided as an example, which is "EV_WA.zip" in the "Data" directory. This is public data from Electric Vehicle Population Data. This dataset shows the Battery Electric Vehicles (BEVs) and Plug-in Hybrid Electric Vehicles (PHEVs) that are currently registered through the Washington State Department of Licensing (DOL). For the purpose of this repository, the data was split into 4 CSV files by the author.
Feel free to use this for your own data. If you want to deploy with your own data on your existing infrastructure, you can do that. Just make sure to stop your crawler schedule, then deploy with the new data, and then resume the schedule. However, if it is a fresh deployment with your data, you don't need to do anything extra.
Usage
After deployment is finished, wait for 2 minute for the first crawling of database to complete. Then go to the AWS Bedrock console, navigate to the agent section, find your agent, and test your agent with a question, for example:
"What are the 5 model years and types of electric vehicles available in Thurston County?"
Data
This project uses the Electric Vehicle Population Data, which is under the Open Data Commons Open Database License (ODbL) v1.0. You can find the dataset here and the license details here.
Conditions for Use:
- You will cite the dataset in your documentation/scientific publication as appropriate.
- You will include a link to the source of the original dataset with the dataset.
- You will abide by the terms of the ODbL license for attribution and attachment of the license to data.
- You will prominently identify the data as being under the ODbL license. Our customers need to be made aware of the usage in a way that allows them to make reasoned decisions.
Citation:
This dataset shows the Battery Electric Vehicles (BEVs) and Plug-in Hybrid Electric Vehicles (PHEVs) that are currently registered through the Washington State Department of Licensing (DOL). For the purpose of this repository, the data was split into 4 CSV files by the author.
Cleaning Up
To delete all resources created and avoid ongoing charges, run .

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/package-lock.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/package.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/text_to_sql_openapi_schema.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/app.py
Summary of app.py:
- Class: MyStack
- Function: __init__


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/lambda/agent/index.py
Summary of index.py:
- Function: get_schema
- Function: correct_query
- Function: execute_athena_query
- Function: extract_result_data
- Function: compress_data
- Function: save_to_s3
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/use-case-examples/text-2-sql-agent-cdk-enhanced/Data/EV_WA.zip

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/README.md
README Summary:
Agents for Amazon Bedrock - Features examples
In this folder we provide you example implementations for the main Agents for Amazon Bedrock functionality:
1. Create Agent with Function Definition: Example of how to create an HR assistant agent defining the Action Group function and parameters as JSON object that is associated with the Action Group invocation. It connects with an AWS Lambda function to execute the actions
1. Create Agent with API Schema: Example of how to create an Insurance Claim's handler agent using an API schema for the functions and parameters definition. The API schema follows the OpenAPI Specificiation format and connects with an AWS Lambda function for the actions exection.
1. Create Agent with Return of Control: Example of how to create an HR assistant agent defining the Action Group function and parameters as JSON object that is associated with the Action Group invocation. It skips the AWS Lambda function definition to return the control to the user's application.
1. Create Agent with a Single Knowledge: Example of how to create a restaurant assistant agent that connects with a single Knowledge Base for Amazon Bedrock to find informations on the menus for adults and children.
1. Create Agent with Knowledge Base and Action Group: Example of how to create extend the Insurance Claim's handler to connect to a Knowledge Base and get the requirements for missing documents.
1. Using Agent's Prompt and Session Parameters: Example of how to pass prompt and session parameters to an agent invocation in order to extend the agent's knowledge.
1. Changing Agent's Advanced Prompts and creating custom Lambda Parsers: Example of how to change an Agent's advanced prompt and how to create a custom lambda parser for advanced agents use cases

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/06-prompt-and-session-attributes/06-prompt-and-session-attributes.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/06-prompt-and-session-attributes/README.md
README Summary:
Prompt and Session Attributes
In this folder, we provide an example of an HR agent using Agents for Amazon Bedrock with prompt and session attributes.
For greater control of session context, you can modify the SessionState object in your agent. The SessionState object contains two types of attributes that you can use to provide conversational context for the agent during user conversations.
* sessionAttributes  Attributes that persist over a session between a user and agent. All InvokeAgent requests made with the same sessionId belong to the same session, as long as the session time limit (the idleSessionTTLinSeconds) has not been surpassed.
* promptSessionAttributes  Attributes that persist over a single turn (one InvokeAgent call). You can use the \$ prompt_session_attributes\$ placeholder when you edit the orchestration base prompt template. This placeholder will be populated at runtime with the attributes that you specify in the promptSessionAttributes field.
Here is the general format of the session state object:
You can set session attributes at the follwing steps:
When you set up an action group and write the Lambda function, include sessionAttributes or promptSessionAttributes in the response event that is returned to Amazon Bedrock.
During runtime, when you send an InvokeAgent request, include a sessionState object in the request body to dynamically change the session state attributes in the middle of the conversation.
As an example, we can set sessionAttributes for first name. So when a user uses your application and provides their first name, your code will send the first name as a session attribute and the agent will store their first name for the duration of the session. These attributes can be used downstream in the lambda function calls associated with an action group.
In addition, we can also modify session context through promptSessionAttributes.For example, we can retrieve the time zone at the user's location in the case that the user uses a word indicating relative time (such as "tomorrow") in their request. We can then store their time zone in a variable called timeZone. After doing this if the user asks to book a hotel for tomorrow, your code will send the user's time zone to the agent and the agent can determine the exact date that "tomorrow" refers to.
For more details on session attributes, please see Control session context

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/07-advanced-prompts-and-custom-parsers/07-custom-prompt-and-lambda-parsers.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/07-advanced-prompts-and-custom-parsers/README.md
README Summary:
Advanced Prompts and Custom Lambda Parsers
In this folder, we provide an example of an HR agent using Agents for Amazon Bedrock new advanced prompt and custom lambda parser capabilities.
Agents in Amazon Bedrock take a sequence of steps to process a user query: Pre-processing, Orchestration, Knowledge base response generation, and Post-processing. For each step in the sequence Prompt templates are the basis for creating prompts to be provided to the FM. Agents for Amazon Bedrock exposes the default four base prompt templates that are used during the pre-processing, orchestration, knowledge base response generation, and post-processing. You can optionally edit these base prompt templates to customize your agent's behavior at each step of its sequence. This forms the basis for Advanced prompts.
For example, to create a custom pre-processing prompt we can provide the __custom prompt__ string in the __promptOverrideConfiguration__ object in the __UpdateAgent__ call.
In addition, we can provide custom lambda parsers to modify the raw output from the LLM at each of the steps in the agent sequence. This custom lambda parser is often used in conjunction with the custom prompt to give you greater control of not only how process the user query at that step but also
what parts of the output response should be passed onto the next step in the sequence.
To take advantage of custom lambda parsers, a lambda function needs to be created and used to update the agent using the __UpdateAgent__ call. For our pre-processing example, we can provide the lambda arn  to the __overrideLambda__ key in the __promptOverrideConfiguration__ object in the __UpdateAgent__ call, setting the __parserMode__ to __OVERRIDDEN__.
The lambda function provided as the parser needs to respect the structure of event that is produced by  the agent as input as well as respect the structure the agent expects as response from the lambda. Examples of the input and output structure are shown below:
Lambda input event structure:
Lambda response structure for pre-processing:
For examples of the response structures for the other __promptTypes__ see Parser Lambda function in Agents for Amazon Bedrock

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/02-create-agent-with-api-schema/02-create-agent-with-api-schema.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/02-create-agent-with-api-schema/insurance_claims_agent_openapi_schema.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/02-create-agent-with-api-schema/README.md
README Summary:
Create Agents with API Schema
In this folder, we provide an example agent using Agents for Amazon Bedrock integration with API Schema and Lambda functions.
When creating Agents action groups, you can define actions by providing the function details or passing an API Schema. When providing the API Schema, you can define actions more explicitly and map them to API operations in your system. This option requires your API schema file to have the OpenAPI format. You add the API schema to the action group in one of the following ways:
* Upload the schema that you create to an Amazon Simple Storage Service (Amazon S3) bucket.
* Write the schema in the inline OpenAPI schema editor in the AWS Management Console when you add the action group. This option is only available after the agent that the action group belongs to has already been created.
The example agent implements an Insurance Claims Handler that can:
* Get open claims
* Get details for a certain claim
* Get missing paperwork for an existing claim
* Send reminder for an open claim identifying any missing documentation
The architecture of the created agent is as following:
!Insurance Claims Agent
The capabilities are described to the agent using an API Schema in the OpenAPI Schema format.
The code below shows the format of a request for the get open claims functionality:
This code shows an example of how to define API routes with an OpenAPI schema for a Bedrock Agents integration. It has a parent route "/open-items" and a child route that provides different information "/open-items/{claimId}/outstanding-paperwork". Defining these APIs allows your agent to know how and when to use your APIs to collect information.
When creating the Agent's Action Group, the schema definition is passed to the action group via the apiSchema parameter containing the s3 location of the API schema file:
The agent's actions are then implemented as part of an AWS Lambda function that receives the inputs from the Agent via an event.
The event has the following structure where apiPath provides the required path for the action required by the user:
To process the action requested by the Agent, the following code is then added to the Lambda function:
This code collects the Agent's request, processes the request, and then formulates a response to return to the Agent. The response sent back can then be used to answer questions that the end user asks the Agent.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/02-create-agent-with-api-schema/lambda_function.py
Summary of lambda_function.py:
- Function: get_named_parameter
- Function: get_named_property
- Function: claim_detail
- Function: open_claims
- Function: outstanding_paperwork
- Function: send_reminder
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/02-create-agent-with-api-schema/images/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control/README.md
README Summary:
Create Agents with Return of Control (Function Calling)
In this folder, we provide an example of an HR agent using Agents for Amazon Bedrock new capabilities for function definition and return of control for function calling.
Return of control for function calling allows developers to define an action schema and get the control back whenever the agent invokes the action. This provides developers more options to implement business logic in addition to the already available Lambda approach. Furthermore, with Return of Control, developers get the ability to execute time consuming actions in the background (asynchronous execution), while continuing the orchestration flow. For example, if a user requests to encode three different video files, the agent needs to make three individual encode_video API calls. Developers can now build workflows with Return of Control to invoke the three APIs in parallel without waiting for the results from the first call. This feature can allow you as a developer to achieve higher efficiency, more flexibility over how actions are executed, and enhanced workflow management with asynchronous execution for their Agents.
The agent for this section allows the employee to get_available_vacations_days and book_vacations according to the employee's requests.
Both functionalities are implemented in memory in the notebook and would be available in an existent applications for production use cases. The agent use case is similar to the Lab 1, but the function execution happens outside the scope of the agent, as shown in the architecture below:
!HR Assistant Agent
The notebook logic connects with a generated in-memory SQLite database that contains information about employee's available vacation days and planned holidays.
The database structure created is as following:
!Three tables: {employees, vacations, planned_vacations}, employees: {employee_id - INTEGER, employee_name - TEXT, employee_job_title - TEXT, employee_start_date - TEXT, employee_employment_status - TEXT}, vacations: {employee_id - INTEGER, year - INTEGER, employee_total_vacation_days - INTEGER, employee_vacation_days_taken - INTEGER, employee_vacation_days_available - INTEGER}, planned_vacations: {employee_id - INTEGER, vacation_start_date - TEXT, vacation_end_date - TEXT, vacation_days_taken - INTEGER}
The functions are defined using Function Definition as a list of `JSON` objects:
When creating the Agent Action Group, the actionGroupExecutor parameter is set to {'customControl': 'RETURN_CONTROL'} to indicate that no Lambda function is provided and that the agent should return which function to call and with which parameters.
An Agent executing with Return of Control will then output an object containing either `functionInvocationInput`, if a function definition was used (the example presented in this folder), or `apiInvocationInput`, if an API schema was used.
Example `JSON` for function definition:
Example `JSON` for API Schema:
Once the function has been executed, the output of the function is passed to the `invoke_agent` call in the `returnControlInvocationResults` parameter.
Here is the syntax for the agents with function definition:
And the same example with API schema:

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control/03-create-agent-with-return-of-control.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control/images/HR_DB.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control/images/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/knowledge_base.py
Summary of knowledge_base.py:
- Function: interactive_sleep
- Class: BedrockKnowledgeBase
- Function: __init__
- Function: create_s3_bucket
- Function: create_bedrock_kb_execution_role
- Function: create_oss_policy_attach_bedrock_execution_role
- Function: create_policies_in_oss
- Function: create_oss
- Function: create_vector_index
- Function: create_knowledge_base
- Function: start_ingestion_job
- Function: get_knowledge_base_id
- Function: get_bucket_name
- Function: delete_kb
- Function: delete_iam_roles_and_policies
- Function: delete_s3


File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/README.md
README Summary:
Creating Agent with Knowledge Base and an Action Group connection
In this folder, we provide an example of creating an agent with Amazon Bedrock and integrating it with a
Knowledge Base for Amazon Bedrock and with an Action Group.
With this integration, the agent will be able to respond to a user query by taking a sequence of actions,
consulting the knowledge base to obtain more information, and/or executing tasks using the lambda function
connected with an Action Group.
Agent Architecture
In this example we will create a restaurant assistant agent that connects with a Knowledge Base for Amazon Bedrock containing the restaurant's different menus.
This agent also connects to an action group that provides functionalities for handling the table booking in this restaurant.
!Agents architecture - showing an agent responding on one end using APIs and action groups and then on the end responding to other questions with a knowledge base on a vector database
The action group created in this example uses function details to define the functionalities for
`create_booking`, `get_booking_details` and `delete_booking`.
The action group execution connects with a Lambda function that interacts with an Amazon DynamoDB table.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/agent.py
Summary of agent.py:
- Function: create_dynamodb
- Function: create_lambda
- Function: create_lambda_role
- Function: create_agent_role_and_policies
- Function: delete_agent_roles_and_policies
- Function: clean_up_resources


File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/05-create-agent-with-knowledge-base-and-action-group.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/agenteval.yml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/images/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/dataset/Restaurant_Childrens_Menu.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/dataset/Restaurant_Dinner_Menu.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/05-create-agent-with-knowledge-base-and-action-group/dataset/Restaurant_week_specials.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/04-create-agent-with-single-knowledge-base/agents-with-kb.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/04-create-agent-with-single-knowledge-base/README.md
README Summary:
Creating Agent with a Single Knowledge Base
In this folder, we provide an example of creating an agent with Amazon Bedrock and
integrating it with Knowledge Bases for Amazon Bedrock.
With this integration, the agent will be able to respond to a user query by taking a sequence of actions,
consulting the knowledge base to obtain more information, and finally responding to the user with an answer.
!Agents with Knowledge Bases for Amazon Bedrock
In this notebook you will learn how to create an Amazon Bedrock Agent that makes use of Knowledge Bases to retrieve information relevant to a certain use case.
We will create a Bedrock Assistant Agent that allows users to ask questions about the Bedrock User Guide based on the documents uploaded to the Knowledge Base.
The architecture created looks as following:
!Bedrock Assistant
The code presented in this lab provides the following functionality:
1. Import the needed libraries
2. Upload the dataset to Amazon S3
3. Create the Knowledge Base for Amazon Bedrock using the Boto3 Agents for Bedrock SDK
4. Create the Agent for Amazon Bedrock using the Boto3 Agents for Bedrock SDK
5. Test the Agent using the Boto3 Agents for Bedrock Runtime SDK
6. Clean-up the resources created

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/04-create-agent-with-single-knowledge-base/04-create-agent-with-single-knowledge-base.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/04-create-agent-with-single-knowledge-base/kb_documents/bedrock-ug.pdf

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/04-create-agent-with-single-knowledge-base/images/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/10-create-agent-with-memory/10-create-agent-with-memory.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/10-create-agent-with-memory/README.md
README Summary:
Create Agents with memory
In this folder, we provide an example of travel agent using Agents for Amazon Bedrock new capabilities for memory.
When creating you agent, you can enable the memory capabilities using the `memoryConfiguration` parameter. You can then invoke you agent with a `memoryId` to track sessions and summarize them to your memory.
In this example we will create a test agent with the following architecture:
!Agent architecture
The code below shows how to configure the memory capabilities when creating your agent using the `create_agent` function from boto3 SDK. You should define the  `enabledMemoryTypes` (currently only `SESSION_SUMMARY` is available) and the `storageDays`.
When invoking your agent, you need to pass the `memoryId` parameter as well as a `sessionId`.
Once you invoke the agent with the `endSession` flag set to `True`, the conversation with the same `sessionId` is summarized and made available to the agent's memory. You can use the `get_agent_memory` from the `bedrock-agent-runtime` boto3 SDK client to get the available memory for an agent
And the `delete_agent_memory` to delete **the full** agent memory for a certain memory id.

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/10-create-agent-with-memory/images/architecture.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/template.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/README.md
README Summary:
Designing secure generative AI Application workflows with Amazon Verified Permissions and Agents for Bedrock
Link AWS Blog: https://aws.amazon.com/blogs/aws/ \
Link to Amazon Verified Permissions: https://aws.amazon.com/verified-permissions/
This is sample code we will demonstrate how to design fine-grained access controls using Verified Permissions for a generative AI application that uses agents for Bedrock to answer questions about insurance claims that exist in a claims review system using textual prompts as inputs and outputs.
**Architecture presented in this Repo:**
The architecture and flow of the sample application will be:
!Alt text
The application architecture flow is as follows:
1. User accesses the Generative AI Claims web application (App)
2. The App authenticates the user with the Amazon Cognito service and issues an ID Token and an Access Token. The ID token has the user's identity and custom attributes.
3. Using the App, the user sends a request asking the application to "list the open claims". The request is sent along with the user's ID Token and Access Token. The App calls the Claims API Gateway API to execute the Claims proxy passing user request and tokens.
4. Claims API Gateway runs the Custom Authorizer to validate the access token
5. When access token validation is successful, the Claims API Gateway sends the user request to the Claims Proxy
6. The Claims Proxy invokes the Bedrock Agent passing the user request and ID token. Bedrock agent is configured to use the Anthropic Claude model and to execute actions using the Claims Agent Helper Lambda function
7. Bedrock Agent leverages chain-of-thought-prompting and builds the list of API actions to execute with the help of Claims Agent Helper
8. The Claims Agent Helper retrieves Claim records from Claims DB and constructs claims list object
9. The Claims Agent Helper retrieves user's metadata(i.e. name, sub ) from ID token, builds the Verified Permissions data entities and makes the Verified Permissions authorization request. This request contains the principal (user/role), action (i.e. ListClaim) and resource (Claim). Verified Permissions evaluates the request against all Verified Permissions policies and return Allow or Deny decision. Subsequently, the Claims Agent Helper filters the claims based on that decision. Note that Verified Permissions has 'default deny' functionality; in the absence of an explicit allow, the service defaults to an implicit deny. If there is an explicit Deny in any of the policies involved in the request, Verified Permissions denies the request
10. The Claims Bedrock Agent receives the authorized list of claims, augments the prompt and sends it to Claude model for completion. The Agent returns the completion back to the caller.
How to use this Repo:
Prerequisites:
1. Amazon Bedrock Access and AWS CLI Credentials are configured.
2. Ensure that AWS CLI is installed on your machine. It can be downloaded here
3. Ensure Python 3.9+ installed on your machine, it is the most stable version of Python for the packages we will be using, it can be downloaded here.
4. Go to the Amazon Bedrock console, Click on Model Access, Select the Anthropic models and save changes.
5. The solution was tested in us-east-1
6. AWS SAM CLI is installed. Instructions [here] (https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html)
7. Install Amplify CLI [here] (https://docs.amplify.aws/gen1/react/start/getting-started/installation/). If running in Cloud shell, you can use the below command:
Step 1:
The first step of utilizing this repo is performing a git clone of the repository and navigate to the folder.
Step 2:
Managing CLI parameters as Environment Variables.
Start with setting a default region. This code was tested in us-east-1.
Step 3:
The below step will use AWS SAM (Serverless Application Model) to create the following resources as Nested Stacks:
1. Amazon Verified Permissions Policy Store and Policies
2. Cognito User Pool
3. Amazon Bedrock Agent
4. Amazon API Gateway
5. Cloud 9 Environment
Please ensure that your AWS CLI Profile has access to run CloudFormation and create resources!
When you run the command, AWS SAM will prompt for few questions, enter "claims-app" for the stack name and retain defaults for rest of the questions
Step 4 - Set the environment variables
Step 5:
Set credentials in Amazon Cognito for test users follows:
Step 6:
Run the below command to change to the frontend directory. Then run the following command to deploy the frontend application :
Step 6.1 - Set the environment variables in env file
Step 6.2 - Initialize Amplify project
The amplify init command is used to initialize a new Amplify project. This command sets up the project directory, configures deployment resources in the cloud, and prepares the project for further Amplify operations.
You will enter "bedrocksecurity" for name of the project and follow the prompts. You can use the below to help you configure:
After initialization, you'll see deployment progress:
You'll be asked about sharing project configurations. Follow the prompts:
Finally, you'll see confirmation messages:
Run this command to link the Cognito User pool that was created in CloudFormation to the Amplify application that we are deploying. This will ensure that the requests will be authenticated by the users in the Cognito userpool.
You will use the below details for configuration:
You will then see this message:
Step 6.3 - Add Amplify hosting
Step 6.4 - Publish Amplify project
Run the below command to publish the project to AWS Amplify. You will use the below details for configuration:
Deployment will complete with below information and a URL will be printed. :
Make a note of the URL and use that to login to the depoloyed application.
Step 7:
At this time, please go to the AWS Bedrock console, then go to Model Access and add access to Claude 3 Sonnet under Anthropic models. This step important for the account to leverage the Claude 3 Sonnet model via Bedrock.
!Alt text
Step 8:
You will login to the application with the username: claims-app-adjuster followed by the password set for the user. Upon login, you will see the claims application.
!Alt text
You can begin asking questions in textbox like using natural language questions like :
1. list all claims
2. get claim details for claim 101
3. update claim details for claim 101
You can head over the CloudWatch logs console to view the logs and observe how the Identity token is being sent to the bedrock agent.
First observe logs for : Claims Iinvoke Bedrock Agent
!Alt text
Followed by logs for : Claims Actiongroup Lambda
!Alt text

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/.gitignore

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/.gitignore

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/package.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/amplify-headless-init-payload.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/public/index.html

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/public/manifest.json

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/public/robots.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/reportWebVitals.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/App.css

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/index.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/index.css

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/aws-exports.tmplt.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/App.test.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/setupTests.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/005_Frontend/src/App.js

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/001_avp/template.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/images/claims-invoke-bedrock-agent.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/images/claims-app.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/images/bedrock-model-access.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/images/Architecture_AVP_bedrock_agents.jpg

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/images/claims-actiongroup-lambda.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/003_bedrock-agent/template.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/003_bedrock-agent/agent/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/003_bedrock-agent/agent/agent.py
Summary of agent.py:
- Function: get_named_parameter
- Function: list_claims
- Function: get_claim
- Function: update_claim
- Function: lambda_handler
- Function: verifyAccess
- Function: verifyJWT_getUserInfo
- Function: getActionID
- Function: handle_is_authorized
- Function: construct_authz_request_from_token


File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/004_apigateway/template.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/004_apigateway/invoke-lambda/requirements.txt

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/004_apigateway/invoke-lambda/invoke_lambda.py
Summary of invoke_lambda.py:
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions/002_cognito/template.yaml

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/01-create-agent-with-function-definition/README.md
README Summary:
Create Agents with Function Definition
In this folder, we provide an example of an HR agent using Agents for Amazon Bedrock new capabilities for function definition.
When creating Agents action groups, you can define actions by providing the function details or passing an API Schema. When providing the function details you can simplify the action group creation process and set up the agent to elicit a set of parameters that you define. You can then pass the parameters on to your application and customize how to use them to carry out the action in your own systems.
The agent connects with an in-memory SQLite database that contains generated data about employee's available vacation days and planned time off. The architecture created is as following:
!HR Assistant Agent
Where the vacation database has the following schema:
!Three tables: {employees, vacations, planned_vacations}, employees: {employee_id - INTEGER, employee_name - TEXT, employee_job_title - TEXT, employee_start_date - TEXT, employee_employment_status - TEXT}, vacations: {employee_id - INTEGER, year - INTEGER, employee_total_vacation_days - INTEGER, employee_vacation_days_taken - INTEGER, employee_vacation_days_available - INTEGER}, planned_vacations: {employee_id - INTEGER, vacation_start_date - TEXT, vacation_end_date - TEXT, vacation_days_taken - INTEGER}
The agent allows the employee to `get_available_vacations_days` and `reserve_vacation_time` according to the employee's requests.
The code below shows the definition of the functions as a list of JSON objects that is passed to the Agent's Action group via the `functionSchema` parameter
The function definition is passed to the `create_agent_action_group` function as the `functionSchema` parameter
Both actions are implemented as part of an AWS Lambda function that receives the inputs from the Agent via an event.
The event has the following structure:
To process the action that the Agent is invoking, you need to recover the action group, function and parameters from the `event` and return the response as a `JSON` object with a `TEXT` key. To do so, the following code is added to the Lambda function:

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/01-create-agent-with-function-definition/01-create-agent-with-function-definition.ipynb

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/01-create-agent-with-function-definition/images/HR_DB.png

File: source/amazon-bedrock-samples-main/agents-for-bedrock/features-examples/01-create-agent-with-function-definition/images/architecture.png

File: source/amazon-bedrock-samples-main/prompt-engineering/Prompt Decomposition.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/README.md
README Summary:
Prompt Engineering
This folder contains information to get you started with prompt engineering on Amazon Bedrock.
!Prompt Engineering
Prompt engineering is the practice of optimizing the quality and performance of your foundation model's response to your request. Prompt engineering may involve:
- Word choice
- Phrasing
- Providing examples (few-shot learning)
- Use of line breaks and content separators
- Following established formats that align with how the model was trained
- Use of stop sequences to help the model know when it should stop generating text
Contents
While general best practices for prompt engineering are still emerging, it is best to understand how each model works. Some prompts may be portable between providers, but many won't. You will likely need to alter and optimize your prompts if you want to try different providers.
You can learn more about prompt engineering in the prompt engineering basics lab.
Below are prompt engineering guides provided by some of Amazon Bedrock's model providers:
- AI21 Prompt Engineering
- Anthropic Claude Prompt Design
- Cohere Prompt Engineering
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/prompt-engineering/Prompt Evaluation.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/Setup.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/requirements.txt

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/Chat_application.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/Function_agent.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-diy/index.faiss

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-diy/index.pkl

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/embeddings_lang.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/chatbot_bedrock.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/terminal.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/chatbot_lang.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/vector_embedding.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/api.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/context-aware-chatbot.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/images/vector_db.jpg

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/README.md
README Summary:
Working with multimodal data using Amazon Bedrock
With the `Amazon Titan Multimodal Embeddings G1` model, you can create embeddings for multimodal data, specifically text and image data. These embeddings can then be used for multimodal search and Retrieval Augmented Generation (RAG) use-cases, for example searching images by text only, images only or a combination of text and images.
!Amazon Titan Multimodal Embeddings G1
Contents
- Multimodal RAG - Multimodal RAG using the Amazon Berkley Objects dataset.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/images/titan-embeddings-g1-image.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/mm_search.ipynb

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/README.md
README Summary:
Build a contextual text and image search engine for product recommendations using Amazon Bedrock and Amazon OpenSearch Serverless
[WIP - 02/07/2024]
This repository aims at building a Large Language Model (LLM) powered search engine prototype to retrieve and recommend products based on text or image queries. This is a step-by-step guide on how to create Amazon Bedrock Titan models to encode images and text into embeddings, ingest embeddings into Amazon OpenSearch Service Serverless index, and query the index using OpenSearch Service k-nearest neighbors (KNN) functionality.
<ins> Introduction </ins>
The rise of contextual and semantic search has made ecommerce and retail businesses search easier for its consumers. Search engines and recommendation systems powered by Generative AI can improve product search experience exponentially by understanding natural language queries and returning more accurate results. This enhances the overall user experience helping customers to find what exactly they are looking for.
<ins> Solution overview </ins>
This solution includes the following components:
- Amazon Titan Multimodal Embeddings model: This FM is used to generate embeddings of the products images used in this blog. Using Titan Multimodal Embeddings, you can generate embeddings for your content and store them in a vector database. When an end user submits any combination of text and image as a search query, the model generates embeddings for the search query and matches them to the stored embeddings to provide relevant search and recommendations results to end users. You can further customize the model to enhance its understanding of your unique content and provide more meaningful results using image-text pairs for fine-tuning. By default, the model generates vectors (embeddings) of 1024 dimensions, and is accessed via the Amazon Bedrock service. You can also generate smaller dimensions to optimize for speed and performance
- Amazon OpenSearch Service Serverless: OpenSearch Service Serverless is an on-demand serverless configuration for Amazon OpenSearch Service. We use OpenSearch Service Serverless as a vector database for storing embeddings generated by the Titan Multimodal Embeddings model. An index created in the OpenSearch Service Serverless collection serves as the vector store for our RAG solution.
- Amazon SageMaker Studio: SageMaker Studio is an integrated development environment (IDE) for machine learning (ML). ML practitioners can perform all ML development stepsfrom preparing their data to building, training, and deploying ML models
<ins> Solution Design </ins>
The solution design consists of two parts  Data Indexing and Contextual Search. During Data Indexing, we process the product images to generate embeddings for these images and then populate the vector data store. These steps are completed prior to the user interaction steps.
In the Contextual Search phase, a search query (text or image) from the user is converted into embeddings and a similarity search is run on the vector database to find the similar product images based on similarity search. We then display the top similar results.
ARCHITECTURE:
!alt text
Following are the solution workflow steps:
1.	Download the product description text & images from public S3 bucket
2.	Review and Prepare the dataset.
3.	Generate embeddings for the product images using Titan Multimodal Embeddings (amazon. titan-embed-image-v1) multi-modal. If you have huge number of images and descriptions, then you can optionally use Amazon Bedrock Batch API.
4.	Store embeddings into vector engine for Amazon OpenSearch Service Serverless as the search engine.
5.	Finally, fetch the user query in natural language, convert it into embedding using Titan Multimodal Embeddings (amazon. titan-embed-image-v1) multi-modal, and perform a k-NN search. To get the relevant search results.
<ins> Dataset </ins>
The Amazon Berkeley Objects Dataset is used in the implementation. The dataset is a collection of 147,702 product listings with multilingual metadata and 398,212 unique catalogue images. We will only make use of the item images and item names in US English. For demo purposes we are going to use ~1,600 products.
Running Costs
This section outlines cost considerations for running this demo. Completing the POC will deploy a OpenSearch Cluster, a SageMaker Studio and will use Amazon Bedrock, which will cost approx. $X per hour. Noted: the price listed below is calculated using us-east-1 region. The cost varies from region to region. And the cost may change over time as well (the price here is recorded 2024-02-04).
Further cost breakdowns are below.
- **Amazon Bedrock**  Please visit the Amazon Bedrock Pricing to learn more about the pricing options.
- On-demand pricing for text embeddings, The Titan Multimodal Embeddings costs $0.0008 per 1,000 input tokens
- On-demand pricing fo image embeddings, The Titan Multimodal Embeddings costs $0.00006 per 1,000 input tokens
- **OpenSearch Service**  Prices vary based on instance type usage and Storage cost. For more information, see Amazon OpenSearch Service pricing.
- The `t3.small.search` instance runs for approx 1 hour at \$0.036 per hour.
- **SageMaker**  Prices vary based on EC2 instance usage for the Studio Apps, Batch Transform jobs and Serverless Inference endpoints. For more information, see Amazon SageMaker Pricing.
- The `ml.t3.medium` instance for *Studio Notebooks* runs for approx 1 hour at \$0.05 per hour.
- The `ml.c5.xlarge` instance for *Batch Transform* runs for approx 6 minutes at \$0.204 per hour.
- **Amazon S3**  Low cost, prices will vary depending on the size of the models/artifacts stored. The first 50 TB each month will cost only $0.023 per GB stored. For more information, see Amazon S3 Pricing.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/utils.py
Summary of utils.py:
- Function: get_titan_multimodal_embedding
- Function: plot_similarity_heatmap
- Function: get_image_from_item_id
- Function: get_image_from_item_id_s3
- Function: display_images
- Function: find_similar_items_from_query
- Function: find_similar_items_from_image


File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/LICENSE.txt

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/images/departure_rate.jpg

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/images/contextual_search_arch.png

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/data/images/ea0c6da6.jpg

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/multimodal/faiss-multimodal/data/images/075e5d67.jpg

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/data/letter/2022.txt

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/data/book/book.txt

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/data/sagemaker/sm_faq_v2.csv

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/data/sagemaker/sagemaker_faqs.csv

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/llama-index/vector_store.json

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/llama-index/graph_store.json

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/llama-index/index_store.json

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/llama-index/docstore.json

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/langchain/index.faiss

File: source/amazon-bedrock-samples-main/prompt-engineering/session-4/faiss-index/langchain/index.pkl

File: source/amazon-bedrock-samples-main/prompt-engineering/images/prompt_engineering.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_anthropic_claude3.py
Summary of bedrock_anthropic_claude3.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_stability.py
Summary of bedrock_stability.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/model_choice_converse_bedrock_streamlit.py
Summary of model_choice_converse_bedrock_streamlit.py:
- Function: invoke_bedrock_model
- Class: ModelThread
- Function: invokeModelsInParallel
- Function: __init__
- Function: run


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_amazon_titan_embeddings.py
Summary of bedrock_amazon_titan_embeddings.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_api.py
Summary of bedrock_api.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_mixtral.py
Summary of bedrock_mixtral.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/Getting_started_with_Converse_API.ipynb

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/getting_started_converse_bedrock_streamlit.py
Summary of getting_started_converse_bedrock_streamlit.py:
- Function: invoke_bedrock_model


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/README.md
README Summary:
Getting Started with Bedrock
With the Amazon Bedrock serverless experience, you can quickly get started, easily experiment with FMs, privately customize FMs with your own data, and seamlessly integrate and deploy them into your applications using AWS tools and capabilities.
This repository contains examples to get you started with the core Amazon Bedrock APIs for each of the foundational model providers.
!Bedrock Models
Contents
- Getting Started with Bedrock Converse API - Notebook - Example notebook to illustrate the basics of the Converse API
- Getting Started with Bedrock Converse API - Streamlit demo - Streamlit demo to illustrate the basics of the Converse API
- Model Choice with Bedrock Converse API - Streamlit demo - Streamlit demo to illustrate the model choice with the Converse API
- Model Choice with Bedrock Converse API - Demo script - Script demo to illustrate the model choice with the Converse API
- Getting Started with the API - Simple example using the REST API
- Example using the Python SDK - Simple example using the Python SDK
- Streaming your responses - Example that streams your response from Bedrock
- Using Embeddings models from Amazon - Syntax for using Amazon Titan Embeddings
- Using Text models from Amazon - Syntax for using Amazon Titan Text
- Using models from Anthropic - Syntax for using models from Anthropic - Claude
- Using models from Stability - Syntax for using models from Stability - Stable Diffusion
- Using models from AI21 Labs - Syntax for using models from AI21 Labs - Jurassic
- Using models from Cohere - Syntax for using models from Cohere - Command
- Anthropic Multi-Model Models - Syntax Multi-Modal models from Anthropic Claude v3 Models
- Single and Mult-turn text generation with Messages API - Examples to illustrate the new Claude Messages API
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_amazon_titan_text.py
Summary of bedrock_amazon_titan_text.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_cohere.py
Summary of bedrock_cohere.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_anthropic.py
Summary of bedrock_anthropic.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/cat.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_mistral.py
Summary of bedrock_mistral.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/Getting_started_with_Prompt_Management_Flows.ipynb

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_meta.py
Summary of bedrock_meta.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_sdk.py
Summary of bedrock_sdk.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/model-choice-demo-converse-api.py
Summary of model-choice-demo-converse-api.py:
- Function: invoke_bedrock_model
- Class: ModelThread
- Function: invokeModelsInParallel
- Function: __init__
- Function: run


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_streaming.py
Summary of bedrock_streaming.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/Claude-MessagesAPI-Examples.ipynb

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/bedrock_ai21.py
Summary of bedrock_ai21.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/images/bedrock.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/images/bedrock_models.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/README.md
README Summary:
Create your first Amazon Bedrock generative AI application
This repository contains the code for deploying your first application with Amazon Bedrock using AWS CDK
For this exercise, we will create and application that processes the text content from emails and extract information from them.
For simplicity and in order to ensure compatibility with multiple customer setups, two options are presented:
* **process-dynamodb-table-bedrock:** assumes that your emails have been extracted to a dynamoDB and are indexed via `thread_id`. This option is useful for the cases where you already have the emails extraction workflow connected to an existent pipeline, and you would like to extract the information from existent data
* **process-emails-bedrock:** connects to your email service using Amazon Simple Email Service (SES) and Amazon Simple Notification Service (SNS) to process new emails that are sent to a certain email box. This option is specially interesting for cases where a central email address is used to connect customers to a certain business.
Both options process the emails using AWS Lambda to query Bedrock. To get started, select your preferred solution and follow the intructions of the `README.md` file of the respective folder.
For educational purposes, the notebook `GettingStartedWithAmazonBedrock.ipynb` provides examples of how to get started with Amazon Bedrock, invoking different models and applying prompt engineering techniques.

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/GettingStartedWithAmazonBedrock.ipynb

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/requirements.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/README.md
README Summary:
Processing Emails with Amazon Bedrock
Sample Authors: Aditi Rajnish, Mara Ladeira Tanke, Raj Pathak
This repo contains an AWS CDK solution for automatically processing emails using Amazon Bedrock, Simple Email Service (SES), Amazon Simple Notification Service (SNS), AWS Lambda, and Amazon DynamoDB.
To get start and set up your environment:
Navigate to the cdk-app
Install dependencies
The `cdk.json` file tells the CDK Toolkit how to execute your app.
This project is set up like a standard Python project.  The initialization
process also creates a virtualenv within this project, stored under the `.venv`
directory.  To create the virtualenv it assumes that there is a `python3`
(or `python` for Windows) executable in your path with access to the `venv`
package. If for any reason the automatic creation of the virtualenv fails,
you can create the virtualenv manually.
To manually create a virtualenv on MacOS and Linux:
After the init process completes and the virtualenv is created, you can use the following
step to activate your virtualenv.
If you are a Windows platform, you would activate the virtualenv like this:
Once the virtualenv is activated, you can install the required dependencies.
Initialize the account and region for the CDK. This will create the S3 buckets and roles for the CDK tool to store artifacts and to be able to deploy infrastructure.
At this point you can now synthesize the CloudFormation template for this code.
Deploy Stack
Deploy the stack:
Manual Actions to connect Amazon SES to Amazon SNS
Verify that the stack is fully deployed.
Create Rule Set
Navigate to Amazon SES and go to the "Email receiving" section. Either create a rule set and make it active, or use an already active rule set. In our example, we create a new rule set.
!Create Rule Set
Activate Rule Set and Create Rule
Within that rule set, make it active (if it isn't already) and create a rule.
!Activate Rule Set and Create Rule
Create Rule - Steps 1 & 2
Name the rule and (optionally) set the recipient conditions, such as only using a test user.
!Create Rule Step 1
!Create Rule Step 2
Create Rule - Step 3: Add Action
Add a new action using the "Publish to Amazon SNS topic" option.
!Create Rule Step 3 - Add Action
Create Rule - Step 3: Select SNS Topic
Select the SNS topic created by the CDK stack ("ProcessEmailBedrockStack.ProcessEmailBedrockTopicName" in the Stack outputs) and keep the Base64 Encoding option selected.
!Create Rule Step 3 - Select SNS Topic
Rule Created
After reviewing this rule, create it, and you should see it in your rule set. Based on the conditions you set, emails that are received will be automatically processed using Amazon SNS and Lambda, leveraging Amazon Bedrock and storing results in the Amazon DynamoDB table.
!Rule Created

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/requirements.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/cdk.json

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/source.bat

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/.gitignore

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/app.py
Summary of app.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/lambdas/bedrock_boto3_layer.zip

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/lambdas/build_lambda_layer.sh

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/lambdas/process_emails_with_bedrock/lambda.py
Summary of lambda.py:
- Function: get_decoded_content_text
- Function: parse_float
- Function: process_emails_with_bedrock
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/lambdas/process_emails_with_bedrock/prompt.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/cdk_app/__init__.py
Summary of __init__.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/cdk-app/cdk_app/cdk_app_stack.py
Summary of cdk_app_stack.py:
- Class: ProcessEmailBedrockStack
- Function: __init__


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/4-create-rule-step-2.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/3-create-rule-step-1.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/2-activate-rule-set.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/5-create-rule-step-3-add-action.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/7-create-rule-complete.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/1-email-receiving-create-rule-set.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-emails-bedrock/manual_steps/6-create-rule-step-3-choose-sns-topic.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/requirements.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/Makefile

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/cdk.json

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/source.bat

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/README.md
README Summary:
Processing an Amazon DynamoDB table with Amazon Bedrock
This repo contains an AWS CDK solution for automatically process an Amazon DynamoDB table using Amazon Bedrock via an AWS Lambda function.
The following architecture is deployed with this repository
!Architecture Diagram
Pre-requisites
This repository assumes that Amazon Bedrock has `Antropic Claude-V2` enabled.
Check the Model Access documentation for more details.
Deploying Solution
Follow the next steps to deploy this solution
Navigate to the app
Install dependencies
The `cdk.json` file tells the CDK Toolkit how to execute your app.
This project is set up like a standard Python project.  The initialization
process also creates a virtualenv within this project, stored under the `.venv`
directory.  To create the virtualenv it assumes that there is a `python3`
(or `python` for Windows) executable in your path with access to the `venv`
package. If for any reason the automatic creation of the virtualenv fails,
you can create the virtualenv manually.
To manually create a virtualenv on MacOS and Linux:
After the init process completes and the virtualenv is created, you can use the following
step to activate your virtualenv.
If you are a Windows platform, you would activate the virtualenv like this:
Once the virtualenv is activated, you can install the required dependencies.
Initialize the account and region for the CDK. This will create the S3 buckets and roles for the CDK tool to store artifacts and to be able to deploy infrastructure.
At this point you can now synthesize the CloudFormation template for this code.
Deploy Stack
Deploy the stack:
Validating Deployment
To validate that your deployment was successful, navigate to Amazon DynamoDB and ensure that test email data has been populated to the `EmailsData` table
* Search for DynamoDB on the AWS console
!Amazon DynamoDB
* Click on `Tables` on the left menu
!Tables Menu
* Click on the `EmailData` table
!Tables List
* Click on `Explore Table Items` button
!Explore Items
* Check the default emails data that is automatically populated on your table
!Table Items
Processing Emails
To process the emails stored in the Amazon DynamoDB table, you should use the `emails-processing-app` lambda function
* Search for Lambda on the AWS console
!AWS Lambda
* Click on the `emails-processing-app` lambda function
!Email Processing Lambda
* Click on the `Test` button
!Test button
* Create your test event
!Test Event
* Click on the `Test` button again for testing the application
!img.png
Validate Extracted Information
You can now navigate to the `EmailsInformationExtracted` DynamoDB table and `Explore Table Items` to validate your extracted information
!img.png
Click on the item to check the details
!img.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/requirements-dev.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/app.py
Summary of app.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/__init__.py
Summary of __init__.py:


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/process_dynamodb_table_bedrock_stack.py
Summary of process_dynamodb_table_bedrock_stack.py:
- Class: ProcessDynamoDBTableBedrockStack
- Function: __init__


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/cdk_helper_scripts/zipimage/Dockerfile

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/populate_dynamodb_table/emails.csv

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/populate_dynamodb_table/lambda_function.py
Summary of lambda_function.py:
- Function: save_data_to_dynamodb
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/process_dynamodb_table_bedrock_lambda/prompt.txt

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/process_dynamodb_table_bedrock/process_dynamodb_table_bedrock_lambda/lambda_function.py
Summary of lambda_function.py:
- Function: create_emails_tags
- Function: save_extracted_info
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/extracted_info_details.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/tables_menu1.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/email-processing-app.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/tables_list.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/navigate_lambda.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/lambda_outputs.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/table_items.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/architecture_diagram.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/extracted_information.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/test_event.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/navigate_dynamodb.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/test_button.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/create_your_first_bedrock_application/process-dynamodb-table-bedrock/images/explore_items.png

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/java/README.md
README Summary:
Java Bedrock REST Api Samples
This repository contains sample of how you can call `invokeModel` REST API and sign it with AWSSigV4 for Amazon Bedrock using Java programming language. The example uses Meta LLama 2 model but you can substitute it with any currently available model isd found on AWS website.
Contents
- Run invokeModel API with Java - Call invokeModel Amazon Bedrock REST API and sing it with AWSSigV4 using Java programming language
Getting Started
To get started with the samples, follow these steps:
1. Clone the repository: `git clone https://github.com/aws-samples/amazon-bedrock-samples.git`
2. Navigate to the `introduction-to-bedrock/java/src/my-app` folder: `cd introduction-to-bedrock/java/src/my-app`
3. Open the `App.java` file in your preferred Java IDE.
4. Make sure you have your AWS credentials stored in the `credentials` file on your local machine.
5. Make sure you have Java and Maven installed on your machine.
6. Build and run the application. To do that you can run `mvn clean compile && mvn exec:java -Dexec.mainClass="com.mycompany.app.App" -e`
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/java/my-app/pom.xml

File: source/amazon-bedrock-samples-main/introduction-to-bedrock/java/my-app/src/main/java/com/mycompany/app/App.java

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/1_get_inference.ipynb

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/LICENSE

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/requirements.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/config.yaml

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/README.md
README Summary:
Get inferences and model evaluations using an _LLM as a judge_
This examples demonstrates how to evaluate LLM responses with another LLM acting as a judge. Responses are generated from multiple LLMs and then another LLM is asked to evaluate the responses based on a rubric (conciseness, clarity, correctness) and pick a response that best matches this criteria, additionally we also ask the judge LLM to provide an explanation why a particular model's response was selected and why responses from other models were not selected.
!LLM as a judge workflow
In this solution we take a dataset of prompts and generate inferences using multiple LLMs (configurable) and then run these responses through an evaluation solution. An LLM is used to act as a judge that goes through each user question, context and model completions, and gives the model response that best matches/answers the question in terms of _conciseness, clarity, correctness_. As a final step, all the explanations provided by the LLM as a judge is run through another final layer of analysis through an LLM to get overall patterns and trends as to why a particular model was selected more times than the other models for the given dataset.
*All the parameters can be configured in the config.yaml file. The dataset used for this sample is synthetically generated, and the pre existing responses are standard definitions or human generated answers*.
Prerequisites
Set up the environment
1. Run this code on an AWS platform so as to not include internet latency in the inference latency for the response.
1. Setup a Python3.11 `conda` environment for running this code.
Bring your own dataset
This repo contains a sample dataset file `data.csv` that has synthetic data for questions about physics and chemistry concepts. The task for the model is to provide answers to these questions.
Follow the steps below to replace the same dataset provided with your own dataset.
The dataset is provided by the user, which contains a _user question_, _system prompt_ (optional), and a _pre existing response_ (optional).
1. Configure your parameters in the `config.yaml` file.
1. Set the `dataset_file_name` in `dir_info` section to the name of your file. We currently support `xlsx`/`xls`/`csv` formats. Place your file in the `data/source_data` folder.
1. Your dataset should either contain the complete prompt with context as a _user prompt_ in the or it should contain the _user prompt_ and _system prompt_ separately.
1. If your dataset only contains the user prompt then set the name of the column containing the user prompt in the `user_question_col` file in the `dataset_info` section. If your dataset also contains an output from another model that you want to compare against then set that column name via `pre_existing_response_col`. Set the `system_prompt_col` to empty.
1. If your dataset has a user prompt and system prompt both then set the column names via `user_question_col` and `system_prompt_col`.
Steps to run
1. Setup the Python 3.11 `conda` environment, activate it as described in the Prerequisites section.
1. Open the `1_get_inference.ipynb` notebook, select the `llm_as_a_judge_eval_py311` kernel and do a `Run All` to run all the cells. This notebook runs inferences on models (specified in the config file) against your custom dataset. This creates the following files:
1. `all_results.csv`: This file contains the results/responses from all the models that ran inferences, original question, target responses (if any) and their associated metrics.
1. Open the `2_run_llm_as_a_judge_eval.ipynb` notebook, select the `llm_as_a_judge_eval_py311` kernel and do a `Run All` to run all the cells. This notebook implements the evaluation solution using an LLM as a judge and a final analysis summarizer:
1. The following output files are created in the `data` folder.
1. `llm_as_a_judge_comparisons.csv`: This file contains the best_match_answer, selected_model and explanation in JSON format. It contains information on which model had an answer that best matched to the task that was provided, along with an explanation of why it was selected and why others werent.
1. `llm_as_a_judge_comparisons.txt`: a text file to read all the comparison responses from the LLM as a judge.
1. `inference_latency_summary.txt`: a text file that contains the `p50` and `p95` of the inference latency for each model.
1. `llm_as_a_judge_pick_rate.csv`: Shows the LLM as a judge pick rate.
1. `final_analysis.txt`: Shows the final analysis report generated by Claude 3 Sonnet based on all evaluations done by the LLM as a judge
1. `all_explanations.csv`: All selected models and respective explanations generated by the LLM as a judge in a text file.
Run the LLM as a judge solution via a single command
Run the following command which will run all the notebooks included in this repo in the correct order.
**_Here is an example final analysis that is generated on the evaluations done on the synthetic data (`data.csv`) by the LLM as a judge_**.
_Based on the context provided, the model anthropic.claude-3-haiku-20240307-v1:0 was selected more frequently than the other models. The key reasons for its selection appear to be its ability to provide clear, concise, and comprehensive explanations on various scientific concepts and phenomena_.
_This model's responses were often praised for their clarity, directly addressing the questions and covering the essential points without extraneous information. For instance, its explanation of the Heisenberg uncertainty principle was described as 'complete and accurate,' while its description of the difference between nuclear fission and fusion was deemed 'clear and concise.'_
_Furthermore, the anthropic.claude-3-haiku-20240307-v1:0 model was commended for its ability to provide comprehensive overviews and explanations, such as its coverage of the development of atomic models and the significance of the photoelectric effect in the context of quantum mechanics_.
_In contrast, the other models were often criticized for providing incomplete, inaccurate, or vague responses, lacking the clarity and comprehensiveness of the anthropic.claude-3-haiku-20240307-v1:0 model. For example, model_1's answer on catalysts was deemed incomplete, while anthropic.claude-3-sonnet-20240229-v1:0's explanation on classical and quantum mechanics lacked clarity_.
_Overall, the anthropic.claude-3-haiku-20240307-v1:0 model was consistently praised for its ability to provide clear, concise, and comprehensive explanations on various scientific topics, making it the preferred choice for this specific dataset_.
LLM as a judge prompts
There is a prompt template directory in this sample with prompts for different purposes as follows. Change them as appropriate for your use case (for example to add additional evaluation criteria)
1. `llama3_eval_prompt.txt`: This is the LLM as a judge prompt for the `Llama3-70b Instruct` model. This is used to parse through all the model responses, user questions, and inference results to give the best selected model for each question and a corresponding explanation as to why it chose that model.
1. `claude_eval_prompt.txt`: This is the LLM as a judge prompt for `Claude 3` in case you would like to use Claude 3 as a judge.
1. `claude_final_summary_prompt.txt`: This is the prompt template used by `Claude 3` to generate a final analysis summary of the evaluations and explanations from LLM as a judge.
1. Change the LLM as a judge/final summarizer models and their respective prompt templates in the `config.yaml` file under the `llm_as_a_judge_info` and `final_analysis_summarizer` sections.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/main.py
Summary of main.py:
- Function: read_config
- Function: output_handler
- Function: run_notebooks
- Function: main


File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/2_run_llm_as_a_judge_eval.ipynb

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/img/llm_as_a_judge.png

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/img/llm_as_a_judge.drawio

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/9/meta.llama3-70b-instruct-v1-0/model_evaluation_9.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/0/meta.llama3-70b-instruct-v1-0/model_evaluation_0.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/7/meta.llama3-70b-instruct-v1-0/model_evaluation_7.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/6/meta.llama3-70b-instruct-v1-0/model_evaluation_6.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/1/meta.llama3-70b-instruct-v1-0/model_evaluation_1.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/8/meta.llama3-70b-instruct-v1-0/model_evaluation_8.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/4/meta.llama3-70b-instruct-v1-0/model_evaluation_4.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/3/meta.llama3-70b-instruct-v1-0/model_evaluation_3.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/2/meta.llama3-70b-instruct-v1-0/model_evaluation_2.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/eval_completions/5/meta.llama3-70b-instruct-v1-0/model_evaluation_5.json

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/source_data/data.csv

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/source_data/data_user_system_prompt_version.csv

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/prompt_template/claude_inference_prompt_template.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/prompt_template/llama3_eval_prompt.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/prompt_template/claude_final_summary_prompt.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/prompt_template/claude_eval_prompt.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/final_analysis.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/processed_eval_prompts.csv

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/llm_as_a_judge_comparisons.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/llm_as_a_judge_pick_rate.csv

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/llm_as_a_judge_comparisons.csv

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/inference_latency_summary.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/all_explanations.txt

File: source/amazon-bedrock-samples-main/model-evals/llm-as-a-judge/data/results/all_results.csv

File: source/amazon-bedrock-samples-main/rag-solutions/README.md
README Summary:
Retrieval Augmented Generation Solutions
This folder contains examples and solutions of Retrieval Augmented Generation (RAG) applications on Amazon Bedrock
Contents
- Semantic Search - Sample embeddings search application with Amazon Titan Embeddings, LangChain, and Streamlit
- SQL Query Generator & Executor - Sample SQL query generator and executor application with Amazon Titan Embeddings, Amazon Bedrock Claude Model, LangChain, and Streamlit
- Multimodal RAG -  Multimodal RAG with PDF files using both Bedrock Titan text embeddings and Claude LLM
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/README.md
README Summary:
Build Contextual Chatbots using Amazon Bedrock Knowledge Bases
Modern chatbots can serve as digital agents, providing a new avenue for delivering 24/7 customer service and support across many industries. Their popularity stems from the ability to respond to customer inquiries in real time and handle multiple queries simultaneously in different languages. Chatbots also offer valuable data-driven insights into customer behavior while scaling effortlessly as the user base grows; therefore, they present a cost-effective solution for engaging customers. Chatbots use the advanced natural language capabilities of large language models (LLMs) to respond to customer questions. They can understand conversational language and respond naturally. However, chatbots that merely answer basic questions have limited utility. To become trusted advisors, chatbots need to provide thoughtful, tailored responses.
One way to enable more contextual conversations is by linking the chatbot to internal knowledge bases and information systems. Integrating proprietary enterprise data from internal knowledge bases enables chatbots to contextualize their responses to each user's individual needs and interests. For example, a chatbot could suggest products that match a shopper's preferences and past purchases, explain details in language adapted to the user's level of expertise, or provide account support by accessing the customer's specific records. The ability to intelligently incorporate information, understand natural language, and provide customized replies in a conversational flow allows chatbots to deliver real business value across diverse use cases.
The popular architecture pattern of Retrieval Augmented Generation (RAG) is often used to augment user query context and responses. RAG combines the capabilities of LLMs with the grounding in facts and real-world knowledge that comes from retrieving relevant texts and passages from corpus of data. These retrieved texts are then used to inform and ground the output, reducing hallucination and improving relevance.
This sample illustrates contextually enhancing a chatbot by using Knowledge Bases for Amazon Bedrock, aa fully managed serverless service. The Knowledge Bases for Amazon Bedrock integration allows our chatbot to provide more relevant, personalized responses by linking user queries to related information data points. Internally, Amazon Bedrock uses embeddings stored in a vector database to augment user query context at runtime and enable a managed RAG architecture solution. We use the Amazon letters to share holders dataset to develop this solution.
Retrieval Augmented Generation
RAG is an approach to natural language generation that incorporates information retrieval into the generation process. RAG architecture involves two key workflows: data preprocessing through ingestion, and text generation using enhanced context.
The data ingestion workflow uses LLMs to create embedding vectors that represent semantic meaning of texts. Embeddings are created for documents and user questions. The document embeddings are split into chunks and stored as indexes in a vector database. The text generation workflow then takes a question's embedding vector and uses it to retrieve the most similar document chunks based on vector similarity. It augments prompts with these relevant chunks to generate an answer using the LLM. For more details, refer to the Primer on Retrieval Augmented Generation, Embeddings, and Vector Databases section in Preview  Connect Foundation Models to Your Company Data Sources with Agents for Amazon Bedrock.
The following diagram illustrates the high-level RAG architecture.
</br><img src="images/architecture_1.jpg" alt="architecture1" width="800" align="center"/></br>
Although the RAG architecture has many advantages, it involves multiple components, including a database, retrieval mechanism, prompt, and generative model. Managing these interdependent parts can introduce complexities in system development and deployment. The integration of retrieval and generation also requires additional engineering effort and computational resources. Some open source libraries provide wrappers to reduce this overhead; however, changes to libraries can introduce errors and add additional overhead of versioning. Even with open source libraries, significant effort is required to write code, determine optimal chunk size, generate embeddings, and more. This setup work alone can take weeks depending on data volume.
Therefore, a managed solution that handles these undifferentiated tasks could streamline and accelerate the process of implementing and managing RAG applications.
Knowledge Bases for Amazon Bedrock
Knowledge Bases for Amazon Bedrock is a serverless option to build powerful conversational AI systems using RAG. It offers fully managed data ingestion and text generation workflows.
For data ingestion, it handles creating, storing, managing, and updating text embeddings of document data in the vector database automatically. It splits the documents into manageable chunks for efficient retrieval. The chunks are then converted to embeddings and written to a vector index, while allowing you to see the source documents when answering a question.
For text generation, Amazon Bedrock provides the RetrieveAndGenerate API to create embeddings of user queries, and retrieves relevant chunks from the vector database to generate accurate responses. It also supports source attribution and short-term memory needed for RAG applications.
This enables you to focus on your core business applications and removes the undifferentiated heavy lifting.
Solution overview
The solution presented in this example uses a chatbot created using a Streamlit application and includes the following AWS services:
* Amazon Simple Storage Service) (Amazon S3) as source
* Knowledge Bases for Amazon Bedrock for data ingestion
* An Amazon OpenSearch Serverless vector store to save text embeddings
* AWS Lambda as API function to invoke Knowledge Bases API
The following diagram is a common solution architecture pattern you can use to integrate any chatbot application to Knowledge Bases for Amazon Bedrock.
</br><img src="images/architecture_2.jpg" alt="architecture2" width="800" align="center" border="1"/></br>
This architecture includes the following steps:
* A user interacts with the Streamlit chatbot interface and submits a query in natural language
* This triggers a Lambda function, which invokes the Knowledge Bases  API. Internally, Knowledge Bases uses an Amazon Titan embedding model and converts the user query to a vector and finds chunks that are semantically similar to the user query. The user prompt is than augmented with the chunks that are retrieved from the knowledge base. The prompt alongside the additional context is then sent to a LLM for response generation. In this solution, we use Anthropic Claude Instant as our LLM to generate user responses using additional context. Note that this solution is supported in Regions where Anthropic Claude on Amazon Bedrock is available.
* A contextually relevant response is sent back to the chatbot application and user.
Prerequisites
Amazon Bedrock users need to request access to foundation models before they are available for use. This is a one-time action and takes less than a minute. For this solution, youll need to enable access to the Titan Embeddings G1 - Text and Claude Instant - v1.2 model in Amazon Bedrock. For more information, refer to Model access.
Clone the GitHub repo
To clone this GitHub repository run the following command. Note this is one single  command.
Upload your knowledge dataset to Amazon S3
Now download the dataset for knowledge base and upload it into a S3 bucket. This dataset will feed and power knowledge base. Complete the following steps:
1. Navigate to Amazon Annual reports, proxies and shareholder letters data repository data repository and download the last few years of Amazon shareholder letters.
</br><img style="border:1px solid black;" src="images/share-holders.jpg" alt="share-holders" width="800" align="center" /></br>
2. On the Amazon S3 console, choose **Buckets** in the navigation pane.
3. Click **Create bucket**.
4. Name the bucket .
5. Leave all other bucket settings as default and choose **Create**.
6. Navigate to the  bucket.
7. Choose Create folder and name it .
8. Leave all other folder settings as default and choose **Create**.
9. Navigate to the  folder
10. Drag and drop the Amazon annual reports, proxies and shareholder letters data files you downloaded earlier to this bucket and choose **Upload**.
11. Navigate back to the bucket home and choose **Create folder** to create a new folder and name it .
12. Leave all other settings as default and create the folder.
</br><img src="images/s3-objects.jpg" alt="s3-objects" width="800" align="center"/></br>
13. Navigate to the  folder.
14. Upload the  file available under the  folder in the code base you cloned earlier and choose **Upload**. You will use this Lambda layer code later to create the Lambda function.
</br><img src="images/lambda-layer.jpg" alt="lambda-layer" width="800" align="center"/></br>
Create a Knowledge Base
In this step, create a knowledge base using the Amazon shareholder letters dataset we uploaded to S3 bucket in the previous step.
1. On the Amazon Bedrock console, under **Orchestration** in the navigation pane, choose **Knowledge base**.
</br><img src="images/bedrock-left.jpg" alt="bedrock-left" height="600" align="center"/></br>
2. Choose **Create knowledge base**.
</br><img src="images/kb-body.jpg" alt="kb-body" width="800" align="center"/></br>
3. In the **Knowledge base details** section, enter a name and optional description
4. In the IAM permissions section, select Create and use a new service role and enter a name for the role.
5.	Add tags as needed.
6.	Choose Next.
</br><img src="images/kb-details.jpg" alt="kb-details" width="800" align="center"/></br>
7. In the **Data source** section, leave **Data source name** as the default name.
8.	For **S3 URI**, choose **Browse S3** to choose the S3 bucket . You need to point to the bucket and dataset folder you created in the previous steps.
9.	In the **Advanced settings** section, leave the default values (if you want, you can change the default chunking strategy and specify the chunk size and overlay in percentage).
10.	Choose **Next**.
</br><img src="images/kb-datasource.jpg" alt="kb-datasource" width="800" align="center"/></br>
11.	In the **Embeddings model** section, select **Titan Embedding G1  Text** for embedding model.
12.	For **Vector database** section, you can either select **Quick create a new vector store**, or **Choose a vector store you have created**. Note that, to use the vector store of your choice, you need have a vector store preconfigured to use. We currently support four vector engine types: the vector engine for Amazon OpenSearch Serverless, Amazon Aurora, Pinecone, and Redis Enterprise Cloud. For this post, we select **Quick create a new vector store**, which by default creates a new OpenSearch Serverless vector store in your account.
13.	Choose Next.
</br><img src="images/kb-vectorstore.jpg" alt="kb-vectorstore" width="800" align="center"/></br>
14.   On the Review and create page, review all the information, or choose Previous to modify any options
15.   Choose Create knowledge base. Note the knowledge base creation process begins and the status is **In progress**. It will take a few minutes to create the vector store and knowledge base. Dont navigate away from the page, otherwise creation will fail.
</br><img src="images/kb-review.jpg" alt="kb-review" width="800" align="center"/></br>
16.   When the knowledge base status is in the Ready state, note down the knowledge base ID. You will use it in the next steps to configure the Lambda function
</br><img src="images/kb-ready.jpg" alt="kb-ready" width="800" align="center"/></br>
17.   Now that knowledge base is ready, we need to sync our Amazon shareholders letter data to it. In the Data Source section of the knowledge base details page, choose Sync to trigger the data ingestion process from the S3 bucket to the knowledge base.
</br><img src="images/kb-sync.jpg" alt="kb-sync" width="800" align="center"/></br>
18.   This sync process splits the document files into smaller chunks of the chunk size specified earlier, generates vector embeddings using the selected text embedding model, and stores them in the vector store managed by Knowledge Bases for Amazon Bedrock.
</br><img src="images/kb-syncing.jpg" alt="kb-syncing" width="800" align="center"/></br>
19.   When the dataset sync is complete, the status of the data source will change to the Ready state. Note that, if you add any additional documents in the S3 data folder, you need to re-sync the knowledge base.
</br><img src="images/kb-readysync.jpg" alt="kb-readysync" width="800" align="center"/></br>
Congratulations, your Knowledge base is ready.
Note that you can also use Knowledge Bases for Amazon Bedrock service APIs and the AWS Command Line Interface (AWS CLI) to programmatically create a knowledge base. You will need to run various sections of the Jupyter notebook provided under the /notebook folder in the code base you cloned earlier.
Create AWS Lambda function
This Lambda function is deployed using an AWS CloudFormation template available under the  folder. The template requires two parameters: the S3 bucket name and the knowledge base ID.
1. On the AWS CloudFormation service home page, choose Create stack to create a new stack.
</br><img src="images/cfn-body.jpg" alt="cfn-body" width="800" align="center"/></br>
2.	Select **Template is ready** for **Prepare template**.
3.	Select **Upload the template** file for **Template source**.
4.	Choose **Choose file**, navigate to the code base you cloned earlier, and choose the .yaml file under the  folder.
5.	Choose **Next**.
</br><img src="images/cfn-create.jpg" alt="cfn-create" width="800" align="center"/></br>
6.	For **Stack name**, enter a name.
7.	In the **Parameters** section, enter the knowledge base ID and S3 bucket name you noted down earlier.
8.	Choose **Next**.
</br><img src="images/cfn-specify.jpg" alt="cfn-specify" width="800" align="center"/></br>
9.	Leave all default options as is, choose **Next**, and choose **Submit**.
10.	Verify that the CloudFormation template ran successfully, and there are no errors.
Congratulations, you have created a Lambda function, related roles, and policies successfully.
Test the Contextual Chatbot Application
To test the chatbot application, complete the following steps:
1. Open a new terminal or a command line window on your machine.
2.	Run the following command to install the AWS SDK for Python (Boto3). Boto3 makes it straightforward to integrate a Python application, library, or script with AWS services.
3.	Run the following command to install and set up a local Python development environment to run the Streamlit application:
4.	Navigate to the /streamlit folder in the code base you cloned earlier.
5.	Run the following command to instantiate the chatbot application:
6. This should open a web based chat application powered by Streamlit in your default web browser.
</br><img src="images/streamlit-blank.jpg" alt="streamlit-blank" width="500" align="center" border="1"/></br>
7. Use this Streamlit chatbot application to post natural language questions to start the conversations powered by Bedrock Knowledge base.
</br><img src="images/streamlit-filled-withanswer.png" alt="streamlit-filled-withanswer" width="500" align="center" border="1"/></br>
When you submit a prompt, the Streamlit app triggers the Lambda function, which invokes the Knowledge Bases RetrieveAndGenerate API to search and generate responses.
The following table includes some sample questions and related knowledge base responses. Try out some of these questions by using prompts.
| Questions | Answers |
| --------- | ------- |
| What is Amazon's doing in the field of generative AI? |	Amazon has been working on their own large language models (LLMs) for generative AI and believes it will transform and improve every customer experience. They plan to continue investing substantially in these models across all their consumer, seller, brand, and creator experiences. |
| What is AWS year-over-year revenue in 2022? | AWS revenue grew 29% year-over-year in 2022 on a $62 billion revenue base in 2021.
How many days has Amazon asked employees to come to work in office? | Amazon has asked corporate employees to come back to office at least three days a week beginning May 2022. |
| By what percentage did AWS revenue grow year-over-year in 2022? | AWS had a 29% year-over-year ('YoY') revenue in 2022. |
| Compared to Graviton2 processors, what performance improvement did Graviton3 chips deliver according to the passage? | In 2022, AWS delivered their Graviton3 chips, providing 25% better performance than the Graviton2 processors. |
| Which was the first inference chip launched by AWS according to the passage? | AWS launched their first inference chips (Inferentia) in 2019, and they have saved companies like Amazon over a hundred million dollars in capital expense. |
| According to the context, in what year did Amazon's annual revenue increase from $245B to $434B?	| Amazon's annual revenue increased from $245B in 2019 to $434B in 2022. |
During the first call to the Lambda function, the  API returns a , which is then passed by the Streamlit app along with the subsequent user prompt as an input to the  API to continue the conversation in the same session. The  API manages the short-term memory and uses the chat history as long as the same  is passed as an input in the successive calls.
Congratulations, you have successfully created and tested a chatbot application using Knowledge Bases for Amazon Bedrock.
Clean Up
Failing to delete resources such as the S3 bucket, OpenSearch Serverless collection, and knowledge base will incur charges. To clean up these resources, delete the CloudFormation stack, delete the S3 bucket (including any document folders and files stored in that bucket), delete the OpenSearch Serverless collection, delete the knowledge base, and delete any roles, policies, and permissions that you created earlier.
Conclusion
This example provided an overview of contextual chatbots and explained why theyre important. It described the complexities involved in data ingestion and text generation workflows for a RAG architecture. It then introduced how Knowledge Bases for Amazon Bedrock creates a fully managed serverless RAG system, including a vector store. Finally, it provided a solution architecture and sample code in this GitHub repo to retrieve and generate contextual responses for a chatbot application using a knowledge base.
By explaining the value of contextual chatbots, the challenges of RAG systems, and how Knowledge Bases for Amazon Bedrock addresses those challenges, this example aimed to showcase how Amazon Bedrock enables you to build sophisticated conversational AI applications with minimal effort.
For more information, see the Amazon Bedrock Developer Guide and Knowledge Base APIs.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/streamlit/chatbot.py
Summary of chatbot.py:
- Function: generate_presigned_url


File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-vectorstore.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/lambda-layer.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-syncing.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-syncing.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-body.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/streamlit-filled.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/bedrock-left.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-details.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/cfn-body.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/share-holders.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/architecture_1.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/share-holders.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/cfn-specify.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/architecture_2.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-datasource.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-readysync.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/streamlit-filled-withanswer.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/streamlit-blank.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-ready.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-ready.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-review.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/cfn-create.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/s3-objects.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/images/kb-sync.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/cfn/DeployKnowledgeBase.yaml

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/lambda/bedrock-kb-retrieveAndGenerate.py
Summary of bedrock-kb-retrieveAndGenerate.py:
- Function: retrieveAndGenerate
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/lambda/layer/knowledgebase_lambdalayer.zip

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/notebook/knowledge_base_create_ingest_documents.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase/notebook/utility.py
Summary of utility.py:
- Function: create_bedrock_execution_role
- Function: create_oss_policy_attach_bedrock_execution_role
- Function: create_policies_in_oss
- Function: delete_iam_role_and_policies


File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/requirements.txt

File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/README.md
README Summary:
SQL Query Generator & Executor Example
This demonstrates a simple application using public Northwind with Amazon Titan Embeddings, Amazon Bedrock Claude Model, LangChain, and Streamlit for the front-end.
The example receives a users prompt, generates a SQL query using in-memory vector database and few-shot examples. We then run the query using SQLite database and display query results in the user interface.
For simplicity, we use the in-memory Chroma database to store and search for embeddings vectors. In a real-world scenario at scale, you will likely want to use a persistent data store like the vector engine for Amazon OpenSearch Serverless or the pgvector extension for PostgreSQL.
Contents
The example consists of four files:
* Streamlit application in Python
* Supporting file to make calls to Bedrock to run the SQL chain
* Requirements file, and a data file to search against
* SQLite helper file to run queries
* Local SQLite Northwind database
Requirements
You need an AWS account with following Bedrock models enabled;
* amazon.titan-embed-text-v1
* anthropic.claude-v2
You need to setup your AWS profile and setup your "default" profile with the AWS account credentials where you have above Bedrock models enabled
Setup
From the command line, run the following in the code folder:
Running
From the command line, run the following in the code folder:
You should now be able to access the Streamlit web application from your browser.
!SQL Generator & Executor Frontend
Try a few prompts from the web application:
* Can you list customers which placed orders in the last 30 days?
* Can you get alphabetical list of products?
* For each order, calculate a subtotal for each Order (identified by OrderID)?
* For each employee, can you get their sales amount, broken down by country name?
* Can you calculate sales price for each order after discount is applied?
* For each category, can you get the list of products sold and the total sales amount?
* Can you list ten most expensive products?
* Can you list products above average price?
* Can you show sales amount for each quarter?
* Can you list number of units in stock by category and supplier continent?
* What are the total sales amounts by year?
* What are the top 5 most expensive products?
* What customers have spent over $1000 in total?
* What products were sold in the last month?
* What is the total revenue for each employee?

File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/sql_chat_ui.py
Summary of sql_chat_ui.py:
- Function: ask_question
- Function: is_query_present
- Function: extract_query
- Function: run_query


File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/northwind.db

File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/sql_query_chain.py
Summary of sql_query_chain.py:
- Function: sql_chain


File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/sqlite_helper.py
Summary of sqlite_helper.py:
- Function: run_query


File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/northwind_ddl.sql

File: source/amazon-bedrock-samples-main/rag-solutions/sql-query-generator/images/sql_chat_ui.png

File: source/amazon-bedrock-samples-main/rag-solutions/multimodal-rag-pdf/README.md
README Summary:
Multimodal RAG for PDF files
This is an example for RAG with pdf files and includes the data ingestion pipeline and inference flow.
Contents
- Multimodal RAG - Multimodal RAG with PDF files using both bedrock titan text embeddings and claude LLM.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/rag-solutions/multimodal-rag-pdf/rag/multimodal-rag-pdf.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/multimodal-rag-pdf/rag/diagrams/multimodal-rag-inference.drawio.png

File: source/amazon-bedrock-samples-main/rag-solutions/multimodal-rag-pdf/rag/diagrams/multimodal-rag.drawio.png

File: source/amazon-bedrock-samples-main/rag-solutions/semantic-search/requirements.txt

File: source/amazon-bedrock-samples-main/rag-solutions/semantic-search/search_lib.py
Summary of search_lib.py:
- Function: get_index
- Function: get_similarity_search_results


File: source/amazon-bedrock-samples-main/rag-solutions/semantic-search/README.md
README Summary:
Semantic Search Example
This demonstrates a simple embeddings search application with Amazon Titan Embeddings, LangChain, and Streamlit.
The example matches a users query to the closest entries in an in-memory vector database. We then display those matches directly in the user interface. This can be useful if you want to troubleshoot a RAG application, or directly evaluate an embeddings model.
For simplicity, we use the in-memory FAISS database to store and search for embeddings vectors. In a real-world scenario at scale, you will likely want to use a persistent data store like the vector engine for Amazon OpenSearch Serverless or the pgvector extension for PostgreSQL.
Contents
The example consists of four files: A Streamlit application in Python, a supporting file to make calls to Bedrock, a requirements file, and a data file to search against.
Setup
From the command line, run the following in the code folder:
Running
From the command line, run the following in the code folder:
You should now be able to access the Streamlit web application from your browser.
Try a few prompts from the web application:
* How can I monitor my usage?
* How can I customize models?
* Which programming languages can I use?
* Comment mes donnes sont-elles scurises ?
* 
* Quais fornecedores de modelos esto disponveis por meio do Bedrock?
* In welchen Regionen ist Amazon Bedrock verfgbar?
* 
Note that even though the source material was in English, the queries in other languages were matched with relevant entries.

File: source/amazon-bedrock-samples-main/rag-solutions/semantic-search/search_app.py
Summary of search_app.py:


File: source/amazon-bedrock-samples-main/rag-solutions/semantic-search/bedrock_faqs.csv

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/Basic_RAG_With_LlamaIndex.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/Router_Query_Engine.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/Multi_Document_Agent.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/2_llama_index_bedrock_kb.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/SubQuestion_Query_Engine.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/1_llama_parse_upload_s3.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/llamaindex-examples/ReAct_Agent.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/README.md
README Summary:
Build Contextual Chatbots using Amazon Bedrock Knowledge Bases
Modern chatbots can serve as digital agents, providing a new avenue for delivering 24/7 customer service and support across many industries. Their popularity stems from the ability to respond to customer inquiries in real time and handle multiple queries simultaneously in different languages. Chatbots also offer valuable data-driven insights into customer behavior while scaling effortlessly as the user base grows; therefore, they present a cost-effective solution for engaging customers. Chatbots use the advanced natural language capabilities of large language models (LLMs) to respond to customer questions. They can understand conversational language and respond naturally. However, chatbots that merely answer basic questions have limited utility. To become trusted advisors, chatbots need to provide thoughtful, tailored responses.
One way to enable more contextual conversations is by linking the chatbot to internal knowledge bases and information systems. Integrating proprietary enterprise data from internal knowledge bases enables chatbots to contextualize their responses to each user's individual needs and interests. For example, a chatbot could suggest products that match a shopper's preferences and past purchases, explain details in language adapted to the user's level of expertise, or provide account support by accessing the customer's specific records. The ability to intelligently incorporate information, understand natural language, and provide customized replies in a conversational flow allows chatbots to deliver real business value across diverse use cases.
The popular architecture pattern of Retrieval Augmented Generation (RAG) is often used to augment user query context and responses. RAG combines the capabilities of LLMs with the grounding in facts and real-world knowledge that comes from retrieving relevant texts and passages from corpus of data. These retrieved texts are then used to inform and ground the output, reducing hallucination and improving relevance.
This sample illustrates contextually enhancing a chatbot by using Knowledge Bases for Amazon Bedrock, aa fully managed serverless service. The Knowledge Bases for Amazon Bedrock integration allows our chatbot to provide more relevant, personalized responses by linking user queries to related information data points. Internally, Amazon Bedrock uses embeddings stored in a vector database to augment user query context at runtime and enable a managed RAG architecture solution. We use the Amazon letters to share holders dataset to develop this solution.
Retrieval Augmented Generation With Guardrails
RAG is an approach to natural language generation that incorporates information retrieval into the generation process. RAG architecture involves two key workflows: data preprocessing through ingestion, and text generation using enhanced context.
The data ingestion workflow uses LLMs to create embedding vectors that represent semantic meaning of texts. Embeddings are created for documents and user questions. The document embeddings are split into chunks and stored as indexes in a vector database. The text generation workflow then takes a question's embedding vector and uses it to retrieve the most similar document chunks based on vector similarity. It augments prompts with these relevant chunks to generate an answer using the LLM. For more details, refer to the Primer on Retrieval Augmented Generation, Embeddings, and Vector Databases section in Preview  Connect Foundation Models to Your Company Data Sources with Agents for Amazon Bedrock.
The following diagram illustrates the high-level RAG architecture with a Guardrail.
</br><img src="images/architecture_1.jpg" alt="architecture1" width="800" align="center"/></br>
Although the RAG architecture has many advantages, it involves multiple components, including a database, retrieval mechanism, prompt, and generative model. Managing these interdependent parts can introduce complexities in system development and deployment. The integration of retrieval and generation also requires additional engineering effort and computational resources. Some open source libraries provide wrappers to reduce this overhead; however, changes to libraries can introduce errors and add additional overhead of versioning. Even with open source libraries, significant effort is required to write code, determine optimal chunk size, generate embeddings, and more. This setup work alone can take weeks depending on data volume.
Therefore, a managed solution that handles these undifferentiated tasks could streamline and accelerate the process of implementing and managing RAG applications.
Knowledge Bases for Amazon Bedrock
Knowledge Bases for Amazon Bedrock is a serverless option to build powerful conversational AI systems using RAG. It offers fully managed data ingestion and text generation workflows.
For data ingestion, it handles creating, storing, managing, and updating text embeddings of document data in the vector database automatically. It splits the documents into manageable chunks for efficient retrieval. The chunks are then converted to embeddings and written to a vector index, while allowing you to see the source documents when answering a question.
For text generation, Amazon Bedrock provides the RetrieveAndGenerate API to create embeddings of user queries, and retrieves relevant chunks from the vector database to generate accurate responses. It also supports source attribution and short-term memory needed for RAG applications.
This enables you to focus on your core business applications and removes the undifferentiated heavy lifting.
Guardrails for Amazon Bedrock is integrated with Knowledge Bases. Guardrails allow you to instrument safeguards customized to your RAG application requirements, and responsible AI policies, leading to a better end user experience.
Guardrails provides a comprehensive set of policies to protect your users from undesirable responses and interactions with a generative AI application. First, you can customize a set of denied topics to avoid within the context of your application. Second, you can filter content across prebuilt harmful categories such as hate, insults, sexual, violence, misconduct, and prompt attacks. Third, you can define a set of offensive and inappropriate words to be blocked in their application. Finally, you can filter user inputs containing sensitive information (e.g., personally identifiable information) or redact confidential information in model responses based on use cases. Guardrails can be applied to the input sent to the model as well the content generated by the foundation model
In this sample we will apply filters based on defined words.
Solution overview
The solution presented in this example uses a chatbot created using a Streamlit application and includes the following AWS services:
* Amazon Simple Storage Service) (Amazon S3) as source
* Knowledge Bases for Amazon Bedrock for data ingestion
* An Amazon OpenSearch Serverless vector store to save text embeddings
* AWS Lambda as API function to invoke Knowledge Bases API
The following diagram is a common solution architecture pattern you can use to integrate any chatbot application to Knowledge Bases for Amazon Bedrock.
</br><img src="images/architecture_2.jpg" alt="architecture2" width="800" align="center" border="1"/></br>
This architecture includes the following steps:
* A user interacts with the Streamlit chatbot interface and submits a query in natural language
* This triggers a Lambda function, which invokes the Knowledge Bases  API. Internally, Knowledge Bases uses an Amazon Titan embedding model and converts the user query to a vector and finds chunks that are semantically similar to the user query. The user prompt is than augmented with the chunks that are retrieved from the knowledge base. The prompt alongside the additional context is then sent to a LLM for response generation. In this solution, we use Anthropic Claude Instant as our LLM to generate user responses using additional context. Note that this solution is supported in Regions where Anthropic Claude on Amazon Bedrock is available.
* A contextually relevant response is sent back to the chatbot application and user.
* User has the ability to apply guardrails and verify how it impacts the answers.
Prerequisites
Amazon Bedrock users need to request access to foundation models before they are available for use. This is a one-time action and takes less than a minute. For this solution, youll need to enable access to the Titan Embeddings G1 - Text and Claude Instant - v1.2 model in Amazon Bedrock. For more information, refer to Model access.
Clone the GitHub repo
To clone this GitHub repository run the following command. Note this is one single  command.
Upload your knowledge dataset to Amazon S3
Now download the dataset for knowledge base and upload it into a S3 bucket. This dataset will feed and power knowledge base. Complete the following steps:
1. Navigate to Amazon Annual reports, proxies and shareholder letters data repository data repository and download the last few years of Amazon shareholder letters.
</br><img style="border:1px solid black;" src="images/share-holders.jpg" alt="share-holders" width="800" align="center" /></br>
2. On the Amazon S3 console, choose **Buckets** in the navigation pane.
3. Click **Create bucket**.
4. Name the bucket .
5. Leave all other bucket settings as default and choose **Create**.
6. Navigate to the  bucket.
7. Choose Create folder and name it .
8. Leave all other folder settings as default and choose **Create**.
9. Navigate to the  folder
10. Drag and drop the Amazon annual reports, proxies and shareholder letters data files you downloaded earlier to this bucket and choose **Upload**.
11. Navigate back to the bucket home and choose **Create folder** to create a new folder and name it .
12. Leave all other settings as default and create the folder.
</br><img src="images/s3-objects.jpg" alt="s3-objects" width="800" align="center"/></br>
13. Navigate to the  folder.
14. Upload the  file available under the  folder in the code base you cloned earlier and choose **Upload**. You will use this Lambda layer code later to create the Lambda function.
</br><img src="images/lambda-layer.jpg" alt="lambda-layer" width="800" align="center"/></br>
Create a Knowledge Base
In this step, create a knowledge base using the Amazon shareholder letters dataset we uploaded to S3 bucket in the previous step.
1. On the Amazon Bedrock console, under **Orchestration** in the navigation pane, choose **Knowledge base**.
</br><img src="images/bedrock-left.jpg" alt="bedrock-left" height="600" align="center"/></br>
2. Choose **Create knowledge base**.
</br><img src="images/kb-body.jpg" alt="kb-body" width="800" align="center"/></br>
3. In the **Knowledge base details** section, enter a name and optional description
4. In the IAM permissions section, select Create and use a new service role and enter a name for the role.
5.	Add tags as needed.
6.	Choose Next.
</br><img src="images/kb-details.jpg" alt="kb-details" width="800" align="center"/></br>
7. In the **Data source** section, leave **Data source name** as the default name.
8.	For **S3 URI**, choose **Browse S3** to choose the S3 bucket . You need to point to the bucket and dataset folder you created in the previous steps.
9.	In the **Advanced settings** section, leave the default values (if you want, you can change the default chunking strategy and specify the chunk size and overlay in percentage).
10.	Choose **Next**.
</br><img src="images/kb-datasource.jpg" alt="kb-datasource" width="800" align="center"/></br>
11.	In the **Embeddings model** section, select **Titan Embedding G1  Text** for embedding model.
12.	For **Vector database** section, you can either select **Quick create a new vector store**, or **Choose a vector store you have created**. Note that, to use the vector store of your choice, you need have a vector store preconfigured to use. We currently support four vector engine types: the vector engine for Amazon OpenSearch Serverless, Amazon Aurora, Pinecone, and Redis Enterprise Cloud. For this post, we select **Quick create a new vector store**, which by default creates a new OpenSearch Serverless vector store in your account.
13.	Choose Next.
</br><img src="images/kb-vectorstore.jpg" alt="kb-vectorstore" width="800" align="center"/></br>
14.   On the Review and create page, review all the information, or choose Previous to modify any options
15.   Choose Create knowledge base. Note the knowledge base creation process begins and the status is **In progress**. It will take a few minutes to create the vector store and knowledge base. Dont navigate away from the page, otherwise creation will fail.
</br><img src="images/kb-review.jpg" alt="kb-review" width="800" align="center"/></br>
16.   When the knowledge base status is in the Ready state, note down the knowledge base ID. You will use it in the next steps to configure the Lambda function
</br><img src="images/kb-ready.jpg" alt="kb-ready" width="800" align="center"/></br>
17.   Now that knowledge base is ready, we need to sync our Amazon shareholders letter data to it. In the Data Source section of the knowledge base details page, choose Sync to trigger the data ingestion process from the S3 bucket to the knowledge base.
</br><img src="images/kb-sync.jpg" alt="kb-sync" width="800" align="center"/></br>
18.   This sync process splits the document files into smaller chunks of the chunk size specified earlier, generates vector embeddings using the selected text embedding model, and stores them in the vector store managed by Knowledge Bases for Amazon Bedrock.
</br><img src="images/kb-syncing.jpg" alt="kb-syncing" width="800" align="center"/></br>
19.   When the dataset sync is complete, the status of the data source will change to the Ready state. Note that, if you add any additional documents in the S3 data folder, you need to re-sync the knowledge base.
</br><img src="images/kb-readysync.jpg" alt="kb-readysync" width="800" align="center"/></br>
Congratulations, your Knowledge base is ready.
20. Create a Guardrail
</br><img src="images/gr-image.png" alt="gr-image" width="175" align="center"/></br>
Click on the Create guardrail buttnon
</br><img src="images/gr-create.png" alt="gr-create" width="600" align="center"/></br>
Enter **Competition-Guardrail** as Name
</br><img src="images/gr-create-new.png" alt="gr-create-new" width="600" align="center"/></br>
Click next untill you reach to the  **Add word filters - optional** screen. Then add a word that you would like to restrict inquiries about. Then keep clicking next and create finally.
</br><img src="images/gr-add-word.png" alt="gr-add-word" width="600" align="center"/></br>
Once the guardrail is created now we need to add a version. **Take a note of guardrail id.**
</br><img src="images/gr-version.png" alt="gr-version" width="600" align="center"/></br>
Congratulations, your Guardrail is ready.
Note that you can also use Knowledge Bases for Amazon Bedrock service APIs and the AWS Command Line Interface (AWS CLI) to programmatically create a knowledge base. You will need to run various sections of the Jupyter notebook provided under the /notebook folder in the code base you cloned earlier.
Create AWS Lambda function
This Lambda function is deployed using an AWS CloudFormation template available under the  folder. The template requires two parameters: the S3 bucket name and the knowledge base ID.
1. On the AWS CloudFormation service home page, choose Create stack to create a new stack.
</br><img src="images/cfn-body.jpg" alt="cfn-body" width="800" align="center"/></br>
2.	Select **Template is ready** for **Prepare template**.
3.	Select **Upload the template** file for **Template source**.
4.	Choose **Choose file**, navigate to the code base you cloned earlier, and choose the .yaml file under the  folder.
5.	Choose **Next**.
</br><img src="images/cfn-create.jpg" alt="cfn-create" width="800" align="center"/></br>
6.	For **Stack name**, enter a name.
7.	In the **Parameters** section, enter the knowledge base ID, GuardrailID and S3 bucket name you noted down earlier.
8.	Choose **Next**.
</br><img src="images/cfn-specify.png" alt="cfn-specify" width="800" align="center"/></br>
9.	Leave all default options as is, choose **Next**, and choose **Submit**.
10.	Verify that the CloudFormation template ran successfully, and there are no errors.
Congratulations, you have created a Lambda function, related roles, and policies successfully.
Test the Contextual Chatbot Application
To test the chatbot application, complete the following steps:
1. Open a new terminal or a command line window on your machine.
2.	Run the following command to install the AWS SDK for Python (Boto3). Boto3 makes it straightforward to integrate a Python application, library, or script with AWS services.
3.	Run the following command to install and set up a local Python development environment to run the Streamlit application:
If you already have Streamlit, make sure you have a current version
4.	Navigate to the /streamlit folder in the code base you cloned earlier.
5.	Run the following command to instantiate the chatbot application:
6. This should open a web based chat application powered by Streamlit in your default web browser.
</br><img src="images/streamlit-blank.jpg" alt="streamlit-blank" width="500" align="center" border="1"/></br>
7. Use this Streamlit chatbot application to post natural language questions to start the conversations powered by Bedrock Knowledge base.
</br><img src="images/streamlit-filled.jpg" alt="streamlit-filled" width="500" align="center" border="1"/></br>
</br><img src="images/streamlit-filled-checked.jpg" alt="streamlit-filled-checked" width="500" align="center" border="1"/></br>
When you submit a prompt, the Streamlit app triggers the Lambda function, which invokes the Knowledge Bases RetrieveAndGenerate API to search and generate responses.
The following table includes some sample questions and related knowledge base responses. Try out some of these questions by using prompts.
| Questions | Answers |
| --------- | ------- |
| **Uncheck Enable Guardrails**  How did Google do in 2023 ?  	| The search results do not contain any information about Google's business performance in 2023. |
| **Check Enable Guardrails**  How did Google do in 2023 ? 	| Sorry, the model cannot answer this question. |
| What is Amazon's doing in the field of generative AI? |	Amazon has been working on their own large language models (LLMs) for generative AI and believes it will transform and improve every customer experience. They plan to continue investing substantially in these models across all their consumer, seller, brand, and creator experiences. |
| What is AWS year-over-year revenue in 2022? | AWS revenue grew 29% year-over-year in 2022 on a $62 billion revenue base in 2021.
During the first call to the Lambda function, the  API returns a , which is then passed by the Streamlit app along with the subsequent user prompt as an input to the  API to continue the conversation in the same session. The  API manages the short-term memory and uses the chat history as long as the same  is passed as an input in the successive calls. When Enable Guardrails is checked we pass  and provide the .
Congratulations, you have successfully created and tested a chatbot application using Knowledge Bases for Amazon Bedrock.
Clean Up
Failing to delete resources such as the S3 bucket, OpenSearch Serverless collection, and knowledge base will incur charges. To clean up these resources, delete the CloudFormation stack, delete the S3 bucket (including any document folders and files stored in that bucket), delete the OpenSearch Serverless collection, delete the knowledge base, and delete any roles, policies, and permissions that you created earlier.
Conclusion
This example provided an overview of contextual chatbots and explained why theyre important. It described the complexities involved in data ingestion and text generation workflows for a RAG architecture. It then introduced how Knowledge Bases for Amazon Bedrock creates a fully managed serverless RAG system, including a vector store. Finally, it provided a solution architecture and sample code in this GitHub repo to retrieve and generate contextual responses for a chatbot application using a knowledge base.
By explaining the value of contextual chatbots, the challenges of RAG systems, and how Knowledge Bases for Amazon Bedrock addresses those challenges, this example aimed to showcase how Amazon Bedrock enables you to build sophisticated conversational AI applications with minimal effort.
For more information, see the Amazon Bedrock Developer Guide and Knowledge Base APIs.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/streamlit/chatbot.py
Summary of chatbot.py:


File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-vectorstore.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/lambda-layer.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-syncing.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/gr-create.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-syncing.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-body.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/streamlit-filled.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/bedrock-left.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/gr-image.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-details.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/cfn-body.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/share-holders.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/architecture_1.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/share-holders.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/cfn-specify.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/cfn-specify.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/architecture_2.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-datasource.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/gr-create-new.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/gr-add-word.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-readysync.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/streamlit-blank.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-ready.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-ready.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/streamlit-filled-checked.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-review.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/gr-version.png

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/cfn-create.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/s3-objects.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/images/kb-sync.jpg

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/cfn/DeployKnowledgeBase.yaml

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/lambda/bedrock-kb-retrieveAndGenerate.py
Summary of bedrock-kb-retrieveAndGenerate.py:
- Function: retrieveAndGenerate
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/lambda/layer/knowledgebase_lambdalayer.zip

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/notebook/knowledge_base_create_ingest_documents.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/contextual-chatbot-using-knowledgebase-guardrails/notebook/utility.py
Summary of utility.py:
- Function: create_bedrock_execution_role
- Function: create_oss_policy_attach_bedrock_execution_role
- Function: create_policies_in_oss
- Function: delete_iam_role_and_policies


File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/LICENSE

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/requirements.txt

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/README.md
README Summary:
AIM307 2023 - Retrieval Augmented Generation with Amazon Bedrock
Welcome to re\:Invent 2023! Large language models (LLMs) are often limited by the data they were trained on and dont always provide up-to-date responses, or worse, they make things up. To overcome this limitation, you can supplement prompts with up-to-date information using embeddings stored in vector databases, a process known as Retrieval Augmented Generation (RAG). With supplemental information in the prompt providing more context, the LLM can respond more accurately and is less likely to hallucinate.
In this workshop you will learn how to build a Retrieval Augmented Generation (RAG) system powered Amazon Bedrock. Throughout this workshop you will learn how to...
1. Use the Amazon Bedrock API to leverage generative AI (GenAI) models in an easy to use manner
2. Use Anthropic's Claude model for text generation
3. Build a conversational interface to a large language model
4. Use Amazon's Titan Text Embeddings model to create high quality text embeddings
5. Ingest embeddings into a local vector database to power a semantic search capability
6. Combine the power of large language models with semantic search to create a RAG application
7. Combine the power of large language models with APIs to create a RAG application which interacts with APIs
Go ahead and open this notebook to get started building with Amazon Bedrock!

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-diy/index.faiss

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-diy/index.pkl

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/letter/2022.txt

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/book/book.txt

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/sagemaker/Amazon-com-Inc-2023-Shareholder-Letter.pdf

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/sagemaker/Amazon_SageMaker_FAQs.pdf

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/sagemaker/sm_faq_v2.csv

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/data/sagemaker/sagemaker_faqs.csv

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/04_retrieval_based_chat_application.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/03_retrieval_based_text_application.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/05_agent_based_text_generation.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/02_contextual_text_generation.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/04_retrieval_based_chat.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/01_workshop_setup.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/06_build_yourself.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/06_DO_NOT_OPEN_build_yourself_answers.ipynb

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/embeddings_lang.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/chatbot_bedrock.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/terminal.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/chatbot_lang.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/model_eval.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/api.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/notebooks/images/context-aware-chatbot.png

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/llama-index/vector_store.json

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/llama-index/graph_store.json

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/llama-index/index_store.json

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/llama-index/docstore.json

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/langchain/index.faiss

File: source/amazon-bedrock-samples-main/rag-solutions/rag-foundations-workshop/faiss-index/langchain/index.pkl

File: source/amazon-bedrock-samples-main/knowledge-bases/utility.py
Summary of utility.py:
- Function: create_bedrock_execution_role
- Function: create_oss_policy_attach_bedrock_execution_role
- Function: create_policies_in_oss
- Function: delete_iam_role_and_policies
- Function: interactive_sleep
- Function: create_bedrock_execution_role_multi_ds


File: source/amazon-bedrock-samples-main/knowledge-bases/README.md
README Summary:
Amazon Bedrock Knowledge Base - Samples for building RAG workflows
Contents
Contains following folders:
- 00-zero-setup-chat-with-your-document
- 01-rag-concepts
- 02-advanced-concepts
00-zero-setup-chat-with-your-document
- 0_chat_with_document_kb.ipynb - Enables you to chat with your document without setting up any vector database. You can either upload the document or simply point to the document in your S3 location.
01-rag-concepts
- 1a_create_ingest_documents_test_kb.ipynb - creates necessary role and policies required using the `utility.py` file. It uses the roles and policies to create Open Search Serverless vector index, knowledge base, data source, and then ingests the documents to the vector store. Once the documents are ingested it will then test the knowledge base using `RetrieveAndGenerate` API for question answering, and `Retrieve` API for fetching relevant documents. Finally, it deletes all the resources. If you want to continue with other notebooks, you can choose not to delete the resources and move to other notebooks. Please note, that if you do not delete the resources, you may be incurred cost of storing data in OpenSearch Serverless, even if you are not using it. Therefore, once you are done with trying out the sample code, make sure to delete all the resources.
- 1b_create_ingest_documents_test_kb_multi_ds.ipynb - creates necessary role and policies required using the `utility.py` file. It creates knowledge bases with multiple s3 buckets as data sources.
- 2_managed-rag-kb-retrieve-generate-api.ipynb - Code sample for managed retrieval augmented generation (RAG) using `RetrieveAndGenerate` API from Knowledge Bases for Amazon Bedrock.
- 3_customized-rag-retrieve-api-claude-v2.ipynb - If you want to customize your RAG workflow, you can use the `retrieve` API provided by Knowledge Bases for Amazon Bedrock. You can either performa `semantic` or `hybrid` search over your vector store. This notebook, provides sample code for `hybrid` search using Claude 3 models as well as demonstrates LangChain integraion with Knowledge Bases for Amazon Bedrock.
- 4_customized-rag-retrieve-api-titan-lite-evaluation.ipynb - If you are interested in evaluating your RAG application, try this sample code where we are using the `Amazon Titan Lite` model for generating responses and `Anthropic Claude V2` for evaluating the response.
- 5_customized-rag-retreive-api-langchain-claude-v2-evaluation-ragas.ipynb - If you are interested in building Q&A application using Retrieve API provide by Knowledge Bases for Amazon Bedrock, along with LangChain and RAGAS for evaluating the responses, try this sample.
- 6_customized-rag-retreive-api-langchain-claude-v2-online-evaluation-ragas.ipynb - The popularity of large language models (LLMs) is skyrocketing, and with it the need to observe and analyze their performance. Tracing model usage in production and getting detailed insights on quality, cost and speed are crucial for the continued growth of generative AI apps.  Now let's explore Langfuse, another emerging project tackling observability for these complex systems.
Langfuse aims to provide granular visibility into model invocation traces and metrics like accuracy, latency and cost per query. With advanced analytics and visualization, it can help teams optimize performance, reduce expenses and identify issues early. As generative AI enters the mainstream, Langfuse and similar tools will be key enablers for delivering reliable, cost-effective services at scale.
In this notebook, we will use RAGAS to run the evaluations for each trace item and score them. This gives you better idea of how each call to RAG pipelines is performing. You compute the score with each request from getting question from the user and fetch context from the Knoweldge base then pass the question and the contexts to the LLM to generate the answer. All these step are logged as spans in a single trace in langfuse. You can read more about traces and spans from the langfuse documentation.
Vidoe : Langfuse Dashboard and Traces view
https://github.com/aws-samples/amazon-bedrock-samples/assets/136643863/3277e195-faa4-4c36-8acf-d7d967b20cb5
02-advanced-concepts
- 0_chunk_size_evaluation_for_KB_RAG.ipynb - This notebook provides sample code for chunking size evaluation for building optimum RAG applcation.
***
Note
If you use the notebook - `0_create_ingest_documents_test_kb.ipynb` for creating the knowledge bases and do not delete the resources, you may be incurred cost of storing data in OpenSearch Serverless, even if you are not using it. Therefore, once you are done with trying out the sample code, make sure to delete all the resources.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the Contents section of this README file with a link to your sample, along with a description..

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/4_customized-rag-retreive-api-titan-lite-evaluation.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/2a_managed_rag_kb_retrieve_generate_api.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/1b_create_ingest_documents_test_kb_multi_ds.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/6_customized-rag-retreive-api-langchain-claude-v2-online-evaluation-ragas.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/1a_create_ingest_documents_test_kb.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/5_customized-rag-retreive-api-langchain-claude-evaluation-ragas.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/3_customized-rag-retreive-api-hybrid-search-claude-3-sonnet-langchain.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/2b_managed_rag_custom_prompting_and_no_of_results.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/rag-eval-flow-guidelines.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/LangfuseAPIKEY.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/rag-eval-flow-correctness.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/rag-eval-online-langfuse.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/no-of-results-1.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/rag-eval-flow-faithfulness.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/no-of-results-2.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/rag-eval-flow-relevancy.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/data_ingestion.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/LangfuseTraceDetailsGeneration.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/retrieveAPI.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/LangfuseTraceDetailsRetreive.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/LangfuseTraceDetail.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/retrieveAndGenerate.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/custom-prompting-0.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/custom-prompting-1.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/images/custom-prompting-2.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/hybrid_search_and_multi_query.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/optimizing-rag-retrieval-using-metadata_filtering.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/multi-query.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/multi-query.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/data_ingestion.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/hybrid-search-2.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/retrieveAPI.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/hybrid-overview.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/hybrid-search-1.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/hybrid-overview.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/metadata-filter.png

File: source/amazon-bedrock-samples-main/knowledge-bases/01-rag-concepts/optimizing-accuracy-retrieved-results/images/retrieveAndGenerate.png

File: source/amazon-bedrock-samples-main/knowledge-bases/00-zero-setup-chat-with-your-document/00_chat_with_document_kb.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/images/rag-eval-flow-guidelines.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/LangfuseAPIKEY.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/rag-eval-flow-correctness.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/rag-eval-online-langfuse.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/rag-eval-flow-faithfulness.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/rag-eval-flow-relevancy.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/data_ingestion.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/LangfuseTraceDetailsGeneration.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/images/retrieveAPI.png

File: source/amazon-bedrock-samples-main/knowledge-bases/images/LangfuseTraceDetailsRetreive.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/images/LangfuseTraceDetail.jpg

File: source/amazon-bedrock-samples-main/knowledge-bases/images/retrieveAndGenerate.png

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/README.md
README Summary:
Deploy e2e RAG solution (using Knowledgebases for Amazon Bedrock) via CloudFormation
This is a complete setup for automatic deployment of end-to-end RAG workflow using Knowledge Bases for Amazon Bedrock.
Following resources will get created and deployed:
- IAM role
- Open Search Serverless Collection and Index
- Set up Data Source (DS) and Knowledge Base (KB)
Pre-requisite:
- You already have s3 bucket where your documents are stored
- The documents must be in one of the following supported formats- .txt,.md, .html, doc/.docx, .csv, xls/.xlsx, .pdf
Solution Deployment:
Step 1 : Prepare templates for deployment
`deploy.sh` script will create a S3 deployment bucket, upload the required artifacts it, and prepare the CloudFormation templates for deployment.
a.	If you run this script without [args], this will create a deployment bucket with default name - 'e2e-rag-deployment-${ACCOUNT_ID}-${AWS_REGION}'
b.	If you run this script with [args], this will create a deployment bucket with the name provided in second args- '<BUCKET_NAME>-${ACCOUNT_ID}-${AWS_REGION}'
Run the included `deploy.sh` script as shown below:
-  git clone https://github.com/aws-samples/amazon-bedrock-samples.git
-  cd knowledge-bases/03-infra/e2e-rag-deployment-using-bedrock-kb-cfn
-  bash deploy.sh (For Windows users it may be different)
Once deploy.sh script run is finished, go to the deployment bucket created and copy the `main-template-out.yml` S3 URL for Step 2
Step 2 : Deploy stacks
Using AWS Console:
- 1. Go to AWS CloudFormation Console and choose 'Template source' as Amazon S3 URL
- 2. Enter the 'Main CloudFormation template S3 URL' (noted in step 1) in Amazon S3 URL text box.
- 3. Specify the RAG workflow details with the options fitting your use case
- 4. In the Configure stack options section, add optional tags, permissions, and other advanced settings
- 5. Click Submit
Testing the RAG Workflow
Deployment may take 7-10 minutes.
After successful deployment,
- Go to Amazon Bedrock Console and select the Knowledge Base which is created
- Click on the `sync` button to start the ingestion job
- Once data is sync, selected the Foundation Model of your choice and ask query
Done!!

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/deploy.sh

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/artifacts/provider-event-handler.zip

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/artifacts/opensearchpy-layer.zip

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/artifacts/custom-resource-lambda.zip

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/main-template-out.yml

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/oss-infra-template.template

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/main-template-out-tmp.yml

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/kb-infra-template.template

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/kb-role-template.template

File: source/amazon-bedrock-samples-main/knowledge-bases/03-infra/e2e-rag-using-bedrock-kb-cfn/templates/oss-infra-template-tmp.template

File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/README.md
README Summary:
Access Controls for Knowledge Bases on Amazon Bedrock
This notebook guides users on creating access controls for Knowledge Bases on Amazon Bedrock.
Metadata filtering in knowledge bases enables access control for your data. By defining metadata fields based on attributes such as user roles, departments, or data sensitivity levels, you can ensure that the retrieval only fetches and uses information that a particular user or application is authorized to access. This helps maintain data privacy and security, preventing sensitive or restricted information from being inadvertently surfaced or used in generated responses. With this access control capability, you can safely use retrieval across different user groups or scenarios while complying with company specific data governance policies and regulations.
This example demonstrates the access control capabilities enabled by metadata filtering in Knowledge Bases, using a use case where a healthcare provider has a Knowledge Base containing conversation transcripts between doctors and patients.
!Solution Architecture
The workflow for the solution is as follows:
1. The doctor interacts with the Streamlit frontend, which serves as the application interface. Amazon Cognito handles user authentication and access control, ensuring only authorized doctors can access the application. For production use, it is recommended to use a more robust frontend framework such as AWS Amplify, which provides a comprehensive set of tools and services for building scalable and secure web applications.
2. After the doctor has successfully signed in, the application retrieves the list of patients associated with the doctor's ID from the Amazon DynamoDB database. The doctor is then presented with this list of patients, from which they can select one or more patients to filter their search.
3. When the doctor interacts with the Streamlit frontend, it sends a request to an AWS Lambda function, which acts as the application backend. The request includes the doctor's ID, a list of patient IDs to filter by, and the text query.
4. Before querying the knowledge base, the Lambda function retrieves data from the DynamoDB database, which stores doctor-patient associations. This step validates that the doctor is authorized to access the requested patient or list of patient's information.
5. If the validation is successful, the Lambda function queries the knowledge base using the provided patient or list of patient's IDs. The knowledge base is pre-populated with transcript and metadata files stored in Amazon Simple Storage Service (Amazon S3).
6. The knowledge base returns the relevant results, which are then sent back to the Streamlit application and displayed to the doctor.
Prerequisites
- AWS account
Deployment
The deployment steps for this solution are provided in the **kb-end-to-end-acl.ipynb** notebook.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the Contents section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/utils.py
Summary of utils.py:
- Function: create_base_infrastructure
- Function: create_kb_infrastructure
- Function: updateDataAccessPolicy
- Function: createAOSSIndex
- Function: replace_vars


File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/kb-end-to-end-acl.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/imgs/architecture.png

File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/templates/2-knowledgebase-infra.yaml

File: source/amazon-bedrock-samples-main/knowledge-bases/use-case-examples/metadata-filter-access-control/templates/1-base-infra.yaml

File: source/amazon-bedrock-samples-main/knowledge-bases/videos/LangfuseDashboardrec.mov

File: source/amazon-bedrock-samples-main/knowledge-bases/02-advanced-concepts/README.md
README Summary:
Advanced Concepts
Contents
0_chunk_size_evaluation_for_KB_RAG.ipynb - This notebook provides sample code for chunking size evaluation for building optimum RAG applcation. For each chunk sizes (you want to evaluate), following steps are repeated:
- Create execution role for Knowledge Bases for Amazon Bedrock with necessary policies for accessing data from S3 and writing embeddings into vector store (OpenSearchServerless).
- Create an empty OpenSearch serverless index.
- Download documents (or point to your document S3 location)
- Create knowledge base for Amazon Bedrock
- Create a data source within knowledge base which will connect to Amazon S3
- Once the data is available in the Bedrock Knowledge Bases with different chunk size, we'll evaluate the text chunks retreived for refernce QA pairs from these knowledge bases for faithfulness, correctness, and relevancy metrics using LlamaIndex.
- Using these metrics we can decide for RIGHT chunk size for our RAG based application.
Finally, based on the evaluation results, a question answering application with RIGHT chunk strategy can be built using the Amazon Bedrock APIs.
***
Note
If you use the notebook - `0_chunk_size_evaluation_for_KB_RAG.ipynb` for creating the knowledge bases and do not delete the resources, you may be incurred cost of storing data in OpenSearch Serverless, even if you are not using it. Therefore, once you are done with trying out the sample code, make sure to delete all the resources.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the Contents section of this README file with a link to your sample, along with a description..

File: source/amazon-bedrock-samples-main/knowledge-bases/02-advanced-concepts/02-using-open-source-framework/semantic_chunking_langchain.ipynb

File: source/amazon-bedrock-samples-main/knowledge-bases/02-advanced-concepts/02-using-open-source-framework/requirements.txt

File: source/amazon-bedrock-samples-main/knowledge-bases/02-advanced-concepts/02-using-open-source-framework/images/semantic-chunking.png

File: source/amazon-bedrock-samples-main/knowledge-bases/02-advanced-concepts/01-chunking-strategy/0_chunk_size_evaluation_for_KB_RAG.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan Image Generator/Instant Customization/Introduction to Amazon Titan Image Generator Instant Customization Feature.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan Image Generator/Instant Customization/Data/sketch_dog.png

File: source/amazon-bedrock-samples-main/multimodal/Titan Image Generator/Instant Customization/Data/smila.jpg

File: source/amazon-bedrock-samples-main/multimodal/Titan Image Generator/Instant Customization/Data/carton_ladybug.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/Titan-V2-Embeddings.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/embeddings_lang.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/chatbot_bedrock.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/terminal.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/chatbot_lang.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/vector_embedding.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/api.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/context-aware-chatbot.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/embeddings/v2/images/vector_db.jpg

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/README.md
README Summary:
Working with multimodal data using Amazon Bedrock
With the `Amazon Titan Multimodal Embeddings G1` model, you can create embeddings for multimodal data, specifically text and image data. These embeddings can then be used for multimodal search and Retrieval Augmented Generation (RAG) use-cases, for example searching images by text only, images only or a combination of text and images.
!Amazon Titan Multimodal Embeddings G1
Contents
- Multimodal RAG - Multimodal RAG using the Amazon Berkley Objects dataset.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/README.md
README Summary:
Build a contextual text and image search engine for product recommendations using Amazon Bedrock and Amazon OpenSearch Serverless
[WIP - 02/07/2024]
This repository aims at building a Large Language Model (LLM) powered search engine prototype to retrieve and recommend products based on text or image queries. This is a step-by-step guide on how to create Amazon Bedrock Titan models to encode images and text into embeddings, ingest embeddings into Amazon OpenSearch Service Serverless index, and query the index using OpenSearch Service k-nearest neighbors (KNN) functionality.
<ins> Introduction </ins>
The rise of contextual and semantic search has made ecommerce and retail businesses search easier for its consumers. Search engines and recommendation systems powered by Generative AI can improve product search experience exponentially by understanding natural language queries and returning more accurate results. This enhances the overall user experience helping customers to find what exactly they are looking for.
<ins> Solution overview </ins>
This solution includes the following components:
- Amazon Titan Multimodal Embeddings model: This FM is used to generate embeddings of the products images used in this blog. Using Titan Multimodal Embeddings, you can generate embeddings for your content and store them in a vector database. When an end user submits any combination of text and image as a search query, the model generates embeddings for the search query and matches them to the stored embeddings to provide relevant search and recommendations results to end users. You can further customize the model to enhance its understanding of your unique content and provide more meaningful results using image-text pairs for fine-tuning. By default, the model generates vectors (embeddings) of 1024 dimensions, and is accessed via the Amazon Bedrock service. You can also generate smaller dimensions to optimize for speed and performance
- Amazon OpenSearch Service Serverless: OpenSearch Service Serverless is an on-demand serverless configuration for Amazon OpenSearch Service. We use OpenSearch Service Serverless as a vector database for storing embeddings generated by the Titan Multimodal Embeddings model. An index created in the OpenSearch Service Serverless collection serves as the vector store for our RAG solution.
- Amazon SageMaker Studio: SageMaker Studio is an integrated development environment (IDE) for machine learning (ML). ML practitioners can perform all ML development stepsfrom preparing their data to building, training, and deploying ML models
<ins> Solution Design </ins>
The solution design consists of two parts  Data Indexing and Contextual Search. During Data Indexing, we process the product images to generate embeddings for these images and then populate the vector data store. These steps are completed prior to the user interaction steps.
In the Contextual Search phase, a search query (text or image) from the user is converted into embeddings and a similarity search is run on the vector database to find the similar product images based on similarity search. We then display the top similar results.
ARCHITECTURE:
!alt text
Following are the solution workflow steps:
1.	Download the product description text & images from public S3 bucket
2.	Review and Prepare the dataset.
3.	Generate embeddings for the product images using Titan Multimodal Embeddings (amazon. titan-embed-image-v1) multi-modal. If you have huge number of images and descriptions, then you can optionally use Amazon Bedrock Batch API.
4.	Store embeddings into vector engine for Amazon OpenSearch Service Serverless as the search engine.
5.	Finally, fetch the user query in natural language, convert it into embedding using Titan Multimodal Embeddings (amazon. titan-embed-image-v1) multi-modal, and perform a k-NN search. To get the relevant search results.
<ins> Dataset </ins>
The Amazon Berkeley Objects Dataset is used in the implementation. The dataset is a collection of 147,702 product listings with multilingual metadata and 398,212 unique catalogue images. We will only make use of the item images and item names in US English. For demo purposes we are going to use ~1,600 products.
Running Costs
This section outlines cost considerations for running this demo. Completing the POC will deploy a OpenSearch Cluster, a SageMaker Studio and will use Amazon Bedrock, which will cost approx. $X per hour. Noted: the price listed below is calculated using us-east-1 region. The cost varies from region to region. And the cost may change over time as well (the price here is recorded 2024-02-04).
Further cost breakdowns are below.
- **Amazon Bedrock**  Please visit the Amazon Bedrock Pricing to learn more about the pricing options.
- On-demand pricing for text embeddings, The Titan Multimodal Embeddings costs $0.0008 per 1,000 input tokens
- On-demand pricing fo image embeddings, The Titan Multimodal Embeddings costs $0.00006 per 1,000 input tokens
- **OpenSearch Service**  Prices vary based on instance type usage and Storage cost. For more information, see Amazon OpenSearch Service pricing.
- The `t3.small.search` instance runs for approx 1 hour at \$0.036 per hour.
- **SageMaker**  Prices vary based on EC2 instance usage for the Studio Apps, Batch Transform jobs and Serverless Inference endpoints. For more information, see Amazon SageMaker Pricing.
- The `ml.t3.medium` instance for *Studio Notebooks* runs for approx 1 hour at \$0.05 per hour.
- The `ml.c5.xlarge` instance for *Batch Transform* runs for approx 6 minutes at \$0.204 per hour.
- **Amazon S3**  Low cost, prices will vary depending on the size of the models/artifacts stored. The first 50 TB each month will cost only $0.023 per GB stored. For more information, see Amazon S3 Pricing.
Security
See CONTRIBUTING for more information.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/utils.py
Summary of utils.py:
- Function: get_titan_multimodal_embedding
- Function: plot_similarity_heatmap
- Function: get_image_from_item_id
- Function: get_image_from_item_id_s3
- Function: display_images
- Function: find_similar_items_from_query
- Function: find_similar_items_from_image


File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/titan_mm_embed_search_blog.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/CONTRIBUTING.md

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/LICENSE.txt

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/amazon-bedrock-multimodal-oss-searchengine-e2e/images/contextual_search_arch.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/images/titan-embeddings-g1-image.png

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/requirements.txt

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/globals.py
Summary of globals.py:


File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/0_data_prep.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/README.md
README Summary:
Multimodal RAG example
This example demonstrates how to implement a simple multimodal RAG solution using the `Amazon Titan Multimodal Embeddings G1` model for multimodal embeddings and the `Anthropic Claude v2` model for text generation.
!Multimodal RAG
1. We download a subset of data from the Amazon Berkley Objects dataset. The data includes Amazon products with metadata and catalog images. The metadata includes multiple tags that provide short text description of the product in the image. The data is filtered to only keep images that are associated for tags with description in a given language (`enUS` in our example), to limit the size of the data.
1. We convert all downloaded images into Base64 encoding.
1. An image and its associated text are converted into embeddings in a single `invoke_model` call to the `amazon.titan-embed-image-v1` model. We embed all images in our dataset in this way.
1. These embeddings are then ingested into in-memory FAISS database to store and search for embeddings vectors. In a real-world scenario, you will likely want to use a persistent data store such as the vector engine for Amazon OpenSearch Service Serverless or the pgvector extension for PostgreSQL.
1. Now for retrieval, we consider the following scenario: a customer is looking for a product and has a text description of the product and, optionally, an image of the product, we do an embeddings based similarity search by converting the text description and the image into embeddings using the `Amazon Titan Multimodal Embeddings G1` model and retrieve the most relevant results from the vector database.
1. We then further refine these search results by creating a text prompt using the description for the retrieved objects and asking the LLM (`Anthropic Claude v2`) to do the following:
* Reason through the responses based on the customer's description of what they were looking for and then either accept or reject each of the search results
* Explain the reasoning why each result was accepted or rejected.
* The text response generated by the model along with the accepted set of results (images and text) are returned to the customer.
Contents
The example consists of three files:
- `0_data_prep.ipynb` - This notebook contains the data download and data preparation code. It downloads the images and metadata from the Amazon Berkley Objects dataset, scales these images (if needed) to fit into the 2048x2048 pixel limit as required the `Amazon Titan Multimodal Embeddings G1` model and finally converts these images into Base64 encoding,
- `download_images.py` - This script downloads the images from `amazon-berkeley-objects` bucket. It uses the Python `asyncio` to download multiple files concurrently. It is called from as part of code cells in the `0_data_prep.ipynb` notebook.
- `1_multimodal_rag.ipynb` - This notebook ingests the Base64 encoded image data along with the accompanying text into the vector database. It implements the RAG functionality by using the user query (text) and an associated image. Just for the purpose of illustration, the input image is generated using `Stability AI's Stable Diffusion XL` model, this can be replaced with an actual image the user may have.
Setup (Optional)
The notebooks install all required Python packages upfront. In case you want to run these notebooks in a custom conda environment then you can create one using the following commands:
Use the `multimodal_rag_py39` conda environment for all notebooks in this folder.
Running
Run the following two notebooks in the order listed below:
1. `0_data_prep.ipynb`
1. `1_multimodal_rag.ipynb`

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/1_multimodal_rag.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/download_images.py
Summary of download_images.py:
- Function: download_image_file
- Function: download_images


File: source/amazon-bedrock-samples-main/multimodal/Titan/titan-multimodal-embeddings/rag/images/multimodal-rag-Page-1.drawio.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/README.md
README Summary:
Claude 3 Features and New Messages API
The multi-modal capability of Claude 3 allows for the input of not only text but also an image that you can ask questions about.
An example of the new mulimodal capability of the Claude 3 model is shown below with the new Messages API structure. In addition, an example of using Claude 3's vision capabilities in a RAG workflow is shown using Langchain. We also have a best practices guide for improving performance with Claude 3 Vision.
For Claude 3 Integration with Bedrock please visit Claude on Amazon Bedrock
Please see Claude 3 for more details on Claude 3 from Anthropic. Please follow this link for more details on the Messages API.
Contents
- Claude3-Sonnet Multi-Modal input - Example to illustrate the multmodal capabilties of Claude 3-Sonnet.
- Claude3-Sonnet Multi-Modal RAG with Langchain - Example to illustrate the multmodal capabilties of Claude 3-Sonnet in a RAG workflow in Langchain.
- Best practices for Claude 3 Vision - Best practices for how to improve performance with Claude 3 Vision capabilities.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/multimodal/Claude3/Claude3-Sonnet-Multimodal-Example.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Claude3/multi-modal-rag-claude3-sonnet-langchain.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Claude3/best_practices_for_claude3_bedrock.ipynb

File: source/amazon-bedrock-samples-main/multimodal/Claude3/animal.jpg

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/wrinkle.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/70.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/nine_dogs.jpg

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/labeled_circle.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/officer.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/100.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/circle.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/officer_example.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/chinos.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/140.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/table.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/receipt2.png

File: source/amazon-bedrock-samples-main/multimodal/Claude3/images/receipt1.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/fmeval_imported_models.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/customized-text-to-sql-model.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/llama3-ngrammedqa-fine-tuning.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/llama3-sftt-llama3-fine-tuning.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/text-2-sql-import-model-job.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/llama3-ft-ImportedModelList.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/llama3-ft-ImportedModelPlayground.gif

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/llama3-ft-ImportScreenshot.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/text-2-sql-imported-models-menu.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/text-2-sql-demo.gif

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/text-2-sql-take-model-arn.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/llama3-ft-SageMakerTrainingLog.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/text-2-sql-import-model-button.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-3/images/llama3-ft-ImportedModelDetails.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-2/Llama2 Fine Tuning-Boolq.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-2/images/import_jobs_perms.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-2/images/iam_role_import_jobs.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/llama-2/images/import_jobs.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/sm-mistral-fine-tuning-qna.ipynb

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/images/MistralImportJobDetailsScreenshot.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/images/MistralModelDetailsScreenshot.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/images/Mistral-ft-SageMakerTrainingLog.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/images/Mistral-ft-ImportScreenshot.png

File: source/amazon-bedrock-samples-main/custom_models/import_models/mistral/images/MistralModelListScreenshot.png

File: source/amazon-bedrock-samples-main/security-and-governance/README.md
README Summary:
Security and Governance
This folder contains examples related to Bedrock security and governance.
Contents
This repo is still under construction, come back soon!
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/README.md
README Summary:
Generative AI use-cases
This repo explores various generative AI use-cases and integrations with Amazon Bedrock.
Contents
- Connecting API Gateway & Lambda to Bedrock - Sample pattern connecting Amazon API Gateway and AWS Lambda with Bedrock
- Java Connection - Sample code for creating a connection to Amazon Bedrock through the AWS Java SDK
- AWS Genai LLM Chatbot - A modular and comprehensive solution to deploy a multi LLM powered chatbot (Amazon Bedrock)
- `VTT file processing and model evaluations with Amazon Bedrock` - Implement a simple `Video Text to track (VTT)` file processing solution that chaptertizes VTT files (transcripts) and uses Amazon Bedrock to create titles for each of the chapters using different Foundation Models (FMs) available via Amazon Bedrock. We also show use of `LiteLLM` as an easy to use interface for Bedrock.
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-lambda-layer/bedrock-1-28-57.zip

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-lambda-layer/README.md
README Summary:
Here is a draft README.md file:
Using Bedrock with AWS Lambda
Overview
The new Bedrock AI service from AWS provides powerful generative AI capabilities through API calls. However, the default Boto3 included in AWS Lambda has not yet been updated to support Bedrock.
To use Bedrock in Lambda functions today, you need to create a Lambda layer with an updated Boto3 that contains the Bedrock service definitions. This README provides steps and code snippets to create a Boto3 layer and deploy Lambda functions that can call Bedrock.
Prerequisites
- AWS account
- Configured AWS credentials on your local system
- Python 3.7+
- Boto3 1.28.57 or later (for Bedrock service definitions)
Errors Without Lambda Layer
If you try to call Bedrock from a Lambda function without using a layer, you will see errors like:
This occurs because the default Boto3 in Lambda does not have the service endpoints defined for Bedrock.
Steps to Create Layer
1. Package Boto3 1.28.57 or later into a .zip file
2. Use Lambda API to publish a layer version
3. Specify the layer ARN when creating Lambda functions
Here is a general video showing the steps to create a lambda layer
See `lambda_base.py` for layer creation code.
Lambda Function Code
`lambda_function.py` shows sample code to call Bedrock from a Python Lambda function.
The key points are:
- Import Boto3 and Bedrock clients
- Specify the Bedrock endpoint URL
- Invoke Bedrock APIs like `list_foundation_models`
There are two clients for Amazon Bedrock.
The `bedrock` client is for creating and managing Bedrock models.
The `bedrock-runtime` client is for running inference on Bedrock models.
Equivalent AWS CLI Commands
To create the layer:
**Note**: Get the layer arn from the output above and update the value below.
To create function:
Learn More
- Overview Video of Lambda and Lambda Layers Until 15:20 in the video
- Amazon Bedrock
- Bedrock service docs
- Boto3 AWS SDK
- Lambda layers

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-lambda-layer/lambda_function.py.zip

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-lambda-layer/lambda_base.py
Summary of lambda_base.py:
- Function: create_layer
- Function: create_functions
- Function: test_functions


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-lambda-layer/lambda_function.py
Summary of lambda_function.py:
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/README.md
README Summary:
AWS Serverless Multi-Modal Image Text Validation
Repository hosting sample AWS CDK code for the AWS Serverless Image Text Validation sample code.
Use Case
There are scenarios when delivery drivers take the picture of restaurant operating hours as a proof to show that its closed. However, given the wide variety of store operating hours signs, it can be challenging to validate the driver's claim, leading to potential fraud.
We aim to solve this use case in this sample solution. We demonstrate the use of Amazon AI service (Rekognition) and LLM (Large Language Models) hosted on Amazon Bedrock to determine whether the restaurant open or based on the picture of storefront's hours sign and the timestamp when the picture was taken. The LLM also provides detailed reasoning that led to the decision. The result is stored in DynamoDB along with metadata which can be used for further analysis.
We use single shot prompting technique to enable complex reasoning capabilities of the large language model (LLM).
The diagram below shows the overall architecture. Once images are dropped into an S3 bucket,
1. An event triggers a Lambda function (rek-bedrock.py)
2. The function then orchestrates the calls to AWS Rekognition, Amazon Bedrock
3. And finally stores the outcome in an Amazon DynamoDB table
!Architecture Diagram
Example
Input:
Current timestamp: Tuesday 01/23/2024 19:02:00
Image with hours of operation:
!Demo
Output:
Outcome: Not Closed
Reason: The current day is Tuesday and the current time is 19:02. Since the restaurant is open Monday-Friday 11AM-11PM and Saturday-Sunday 8AM-11PM, the restaurant is not closed at the current day and time.
Instructions to Use/Deploy this solution
Pre-requisites
1. Install NPM
2. Install latest CDK version CDK
3. Ensure docker is up and running
4. Configure your AWS CLI with the necessary permissions to deploy the resources in the architecture diagram above (Lambda, Rekognition, Bedrock, S3, DynamoDB, CloudWatch Logs, CloudWatch Events, IAM, etc). We strongly recommend following principle of least privileges
Steps to deploy
1. Clone this repository
2. `cd` into the `cdk` directory
3. Run `sudo npm install --legacy-peer-deps` to install dependencies
4. If necessary  run `cdk bootstrap` to bootstrap your environment
5. Run `cdk deploy` to deploy the stack. The deployment typically takes 10-15 minutes
Running the Solution
1. Choose any image from the `images` folder under `bedrock-rekognition-sample`
2. Navigate to the cloudformation stack named `MultiModalLLMStack` deployed afer running `cdk deploy`
!CloudFormationStack
3. Click on the stack name and navigate to the resources tab
!CloudFormationStackResources
4. Expand `multi-modal-landing-bucket` and click through the S3 bucket link
!CloudFormationStackS3Bucket
5. Drop the image in the S3 bucket selected in step4
6. An event is generated that triggers the Lambda function
7. The Lambda function processes the image text and stores the final outcome in
DynamoDB table called `restaurant-results-table`
8. Click on `Explore items` under Tables tab. See the screenshots below.
!DynamoDBTable
!DynamoDBTable
Cleanup
1. `cd` into `cdk` directory
2. Run `sudo cdk destroy` to delete all the deployed resources
Authors
This solution was co-developed by Swagat Kulkarni and Tony Howell.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/.gitignore

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/.npmignore

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/ddb-table-results.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/cloudformation-s3-bucket.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/cloud-formation-stack.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/cloudformation-resources.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/ddb-restaurant-explore.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/cdk.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/package-lock.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/package.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/tsconfig.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/architecture.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/bin/cdk.ts

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/lib/multi-modal-stack.ts

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/lib/lambda/requirements.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/cdk/lib/lambda/rek-bedrock.py
Summary of rek-bedrock.py:
- Function: get_bedrock_client
- Function: create_bedrock_llm
- Function: detect_text
- Function: detect_restaurant_closure
- Function: lambda_handler


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/images/restaurant-hours-3.jpg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/images/restaurant-hours-2.jpg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/images/restaurant-hours-1.jpg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-rekognition-sample/images/restaurant-hours-4.jpg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/metadata-tagger/README.md
README Summary:
Claude 3 - Metadata Extraction Capability
This repo provides code samples for Claude 3 to extract metadata from text. The schema for the metadata is provided as part of the prompt. This example uses synthetic data to demonstrate the metadata extraction capability for Claude 3. The extracted metadata is provided in JSON format so that it is parseable by downstream applications.
Bring your own Schema/Documents
1. To use your custom schema, enter the schema in the notebook as given in the example below. The provided example defines the structure and data types for generating metadata on physics-based documents. It specifies that each document should have an article title (string), author (string), topic (string), and an optional publication date (string). This schema ensures consistent and organized metadata for the documents, enabling efficient indexing, searching, and categorization of content.
2. View an example of a document that is used to generate metadata on:
- **Example document**:
- **Metadata generated**: The metadata generated using Claude 3 is generated in JSON format. This can be used for further analysis, enhanced document storage/retrieval and other downstream applications.
License
This library is licensed under the MIT-0 License. See the LICENSE file.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/metadata-tagger/claude3_metadata_tagger.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/README.md
README Summary:
Connecting to Amazon Bedrock with the AWS Java SDK
This directory contains a simple maven project for how to interact with Amazon Bedrock though the Java SDK.
Prerequisites
* Install Java (17.0.8 used in this example)
* Install Maven (3.9.4 used in this example)
* Authenticate to an AWS IAM role which has the correct permissions to invoke Amazon Bedrock models (This example uses Claude V2 from anthropic)
How to Run
Inside the `my-app` directory, run these two maven commands. The first packages your code and the second executes the code.
This will execute the prompt stored in the `my-app/example-payload.txt` file. Feel free change this prompt to whatever you desire! Just make sure to correctly format the prompt and associated variables as per this documentation.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/my-app/pom.xml

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/my-app/example-payload.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/my-app/src/main/java/com/example/app/App.java

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/my-app/src/main/java/com/example/app/utils/Utils.java

File: source/amazon-bedrock-samples-main/generative-ai-solutions/java-connection/my-app/src/main/java/com/example/app/pojo/ClaudeResponse.java

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-api-gateway/01_bedrock_api.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-api-gateway/README.md
README Summary:
Call the Bedrock APIs from your API Gateway, using a Amazon API Gateway, AWS Lambda layer with Boto3
The Cloudformation template cfn-template.yaml deploys:
* a Lambda Layer containing the Python Boto3 SDK updated to support Bedrock
* a Lambda function for consuming Bedrock **invoke_model** API
* a REST Api for invoking LLMs through Bedrock using `invoke_model`
The template defines a CloudFormation custom resource function that dynamically downloads and uses the latest published Bedrock SDK files to build the Lambda Layer when you deploy the stack.
* The default path to the bedrock-python-sdk.zip is automatically populated in the template. To use a different zip file, change the value for BedrockPreviewSdkUrl
!Architecture
You can test the solution through the following notebooks:
1. 01_bedrock_api.ipynb: Consume REST Api through `requests`
2. 02_bedrock_api_langchain.ipynb: Integrate APIGateway with Langchain

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-api-gateway/02_bedrock_api_langchain.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-api-gateway/images/architecture.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-api-gateway/setup/cfn-template.yaml

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/recordings-summary-generation.yaml

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/README.md
README Summary:
Recordings Summary Generator
Summary
This solution will automatically transcribe a recording that you upload and then create a summary of the recording and then send it to you. The solution uses Amazon Transcribe for the transcription and Amazon Bedrock for the generative summary creation.
Architecture
The solution is orchestrated using a Step Functions state machine that is triggered when you upload a recording to the S3 bucket:
!Architecture
1. Store recording in asset bucket
2. Trigger state machine
3. Transcribe recording and store transcription in asset bucket
4. Retrieve transcription and generate summary
5. Send summary to recipient
The state machine orchestrates the steps to perform the specific tasks. The detailed process is:
!State Machine
Deployment
Prerequisites
**Important!** In order to use Bedrock models, you must first enable model access as a one-time action. For this solution, youll need to enable access to the **Anthropic Claude** (*not* Claude Instant) model. You can enable access following the guidance here.
Supported Regions
This solution is supported in regions where the Bedrock Anthropic Claude model is available.
The solution is deployed using a CloudFormation template to automatically deploy the necessary resources in your AWS account. The template requires the following parameter values:
|Parameter|Purpose|
|---|---|
|Email Address Used to Send Summary |The summary will be sent to this address. ***You must acknowledge the initial SNS confirmation email before receiving additional notifications.*** |
|Summary Instructions               |These are the instructions given to the Bedrock model to generate the summary.|
Running the Solution
After you deploy the solution using CloudFormation, follow these steps:
1. Be sure to acknowledge the SNS email confirmation that you should receive a few moments after creating the CloudFormation stack.
2. On the CloudFormation console for the stack you just created, navigate to the Outputs tab and look for the value associated with **AssetBucketName**; it will look something like `summary-generator-assetbucket-xxxxxxxxxxxxx`.
3. Navigate to the S3 console and locate the bucket from step #2. This is where you'll upload your recordings. Valid file formats are **MP3**, **MP4**, **WAV**, **FLAC**, **AMR**, **OGG**, and **WebM**.
4. Upload your recording to the `recordings` folder. Uploading recordings will automatically trigger the Step Functions state machine. There's a sample team meeting recording in the `sample-recording` directory of the repository.
5. Navigate to the Step Functions console and select the `summary-generator` state machine.
6. Click on the name of the `Running` execution. Here, you can watch the progress of the state machine as it processes the recording.
7. After it reaches its `Success` state, you should receive an emailed summary of the recording.
- Alternatively, navigate to the S3 assets bucket and view the transcript there in the `transcripts` folder.
Viewing the Summary
You will get the recording summary emailed to the address you provided when you created the CloudFormation stack. If you don't receive the email in a few moments, make sure that you acknowledged the SNS confirmation email that you should have received after you created the stack and then upload the recording again, which will trigger the summary process.
Using the Sample Recording
This solution includes a mock team meeting recording that you can use to test the solution. The summary will look similar to the folowing. Because of the nature of generative AI, however, your output will look a bit different, but the content should be close:
> Here are the key points and next steps from the standup:
>
> * Joe finished reviewing the current state for task EDU1 and created a new task to develop the future state. That new task is in the backlog to be prioritized. He's now starting EDU2 but is blocked on resource selection.
>
>* Rob created a tagging strategy for SLG1 based on best practices, but may need to coordinate with other teams who have created their own strategies, to align on a uniform approach. A new task was created to coordinate tagging strategies.
>
>* Rob has made progress debugging for SLG2 but may need additional help. This task will be moved to Sprint 2 to allow time to get extra resources.
>
>Next Steps:
>
>* Joe to continue working on EDU2 as able until resource selection is decided
>* New task to be prioritized to coordinate tagging strategies across teams
>* SLG2 moved to Sprint 2
>* Standups moving to Mondays starting next week
Next Steps
* Instead of using SNS to notify recipients, you can use it to send the output to a different endpoint, such as a team collaboration site, or to the teams chat channel.
* Try changing the summary instructions provided to Bedrock to produce outputs specific to your needs.
* For example, if you were using this to summarize a companys earnings call, could you have the model focus on potential promising opportunities, areas of concern, and things that you should continue to monitor?
* If you are using this to summarize a course lecture, could you have the model identify upcoming assignments, summarize key concepts, list facts, and filter out any small talk from the recording?
* For longer recordings, can you generate summaries for different levels of interest and time commitment? For example, single sentence, single paragraph, single page, or in-depth summaries?
* For the same recording, could you create different summaries for different audiences? For example:
* Engineers summaries focus on design decisions, technical challenges, and upcoming deliverables
* Project managers summaries focus on timelines, costs, deliverables, and action items
* Project sponsors get a brief update on project status and escalations
* For situations where transcripts are available, create an alternate Step Functions flow to ingest existing text-based or PDF-based transcriptions
Cleanup
To clean up the solution, delete the CloudFormation stack that you created earlier. Deleting the stack will *not* delete the asset bucket. If you no longer need the recordings or transcripts, you can delete this bucket separately. Amazon Transcribe will automatically delete transcription jobs after 90 days, but you can delete these manually before then.
Authors and acknowledgment
This solution was created by Rob Barnes.
Special thanks to Anna Banwell and Joe Langreo for recording the mock team meeting and to Sergiy Shevchenko for being my testing guinea pig.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/images/architecture.svg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/images/stepfunctions_graph.png

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/images/stepfunctions_graph.svg

File: source/amazon-bedrock-samples-main/generative-ai-solutions/recordings-summary-generator/sample-recording/sample-team-meeting-recording.mp4

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/requirements.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/0_chapterize_data.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/2_summarize_metrics.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/1_generate_chapter_titles.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/README.md
README Summary:
Meeting transcript chapter title generation and comparison across FMs with Amazon Bedrock
This example shows how to generate chapter titles for `Video Text to track (VTT)` files using different Foundation Models (FMs) available in Bedrock and then evaluate the quality of the generated titles. The evaluation is done by comparing the titles generated by FMs with human written titles if available using quantitative metrics such as ROUGE#:~:text=The%20metrics%20compare%20an%20automatically,produced%20summary%20and%20the%20reference.) and Cosine Similarity Scores as well as by using an _LLM as a judge_ inspired by this paper. The _LLM as a judge_ approach that uses an evaluation prompt template provides a scalable _human out of the loop_ mechanism for evaluating FM outputs.
Additionally, this repo also shows how to use LiteLLM for interfacing with Bedrock and Ray for running Bedrock inference concurrently in an asynchronous manner.
Workflow
The following steps describe how this solution works.
Data Preparation - Option 1 - Use the provided VTT files
1. We provide a synthetic dataset of a couple of VTT files to illustrate the use of this repo. Replace the VTT files in the `data/source_data` folder with your own VTT files to test with your own dataset. Here is a snippet of the synthetically generated VTT file used for this repo.
1. Chapterize the VTT files, this is done by simply splitting the transcript into chunks of 25 lines each (configurable). You can replace the chapterization logic in the `0_chapterize_data` notebook with your own custom logic. The chapterized data from each transcript is stored in a single CSV file `chapterized.csv` file.
Data Preparation - Option 2 - Use your own chapterized JSON files
1. If you have a json file that is already chapterized in the following format, run the 0_already_chapterized_data.ipynb that sends the `already chapterized` data as a dataframe for model title generation:
Chapter Title Generation
1. Run each chapter through the models of interest using LiteLLM and Bedrock and track metrics such as `inference latency`, `prompt and generation tokens` and `cost per transaction`. The completions and metrics for each chapter title generation is stored in a JSON file in the `data/title_completions` folder.
1. Finally, we create a set of summarized results which provide the `mean` and `p95` metrics for each of the models under test and a human readable summary for each model which can help decide which model to pick for your specific dataset. Here is an example of the summarized results file generated by this solution.
>_The numbers presented in the table below are just examples and subject to change. Please test with your own dataset to get actual numbers for your dataset of interest_.
| model_id | latency_seconds | completion_token_count | prompt_token_count | input_token_price | output_token_pricing | p95_latency_seconds | avg_cost_per_txn | p95_cost_per_txn | p95_completion_token_count | p95_prompt_token_count | count | overall_report |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| amazon.titan-text-express-v1 | 1.214417 | 8 | 480 | 0.000384 | 1.3e-05 | 1.370577 | 0.000397 | 0.000518 | 12.25 | 623.3 | 4 | The average inference latency for this workload with prompt tokens 480 (p95 is 623) and completion tokens 8 (p95 is 12) when using amazon.titan-text-express-v1 is 1.2144s (p95 is 1.3706s) and the average cost per-request is $0.000397 (p95 is $0.000518), this is based on 4 requests. |
Model and Title Evaluation
1. We divide the evaluation step into two parts:
- In the first part, we calculate the **_ROUGE & Cosine Similarity_** scores as metrics to show the most optimal model from a quantitative perspective.
- In the second part, we use **Claude Sonnet** as an **_LLM that acts as a judge_** for subjective evaluation, and based on an evaluation prompt you define, it will generate the most optimal titles generated by a "selected model" that it shortlists, along with an "explanation" of why it chose that given title generated by the given **_selected model_** over other titles and models.
1. Following is an example of an **_evaluation prompt_** that Claude as a Judge uses to make a decision on the most optimal title generated:
Contents
The example consists of three Jupyter notebooks and a couple of Python scripts:
- `0_chapterize_data.ipynb` - This notebook contains the data preparation code. Parses the transcripts and chapterized them.
- `0_already_chapterized_data.ipynb` - This notebook contains the data preparation code. Parses already chapterized data.
- `1_generate_chapter_titles.ipynb` - This notebook uses LiteLLM and Bedrock to generate chapter titles and stores the results and metrics in a JSON file.
- `2_summarize_metrics.ipynb` - This notebook summarizes the metrics and creates the results in human readable format. It gives quantitative (**_ROUGE & Cosine Similarity_**) and Subjective (**_LLM acts as a Judge_**) metrics to get the most optimal model to be used for title generation.
- `main.py` - Script to run all the notebooks through a single command. See section on `Running`.
- `config.yml` - contains configuration parameters such as directory path, model information etc. for this solution. ***The pricing information in the `config.yml` is subject to change, please always confirm Bedrock pricing from the `Amazon Bedrock Pricing` page***.
Dataset
The dataset used in this repo is a synthetically dataset generated through the Bedrock chat playground using the Anthropic Claude 3 Sonnet model with the following prompt. It has been manually edits to get into the exact VTT format.
Setup
It is best to create a separate conda environment to run this solution using the commands provided below:
Use the `model_eval_bedrock_py311` conda environment for all notebooks in this folder.
Running
Run the following command which will run all the notebooks included in this repo in the correct order.
You could also run the notebooks manually in the order listed below:
1. `0_chapterize_data.ipynb` OR  `0_already_chapterized_data.ipynb`
1. `1_generate_chapter_titles.ipynb`
1. `2_summarize_metrics.ipynb`
Bring your own chapterization logic
The current solution uses a naive approach to chapterization by treating every Nth (=25, configurable) statement as a chapter boundary. You can easily replace this logic by adding your custom logic in the `chapterize.py` script.

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/chapterize.py
Summary of chapterize.py:
- Function: chapterize


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/.gitignore

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/0_already_chapterized_data.ipynb

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/bedrock_utils.py
Summary of bedrock_utils.py:
- Function: get_bedrock_client


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/config.yml

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/main.py
Summary of main.py:
- Function: read_config
- Function: output_handler
- Function: run_notebooks
- Function: main


File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/filtered_titles_for_eval.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/model_distribution_count.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/recommended_model.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/summary_metrics.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/overall_evaluation_report.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/model_eval.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/processed_evaluation_prompts.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/metrics/per_request_results.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/source_data/particle_physics_meeting.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/source_data/particle_physics_meeting.vtt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/meta.llama2-13b-chat-v1/chapter_1.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/meta.llama2-13b-chat-v1/chapter_3.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/meta.llama2-13b-chat-v1/chapter_2.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/meta.llama2-13b-chat-v1/chapter_4.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-sonnet-20240229-v1-0/chapter_1.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-sonnet-20240229-v1-0/chapter_3.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-sonnet-20240229-v1-0/chapter_2.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-sonnet-20240229-v1-0/chapter_4.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-haiku-20240307-v1-0/chapter_1.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-haiku-20240307-v1-0/chapter_3.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-haiku-20240307-v1-0/chapter_2.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/anthropic.claude-3-haiku-20240307-v1-0/chapter_4.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/mistral.mistral-7b-instruct-v0-2/chapter_1.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/mistral.mistral-7b-instruct-v0-2/chapter_3.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/mistral.mistral-7b-instruct-v0-2/chapter_2.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/mistral.mistral-7b-instruct-v0-2/chapter_4.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/amazon.titan-text-express-v1/chapter_1.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/amazon.titan-text-express-v1/chapter_3.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/amazon.titan-text-express-v1/chapter_2.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/title_completions/particle_physics_meeting.vtt/amazon.titan-text-express-v1/chapter_4.json

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/processed_data/processed.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/processed_data/chapterized.csv

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/mistral_template.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/llama_template.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/eval_template.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/titan_template.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/llama3_template.txt

File: source/amazon-bedrock-samples-main/generative-ai-solutions/bedrock-vtt-file-processing-and-model-evals/data/prompts/anthropic_template.txt

File: source/amazon-bedrock-samples-main/ops-tooling/bedrock_app_custom_dashboard.py
Summary of bedrock_app_custom_dashboard.py:
- Function: knowledge_base_id_to_oss_collection
- Function: knowledge_base_name_to_id
- Function: generate_dashboard_json
- Function: create_dashboard


File: source/amazon-bedrock-samples-main/ops-tooling/bedrock_cloudwatch_dashboard.py
Summary of bedrock_cloudwatch_dashboard.py:


File: source/amazon-bedrock-samples-main/ops-tooling/README.md
README Summary:
Operational Tooling
This folder contains helpful samples to help with operationalizing your work with Amazon Bedrock
Contents
- Set up CloudWatch dashboard - Create CloudWatch dashboard using AWS Python SDK
- Set up custom CloudWatch dashboard for Bedrock app - Create a custom CloudWatch dashboard using the AWS Python SDK to track relevant metrics of your Bedrock app
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/responsible-ai/README.md
README Summary:
Responsible AI
This folder contains examples related to Responsible AI on Bedrock
Contents
Guardrails for Amazon Bedrock Samples - Examples of Building, Updating, Versioning and Testing your Guardrails
Contributing
We welcome community contributions! Please ensure your sample aligns with AWS best practices, and please update the **Contents** section of this README file with a link to your sample, along with a description.

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/Guardrails with LangChain.ipynb

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/guardrails-api.ipynb

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/Apply_Guardrail_with_Streaming_and_Long_Context.ipynb

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/images/agent_guardrails.png

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/images/chatbedrock_guardrails.png

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/data/shareholder_letter.txt

File: source/amazon-bedrock-samples-main/responsible-ai/guardrails-for-amazon-bedrock-samples/data/financial_story.txt

File: docs/.DS_Store

File: docs/modify-prompt-input-restrictions.md

File: docs/modify-prompt-input-restrictions-example-ddb.png

File: docs/sagemaker-payload-examples/alexaTM-20B.md

File: docs/sagemaker-payload-examples/meta-llama-2-7b-chat.md

File: docs/sagemaker-payload-examples/huggingface-falcon-7B-BF16.md

File: docs/sagemaker-payload-examples/huggingace-mistral-7B-instruct.md

File: docs/architecture/usecase_architecture.png

File: docs/architecture/deployment_dashboard_architecture.png

File: deployment/get-cdk-version.js

File: deployment/build-s3-dist.sh

File: deployment/cdk-solution-helper/index.js

File: deployment/cdk-solution-helper/README.md
README Summary:
cdk-solution-helper
A lightweight helper function that cleans-up synthesized templates from the AWS Cloud Development Kit (CDK) and prepares
them for use with the AWS Solutions publishing pipeline. This function performs the following tasks:
Lambda function preparation
Replaces the AssetParameter-style properties that identify source code for Lambda functions with the common variables
used by the AWS Solutions publishing pipeline.
- `Code.S3Bucket` is assigned the `%%BUCKET_NAME%%` placeholder value.
- `Code.S3Key` is assigned the `%%SOLUTION_NAME%%`/`%%VERSION%%` placeholder value.
- `Handler` is given a prefix identical to the artifact hash, enabling the Lambda function to properly find the handler in the extracted source code package.
These placeholders are then replaced with the appropriate values using the default find/replace operation run by the pipeline.
Before:
After helper function run:
After build script run:
After CloudFormation deployment:
Template cleanup
Cleans-up the parameters section and improves readability by removing the AssetParameter-style fields that would have
been used to specify Lambda source code properties. This allows solution-specific parameters to be highlighted and
removes unnecessary clutter.
Before:
After:
---
&copy; Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.

File: deployment/cdk-solution-helper/.gitignore

File: deployment/cdk-solution-helper/package-lock.json

File: deployment/cdk-solution-helper/package.json

File: .github/PULL_REQUEST_TEMPLATE.md

File: .github/ISSUE_TEMPLATE/feature_request.md

File: .github/ISSUE_TEMPLATE/bug_report.md

File: .git/ORIG_HEAD

File: .git/config

File: .git/.COMMIT_EDITMSG.swp

File: .git/HEAD

File: .git/description

File: .git/index

File: .git/packed-refs

File: .git/COMMIT_EDITMSG

File: .git/FETCH_HEAD

File: .git/objects/a4/05feb4a9156e9d5f91d64cadef010e4cebcf3c

File: .git/objects/d8/7b2278952d10fe41d06b40192fb67ff714f765

File: .git/objects/c0/3416a0a73133fd9eaddfac68898c537300d1ec

File: .git/objects/pack/pack-c8b69764c29e6d2ad6ab5210e31811c3d1132f58.idx

File: .git/objects/pack/pack-c8b69764c29e6d2ad6ab5210e31811c3d1132f58.rev

File: .git/objects/pack/pack-c8b69764c29e6d2ad6ab5210e31811c3d1132f58.pack

File: .git/objects/7c/8e07bb811125f1465f275b7ef70957c9a546a2

File: .git/objects/17/8ad583c20d796a027a1f47ba1f80354521dacc

File: .git/objects/88/a3d5cb99586b06cb593754f02bf5bcb9eb9595

File: .git/objects/07/42c6e3905cfaf12a2fa01d3ddff480a52d943a

File: .git/objects/31/8ba1e38d9685c6366d28dc7ed0aa571d9f74c0

File: .git/objects/62/a5fc8f50f17c4e18ecff0109d64976805bc091

File: .git/objects/a6/6e04471baaab2029f5399a7ec6fd539ea15aff

File: .git/objects/cc/315cab296e495ae84ea8d2554dada48e988fcd

File: .git/objects/e0/f2ecd5b011af41d9f5ad29eb91b0d552448f1f

File: .git/objects/48/5087296db500f9ae1c56f283b75204f92ff0a6

File: .git/objects/25/c8abfbed188a0a87cd925dbfbef8670fc6ec34

File: .git/info/exclude

File: .git/logs/HEAD

File: .git/logs/refs/heads/DS-28-migrate-RDS-to-S3

File: .git/logs/refs/heads/main

File: .git/logs/refs/remotes/origin/DS-28-migrate-RDS-to-S3

File: .git/logs/refs/remotes/origin/HEAD

File: .git/logs/refs/remotes/origin/main

File: .git/hooks/commit-msg.sample

File: .git/hooks/pre-rebase.sample

File: .git/hooks/sendemail-validate.sample

File: .git/hooks/pre-commit.sample

File: .git/hooks/applypatch-msg.sample

File: .git/hooks/fsmonitor-watchman.sample

File: .git/hooks/pre-receive.sample

File: .git/hooks/prepare-commit-msg.sample

File: .git/hooks/post-update.sample

File: .git/hooks/pre-merge-commit.sample

File: .git/hooks/pre-applypatch.sample

File: .git/hooks/pre-push.sample

File: .git/hooks/update.sample

File: .git/hooks/push-to-checkout.sample

File: .git/refs/heads/DS-28-migrate-RDS-to-S3

File: .git/refs/heads/main

File: .git/refs/remotes/origin/DS-28-migrate-RDS-to-S3

File: .git/refs/remotes/origin/HEAD

File: .git/refs/remotes/origin/main
